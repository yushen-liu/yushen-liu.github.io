<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"> 
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
		<meta content="all" name="robots" />
		<meta name="author" content="BradBit" />
		<meta name="Copyright" content="Â© BIM Research Group, School of Software, Tsinghua University" />
		<meta name="description" content="Homepage of Yu-Shen Liu" />
		<meta name="keywords"content="Homepage,Yu-Shen Liu" />
		<link rel="icon" href="main/favicon.ico" type="image/x-icon" />
		<link rel="shortcut icon" href="main/favicon.ico" type="image/x-icon" />
		<link rel="stylesheet" rev="stylesheet" href="main/index.css" type="text/css" media="all" />
		<title>Yu-Shen Liu - Tsinghua University</title>
	</head>
	<body>
		<div class="main shadow">
			<div class="navigate shadow round " >
				<ul>
					<li><a href="#Biography">Bio&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></li>
					<li><a href="#Participated Projects">Participated Projects</a></li>
					<li><a href="#Teaching">Teaching</a></li>
					<li><a href="#Awards">Awards</a></li>
					<li><a href="#Academic Activities">Academic Activities</a></li>
					<li>
						<a href="#Selected Publications">Publications</a>
					</li>
					<li><a href="https://aideadlin.es">AI Conference Deadlines</a></li>

				</ul>
				<br/>
				<span style="font-size: 14px; font-family: 宋体; float: right;"><a href="index_cn.html">中文版本</a></span>
			</div>

			<div class="content">
				<div class="desc s15" id="Biography"> 
					<a href="main/big/liu.jpg"><img class="left" src="main/small/liu.jpg" alt="Yu-Shen Liu" width="200" /></a>
					<div class="picdesc">
					<div class="fullname"> 
						Yu-Shen Liu （刘玉身）
					</div>
					<hr/>
					Associate Professor<br/>
					<a href="https://www.thss.tsinghua.edu.cn/">School of Software, Tsinghua University, <br/>
					   	Beijing, P. R. China </a><br/><br/>
					Contacts:<br/>
					<table>
					<tr>
						<td>E-mail:</td><td><a href="mailto:liuyushen@tsinghua.edu.cn">liuyushen@tsinghua.edu.cn</a></td>
					</tr>
					<tr>
						<td>E-mail:</td><td><a href="mailto:liuyushen00@gmail.com">liuyushen00@gmail.com</a></td>
					</tr>
					<tr>
						<td>Tel:</td><td>+86-10-62795455</td>
					</tr>
					</table>
					<br/>
				   HomePages:<br/> 
				   <a href="https://www.thss.tsinghua.edu.cn/faculty/liuyushen.htm" title="Tsinghua homepage">Tsinghua homepage</a>,&nbsp;
				   <a href="https://scholar.google.com/citations?hl=zh-CN&user=Vo4ZHu0AAAAJ&view_op=list_works&sortby=pubdate" title="Google Scholar">Google Scholar</a>,&nbsp;
				   <a href="https://dblp.org/pid/44/2229.html" title="DBLP">DBLP</a>,&nbsp;
				   <a href="https://csrankings.org/#/index?vision&asia" title="CSRanking">CSRanking</a>
				   </div>
				</div>	
				<div class="block">
					Dr. Yu-Shen Liu is an Associate Professor in School of Software at Tsinghua University, China. He spent three years as a post-doctoral researcher in Purdue University from 2006 to 2009. He earned his PhD in the Department of Computer Science and Technology at Tsinghua University, China, in 2006. He received his BS in mathematics from Jilin University, China, in 2000. His current research interests include 3D computer vision, 3D reconstruction and generation, 3D foundation models, AI for industry, and building information modeling (BIM). He has served as Area Chair, senior PC and PC members for some top conferences, such as IJCAI, AAAI, ACM Multimedia, ICLR. He has published 60+ papers in top journals and conferences like TPAMI/TIP/CVPR/ICCV/ECCV/NeurIPS/ICML/AAAI/IJCAI/ACM MM, with a total of more than 5,600 citations on Google Scholar. He has undertaken 5 National Natural Science Foundation projects as PI, and 2 National Key R&D Program projects, and participated in the compilation of three national standards (ranked 3rd). His group has received the 2022 Outstanding Doctoral Dissertation Award of the Chinese Society of Graphics (CSG), the 2021 "Outstanding Graphics Open Source Dataset" Award of the Computer-Aided Design and Graphics Professional Committee of the Chinese Computer Society (CCF CAD&CG), the Highly Cited Research Award by Advanced Engineering Informatics (the Elsevier journal), the Best Student Presentation Award of ICCCBE 2016, and the Best Student Paper Award of CAD/Graphics 2005. One TPAMI paper was selected as an ESI highly cited paper, and he was listed in 2024 World's Top 2% Scientists released by Stanford University and Elsevier. His teaching achievements have won the Tsinghua University Excellent Courses, Tsinghua University Annual Teaching Excellence Award, Tsinghua University Outstanding Class Teacher First Prize (2 times), etc., and the graduate students guided by him have won the Beijing Outstanding Graduates, Tsinghua University Outstanding Graduates, and Tsinghua University Outstanding Dissertations for several times.
				</div>
				<div class="block">
				<!--<strong><font size=4px>社会责任博士生招生</font></strong>
				今年9字班推研(即2022年9月参加推研，2023年入学），清华大学软件学院预计仍会有一个社会责任博士生招生名额，学校要求人选需要满足下述条件之一：<br/> (1)强军计划、<br/> (2)对口支援(新疆大学、青海大学）、<br/> (3)少数名族骨干、<br/> (4)本校应届本科具有专项推免直博资格的军工定向。<br/> 校外考生需满足前三条之一，本校需满足第4条。如有本校9字班同学满足第4条 “本校应届本科具有专项推免直博资格的军工定向”，并有意向博士阶段从事三维计算机视觉、几何智能处理与重建研究，可联系软件学院刘玉身老师，邮箱：liuyushen@tsinghua.edu.cn，主页：<a href="https://yushen-liu.github.io/">https://yushen-liu.github.io/</a>，本科阶段软件工程、计算机等信息科学技术方向优先。欢迎推荐！
				</div>-->
				<div class="title" id="Education"><strong><font size=4px>Education</font></strong></div>
				<div class="block">
					<table cellspacing=5>
						<tr valign="Top">
							<td class="period">2000-2006:</td>
							<td>
							<strong>Tsinghua University</strong>, 
							Ph.D. in Computer Science and Technology.<br/>
						</tr>
						<tr align="top">
							<td class="period">1996-2000:</td>
							<td><strong>Jilin University</strong>, B.Sc. in Mathematics </td>
						</tr>
					</table>
				</div>
				<div class="title" id="Experience"><strong><font size=4px>Experience</font></strong></div>
				<div class="block">
					<table cellpadding=5>
						<tr>
							<td class="period">2009- present:  </td>
							<td>School of Software at <strong>Tsinghua University</strong>, Beijing, China.</td>
						</tr>
						<tr valign="Top">
							<td class="period">2006-2009:</td>
							<td><strong>Purdue University</strong>, West Lafayette, IN, USA. Postdoctoral researcher in School of Mechanical Engineering
							</td>
						</tr>
					</table>
				</div>
				<div class="title" id="Research Interests"><strong><font size=4px>Research Interests</font></strong></div>
				<div class="block"> 
					<talbe cellspacing=5>
						<tr><td><strong>3D Computer Vision, 3D Deep Learning</strong><br/><br/></td></tr>

						<tr><td>3D Representation and Recognition, 3D Geometry Processing and Semantic Understanding, 3D Reconstruction<br/><br/></td></tr>

						<tr><td>Building Information Modeling (BIM)<br/><br/></td></tr>
					</talbe>
					<u><a href="mailto:liuyushen@tsinghua.edu.cn">Currently, I am looking for <strong>PhD students</strong> and <strong>Research Assistants</strong> to work on the top publications. Please feel free to contact me.</a></u><br/><br/>
				</div>
				<div class="title" id="Participated Projects"><strong><font size=4px>Participated Fundings</font></strong></div>
				
				<div class="block">
					
					<talbe cellspacing=5>
						<tr><td><b>1. </b>NSF of China: Research on Semantic-Instance Segmentation and Shape Completion for 3D Point Clouds based on Feature Representation Learning (62072268), 2021.01-2024.12, PI.<br/><br/></td></tr>

						<tr><td><b>2. </b>National Key R&D Program of China (2020YFF0304100), 2020.10-2022.12, PI of sub-project.<br/><br/></td></tr>

						<tr><td><b>3. </b>National Key R&D Program of China (2018YFB0505403), 2018.05-2022.04, PI.<br/><br/></td></tr>

						<tr><td><b>4. </b>NSF of China: Studies on semantic retrieval for building information modeling (BIM) resources based on IFC (61472202), 2015.01-2018.12, PI.<br/><br/></td></tr>

						<tr><td><b>5. </b>NSF of China: Studies on shape matching for 3D articulated models based on metric geometry (61272229), 2013.01-2016.12, PI.<br/><br/></td></tr>

						<tr><td><b>6. </b>NSF of China: Study of non-rigid 3D shape retrieval (61003095), 2011.01-2013.12, PI. <br/><br/></td></tr>

						<tr><td><b>7. </b>National Technological Support Program for the 12th-Five-Year Plan of China (2012BAJ03B07), 2012.01-2015.09, main researcher.<br/><br/></td></tr>

						<tr><td><b>8. </b>NSF of China: China building information technology strategic research (U0970155), finished, main researcher.<br/></td></tr>

					</talbe>
					<br/>
				</div>
				<div class="title" id="Teaching"><strong><font size=4px>Teaching</font></strong></div>
				
				<div class="block">
					
					<talbe cellspacing=5>
						<tr>Instructor: "Fundamental of Programming", the undergraduate course, 2017-present <strong>Tsinghua University Excellent Course Award</strong> (2021-2024), 2021 - (Top 25%)<br/><br/></tr>
						
						<tr>Instructor: “Digital Geometry Processing”, the graduate course, 2016 - present <strong>Tsinghua University Annual Teaching Excellence Award</strong> 2018 - (Top 5%)<br/><br/></tr>

						<tr>Instructor: “Software Engineering (1)”, the undergraduate course, 2013 - 2016<br/><br/></tr>
						
						<tr>Co-Instructor: “Business Process and Asset Management”, the graduate course, 2015 - present<br/><br/></tr>
						
						<tr>Co-Instructor: “Digital Media (2)”, the graduate course, 2019<br/><br/></tr>
						
						<tr><strong>Tsinghua University Excellent Class Advisor</strong> (First Prize), 2017</tr>

					</talbe>
					<br/>
				</div>
				<div class="title" id="Awards"><strong><font size=4px>Awards</font></strong></div>
				<div class="block">	
					<table cellpadding=5>	
						<tr>
							<td><a href="main/big/LiuXh_dataset.png"><img src="main/big/LiuXh_dataset.png" alt="Highly_cited" width="200"/></a></td>
							<td>
								<strong><a href="http://tc.ccf.org.cn/tccad/jlry/txkyrjj/hjrxx/2021-09-01/735713.shtml">Best Open Graphics Benchmark Award</a></strong> in the field of the CAD/Graphics area in 2021, which is selected by Technical Committee on Computer Aided Design and Computer Graphics (TCCADCG) affiliated with the China Computer Federation (CCF). 
							</td>
						</tr>
						<tr>
							<td><a href="main/big/MVP.jpg"><img src="main/big/MVP.jpg" alt="Highly_cited" width="200"/></a></td>
							<td>
								In 2021, he led his team to win the ranked 3rd place in MVP Point Cloud Completion Challenge 2021 at ICCV 2021 - The 3rd Workshop on Sensing, Understanding and Synthesizing Humans.
							</td>
						</tr>
						<tr>
							<td><a href="main/big/Highly_cited.jpg"><img src="main/small/Highly_cited.jpg" alt="Highly_cited" width="200"/></a></td>
							<td>
								<strong>Highly Cited Research Award</strong> The paper, “The IFC-based path planning for 3D indoor spaces”, published in Advanced Engineering Informatics (the Elsevier journal) is awarded Highly Cited Research on December, 2016. This paper was published in 2013, which is one of the most highly cited papers during 2014, 2015 and up until June 2016 according to data from Scopus. Dr. Yu-Shen Liu is the corresponding author of this paper.
								<br/><a href="ifcpath/index.html">[Project Page]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_AEI12IFC.pdf">[Paper]&nbsp&nbsp</a>
								<a href="main/bibtex/Liu13ifc.txt">[Bib]&nbsp&nbsp</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/ICCCBE2016_award.jpg"><img src="main/small/ICCCBE2016_award.jpg" alt="ICCCBE2016_award" width="200"/></a></td>
							<td>
								<strong>Best Student Presentation Award</strong>, at the 16th International Conference on Computing in Civil and Building Engineering (ICCCBE2016), held on July 6-8, at 2016, Osaka, Japan. Dr. Yu-Shen Liu is the corresponding author of this paper, and Mr. Ge Gao is the first author.
								<br/><a href="main/pdf/GaoGe_ICCCBE2016_364.pdf">[Paper]&nbsp&nbsp</a>
							</td>
						</tr>
					</table>
					<tr>
						<td>
							<strong>Best Student Paper Award</strong>, at the Proceedings of the Ninth International Conference on Computer Aided Design and Computer Graphics (CAD-CG'05), 306–312, September, 2005, Hong Kong, China.
						</td>
					</tr>
					<br/><br/>
				</div>

				<div class="title" id="Academic Activities"><strong><font size=4px>Academic Activities</font></strong></div>
				<div class="block">
					<table cellspacing="0">
						<tr><td><strong>Senior Program Committee member</strong> at IJCAI 2021, AAAI 2022</td></tr>
						<tr><td><strong>Program Committee member</strong> at ACM Multimedia 2020, ACM Multimedia 2019</td></tr>
						<tr><td><strong>Program Committee member</strong> at AAAI 2021, AAAI 2020</td></tr>
						<tr><td><strong>Program Committee member</strong> at LCLR 2021</td></tr>
						<tr><td><strong>Program Committee member</strong> at IJCAI 2020, IJCAI 2019</td></tr>
						<tr><td><strong>Program Committee member</strong> at WACV 2020, GDC 2019, CAD&CG 2019, ACM Multimedia Asia 2019</td></tr>
						<tr><td><strong>Program Committee</strong> of EG-ICE 2019(European Group for Intelligent Computing in Engineering)</td></tr>
						<tr><td><strong>The editorial team</strong> of Construction Innovation: Information, Process, Management (CI), 2018 ~ present.
						<a href="http://www.emeraldgrouppublishing.com/products/journals/editorial_team.htm?id=CI">http://www.emeraldgrouppublishing.com/products/journals/editorial_team.htm?id=CI</a><br/><br/></td></tr>
						<tr><td><strong>Co-chairs</strong> of PLM Smart Manufacturing Workshop, <i>2018 Asian Conference on Design and Digital Engineering (ACDDE2018)</i><br/><br/></td></tr>
						<tr><td><strong>The program committee</strong> of <i>AUAPAF2018 (Asian Universities Alliance Postgraduate Academic Forum)</i><br/><br/></td></tr>
						<tr><td><strong>Editorial Board Member</strong> on the international journal <i>Smart Construction Research</i>, 2017 ~ present<br/><br/></td></tr>
						<tr><td><strong>Lead Guest Editor</strong>: Special Issue on Recent Advances on Building Information Modeling (BIM) <i>The Scientific World Journal</i>, 2013. (<b>SCI</b>, 2012 Impact factor: 1.730) <a href="main/bibtex/Liu14TSWJ.txt">&nbsp&nbsp[Bib]</a><br/><a herf="http://www.hindawi.com/journals/tswj/si/465058/cfp/">http://www.hindawi.com/journals/tswj/si/465058/cfp/</a><br/><br/></td></tr>
						<tr><td><strong>Guest Editor</strong>: Special Issue on Advances in Conceptual Design Theories, Methodologies, and Applications. <i>Advances in Mechanical Engineering</i>, 2013. (<b>SCI</b>, 2012 Impact factor: 1.062) <br/>
						<a herf="http://www.hindawi.com/journals/ame/si/293862/">http://www.hindawi.com/journals/ame/si/293862/</a><br/><br/></td></tr>
						<tr><td>The member on IFC Alignment 1.1 Expert Panel in buildingSMART<br/><br/></td></tr>
						<tr><td>The group of buildingSMART IFC Roads and Railway Standard.<br/><br/></td></tr>
						<tr><td>Reviewer for IEEE Transactions on Image Processing (TIP), CVPR, ICCV, IJCAI, AAAI, ACM Multimedia, ICME, Automation in Construction, Computer-Aided Design, ASME Journal of Mechanical Design, The Visual Computer, Computers & Graphics, International Journal of Precision Engineering and Manufacturing, Applied Stochastic Models in Business and Industry.<br/></td></tr>
					</table>
					<br/>
				</div>



				
				<div class="title" id="Selected Publications"><strong><font size=4px>Selected Publications</font></strong> <strong><font size=4px color=red>(*: corresponding author, #: co-first author)</font></strong></div>
			   	<div class="block">
					<b>Preprint</b>
					<hr />
					<table cellpadding=5>
					<tr>
						<td><a href="main/big/geodream.png"><img src="main/big/geodream.png" alt="SPU" width="200"/></a></td>
						<td>
							1. Baorui Ma*#, Haoge Deng#, Junsheng Zhou, <strong>Yu-Shen Liu</strong>, Tiejun Huang, Xinlong Wang*. GeoDream: Disentangling 2D and Geometric Priors for High-Fidelity and Consistent 3D Generation. arXiv:2311.17971.
							<br />
							<a href="https://mabaorui.github.io/GeoDream_page/">[Project Page]&nbsp&nbsp</a>
							<a href="https://arxiv.org/abs/2311.17971">[ArXiv]&nbsp&nbsp</a>
							<a href="main/pdf/LiuYS_Baorui_GeoDream.pdf">[PDF]&nbsp&nbsp</a>
							<a href="https://github.com/baaivision/GeoDream">[Github]&nbsp&nbsp</a>
						</td>
					</tr>
					</table>
					
					<b>2025</b>
					<hr />
					<table cellpadding=5>
						<tr>
							<td><a href="main/big/ICCV2025_SparseRecon.png"><img src="main/big/ICCV2025_SparseRecon.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Liang Han, Xu Zhang, Haichuan Song*, Kanle Shi, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. SparseRecon: Neural Implicit Surface Reconstruction from Sparse Views with Feature and Depth Consistencies. <i>Proceedings of the IEEE/CVF International Conference on Computer Vision (<strong>ICCV</strong>)</i>, 2025. <strong><span style="color:red;"></span></strong>
								<img class="new" src="main/img/new.gif"/>
								<a href="main/pdf/LiuYS_ICCV25_SparseRecon.pdf">[PDF]&nbsp&nbsp</a>
								<br />
								<br />
							</td>
						</tr>
						<tr>
							<td><a href="main/big/ICCV2025_GAP.png"><img src="main/big/ICCV2025_GAP.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Weiqi Zhang#, Junsheng Zhou#*, Haotian Geng#, Wenyuan Zhang, <strong>Yu-Shen Liu*</strong>. GAP: Gaussianize Any Point Clouds with Text Guidance. <i>Proceedings of the IEEE/CVF International Conference on Computer Vision (<strong>ICCV</strong>)</i>, 2025. <strong><span style="color:red;"></span></strong>
								<img class="new" src="main/img/new.gif"/>
								<a href="main/pdf/LiuYS_ICCV25_GAP.pdf">[PDF]&nbsp&nbsp</a>
								<br />
								<br />
							</td>
						</tr>
						<tr>
							<td><a href="main/big/ICCV2025_GradientFiltering.png"><img src="main/big/ICCV2025_GradientFiltering.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Qing Li*, Huifang Feng, Xun Gong, <strong>Yu-Shen Liu</strong>. Learning Normals of Noisy Points by Local Gradient-Aware Surface Filtering. <i>Proceedings of the IEEE/CVF International Conference on Computer Vision (<strong>ICCV</strong>)</i>, 2025. <strong><span style="color:red;"></span></strong>
								<img class="new" src="main/img/new.gif"/>
								<a href="main/pdf/LiuYS_ICCV25_GradientFiltering.pdf">[PDF]&nbsp&nbsp</a>
								<br />
								<br />
							</td>
						</tr>
						<tr>
							<td><a href="main/big/CVPR2025_NeRFPrior.png"><img src="main/big/CVPR2025_NeRFPrior.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Wenyuan Zhang, Emily Yue-ting Jia, Junsheng Zhou, Baorui Ma, Kanle Shi, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. NeRFPrior: Learning Neural Radiance Field as a Prior for Indoor Scene Reconstruction. <i>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</i>, 2025. <strong><span style="color:red;">(Highlight)</span></strong>
								<img class="new" src="main/img/new.gif"/>
								<a href="https://wen-yuan-zhang.github.io/NeRFPrior/">[Project Page]&nbsp&nbsp</a>
								<a href="https://arxiv.org/abs/2503.18361">[ArXiv]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_CVPR2025_NeRFPrior.pdf">[PDF]&nbsp&nbsp</a>
								<br />
								<br />
							</td>
						</tr>
						<tr>
							<td><a href="main/big/CVPR2025_MonoInstance.png"><img src="main/big/CVPR2025_MonoInstance.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Wenyuan Zhang, Yixiao Yang, Han Huang, Liang Han, Kanle Shi, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. MonoInstance: Enhancing Monocular Priors via Multi-view Instance Alignment for Neural Rendering and Reconstruction. <i>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</i>, 2025.
								<img class="new" src="main/img/new.gif"/>
								<a href="https://wen-yuan-zhang.github.io/MonoInstance/">[Project Page]&nbsp&nbsp</a>
								<a href="https://arxiv.org/abs/2503.18363">[ArXiv]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_CVPR2025_MonoInstance.pdf">[PDF]&nbsp&nbsp</a>
								<br />
								<br />
							</td>
						</tr>	
						<tr>
							<td><a href="main/big/CVPR2025_GaussianUDF.png"><img src="main/big/CVPR2025_GaussianUDF.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Shujuan Li, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. GaussianUDF: Inferring Unsigned Distance Functions through 3D Gaussian Splatting. <i>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</i>, 2025. <strong><span style="color:red;">(Highlight)</span></strong>
								<img class="new" src="main/img/new.gif"/>
								<a href="https://lisj575.github.io/GaussianUDF/">[Project Page]&nbsp&nbsp</a>
								<a href="https://arxiv.org/abs/2503.19458">[ArXiv]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_CVPR2025_GaussianUDF.pdf">[PDF]&nbsp&nbsp</a>
								<br />
								<br />
							</td>
						</tr>
						<tr>
							<td><a href="main/big/CVPR2025_Bijective.png"><img src="main/big/CVPR2025_Bijective.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Takeshi Noda#, Chao Chen#, Junsheng Zhou, Weiqi Zhang, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. Learning Bijective Surface Parameterization for Inferring Signed Distance Functions from Sparse Point Clouds with Grid Deformation. <i>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</i>, 2025.
								<img class="new" src="main/img/new.gif"/>
								<a href="https://takeshie.github.io/Bijective-SDF/">[Project Page]&nbsp&nbsp</a>
								<a href="https://arxiv.org/abs/2503.23670">[ArXiv]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_CVPR2025_Bijective.pdf">[PDF]&nbsp&nbsp</a>
								<br />
								<br />
							</td>
						</tr>
						<tr>
							<td><a href="main/big/TPAMI2024_chenchao.png"><img src="main/big/TPAMI2024_chenchao.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Chao Chen, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. NeuralTPS: Learning Signed Distance Functions without Priors from Single Sparse Point Clouds. <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>)</i>, 2025, 47(1): 565-582.
								<a href="main/pdf/LiuYS_TPAMI24_NeuralTPS.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://github.com/chenchao15/NeuralTPS">[Github]&nbsp&nbsp</a>
								<br />
								<br />
							</td>
						</tr>	
						<tr>
							<td><a href="main/big/AAAI2025_Sharpening.png"><img src="main/big/AAAI2025_Sharpening.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Chao Chen, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. Sharpening Neural Implicit Functions with Frequency Consolidation Priors. <i>The 39th Annual AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>)</i>, 2025. <strong><span style="color:red;">(Oral presentation)</span></strong>
								<a href="https://arxiv.org/abs/2412.19720">[ArXiv]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_AAAI2025_Sharpening.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://github.com/chenchao15/FCP">[Github]&nbsp&nbsp</a>
								<br />
								<br />
							</td>
						</tr>	
						<tr>
							<td><a href="main/big/AAAI2025_FatesGS.png"><img src="main/big/AAAI2025_FatesGS.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Han Huang#, Yulun Wu#, Chao Deng, Ge Gao*, Ming Gu, <strong>Yu-Shen Liu</strong>. FatesGS: Fast and Accurate Sparse-View Surface Reconstruction using Gaussian Splatting with Depth-Feature Consistency. <i>The 39th Annual AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>)</i>, 2025. <strong><span style="color:red;">(Oral presentation)</span></strong>
								<a href="https://arxiv.org/abs/2501.04628">[ArXiv]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_AAAI2025_FatesGS.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://github.com/yulunwu0108/FatesGS">[Github]&nbsp&nbsp</a>
								<br />
								<br />
							</td>
						</tr>	
						<tr>
							<td><a href="main/big/AAAI2025_Sparis.png"><img src="main/big/AAAI2025_Sparis.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Yulun Wu#, Han Huang#, Wenyuan Zhang, Chao Deng, Ge Gao*, Ming Gu, <strong>Yu-Shen Liu</strong>. Sparis: Neural Implicit Surface Reconstruction of Indoor Scenes from Sparse Views. <i>The 39th Annual AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>)</i>, 2025. <strong><span style="color:red;">(Oral presentation)</span></strong>
								<a href="https://arxiv.org/abs/2501.01196">[ArXiv]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_AAAI2025_Sparis.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://github.com/yulunwu0108/Sparis">[Github]&nbsp&nbsp</a>
								<br />
								<br />
							</td>
						</tr>
					</table>	

					<b>2024</b>
					<hr />
					<table cellpadding=5>			
						<tr>
							<td><a href="main/big/TPAMI2024_liqing.png"><img src="main/big/TPAMI2024_liqing.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Qing Li, Huifang Feng, Kanle Shi, Yue Gao, Yi Fang, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. Learning Signed Hyper Surfaces for Oriented Point Cloud Normal Estimation. <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>)</i>, 2024, 46(12): 9957-9974.
								<a href="https://leoqli.github.io/SHS-Net/">[Project Page]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_TPAMI24_SHSNet.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://github.com/LeoQLi/SHS-Net">[Github]&nbsp&nbsp</a>
								<br />
								<br />
							</td>
						</tr>
						<tr>
							<td><a href="main/big/TPAMI2024_FastN2N.png"><img src="main/big/TPAMI2024_FastN2N.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Junsheng Zhou#, Baorui Ma#, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. Fast Learning of Signed Distance Functions from Noisy Point Clouds via Noise to Noise Mapping. <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>)</i>, 2024, 46(12): 8936-8953.
								<a href="main/pdf/LiuYS_TPAMI24_FastN2N.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://github.com/mabaorui/Noise2NoiseMapping">[Github]&nbsp&nbsp</a>
								<br />
								<br />
							</td>
						</tr>
						<tr>
							<td><a href="main/big/TPAMI_2024_CAPUDF.png"><img src="main/big/TPAMI_2024_CAPUDF.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Junsheng Zhou#, Baorui Ma#, Shujuan Li, <strong>Yu-Shen Liu*</strong>, Yi Fang, Zhizhong Han. CAP-UDF: Learning Unsigned Distance Functions Progressively from Raw Point Clouds with Consistency-Aware Field Optimization. <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>)</i>, 2024, 46(12): 7475-7492.
								<a href="https://junshengzhou.github.io/CAP-UDF/">[Project Page]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_TPAMI24_CAPUDF.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://github.com/junshengzhou/CAP-UDF">[Github]&nbsp&nbsp</a>
								<br />
								<br />
							</td>
						</tr>
						<tr>
							<td><a href="main/big/NIPS2024_wenyuan.png"><img src="main/big/NIPS2024_wenyuan.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Wenyuan Zhang, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. Neural Signed Distance Function Inference through Splatting 3D Gaussians Pulled on Zero-Level Set. <i>Neural Information Processing Systems (<strong>NeurIPS</strong>)</i>, 2024.
								<a href="https://wen-yuan-zhang.github.io/GS-Pull/">[Project Page]&nbsp&nbsp</a>
								<a href="https://arxiv.org/abs/2410.14189">[ArXiv]&nbsp&nbsp</a>
								<a href="https://github.com/wen-yuan-zhang/GS-Pull">[Github]&nbsp&nbsp</a>
								<br />
								<br />
							</td>
						</tr>
						<tr>
							<td><a href="main/big/NIPS2024_hanliang.png"><img src="main/big/NIPS2024_hanliang.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Liang Han, Junsheng Zhou, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. Binocular-Guided 3D Gaussian Splatting with View Consistency for Sparse View Synthesis. <i>Neural Information Processing Systems (<strong>NeurIPS</strong>)</i>, 2024.
								<a href="https://hanl2010.github.io/Binocular3DGS/">[Project Page]&nbsp&nbsp</a>
								<a href="https://arxiv.org/abs/2410.18822">[ArXiv]&nbsp&nbsp</a>
								<a href="https://github.com/hanl2010/Binocular3DGS">[Github]&nbsp&nbsp</a>
								<br />
								<br />
							</td>
						</tr>
						<tr>
							<td><a href="main/big/NIPS2024_weiqi.png"><img src="main/big/NIPS2024_weiqi.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Junsheng Zhou#, Weiqi Zhang#, <strong>Yu-Shen Liu*</strong>. DiffGS: Functional Gaussian Splatting Diffusion. <i>Neural Information Processing Systems (<strong>NeurIPS</strong>)</i>, 2024.
								<a href="https://junshengzhou.github.io/DiffGS/">[Project Page]&nbsp&nbsp</a>
								<a href="https://arxiv.org/abs/2410.19657">[ArXiv]&nbsp&nbsp</a>
								<a href="https://github.com/weiqi-zhang/DiffGS">[Github]&nbsp&nbsp</a>
								<br />
								<br />
							</td>
						</tr>
						<tr>
							<td><a href="main/big/NIPS2024_junsheng.png"><img src="main/big/NIPS2024_junsheng.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Junsheng Zhou, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. Zero-Shot Scene Reconstruction from Single Images with Deep Prior Assembly. <i>Neural Information Processing Systems (<strong>NeurIPS</strong>)</i>, 2024.
								<a href="https://junshengzhou.github.io/DeepPriorAssembly/">[Project Page]&nbsp&nbsp</a>
								<a href="https://arxiv.org/abs/2410.15971">[ArXiv]&nbsp&nbsp</a>
								<a href="https://github.com/junshengzhou/DeepPriorAssembly">[Github]&nbsp&nbsp</a>
								<br />
								<br />
							</td>
						</tr>
						<tr>
							<td><a href="main/big/NIPS2024_chenchao.png"><img src="main/big/NIPS2024_chenchao.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Chao Chen, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. Inferring Neural Signed Distance Functions by Overfitting on Single Noisy Point Clouds through Finetuning Data-Driven based Priors. <i>Neural Information Processing Systems (<strong>NeurIPS</strong>)</i>, 2024.
								<a href="https://github.com/chenchao15/LocalN2NM">[Project Page]&nbsp&nbsp</a>
								<a href="https://arxiv.org/abs/2410.19680">[ArXiv]&nbsp&nbsp</a>
								<br />
								<br />
							</td>
						</tr>
						<tr>
							<td><a href="main/big/NIPS2024_yetian.png"><img src="main/big/NIPS2024_yetian.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Takeshi Noda#, Chao Chen#, Weiqi Zhang, Xinhai Liu, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. MultiPull: Detailing Signed Distance Functions by Pulling Multi-Level Queries at Multi-Step. <i>Neural Information Processing Systems (<strong>NeurIPS</strong>)</i>, 2024.
								<a href="https://takeshie.github.io/MultiPull/">[Project Page]&nbsp&nbsp</a>
								<a href="https://arxiv.org/abs/2411.01208">[ArXiv]&nbsp&nbsp</a>
								<a href="https://github.com/takeshie/MultiPull">[Github]&nbsp&nbsp</a>
								<br />
								<br />
							</td>
						</tr>
						<tr>
							<td><a href="main/big/cvpr_2024_udf.png"><img src="main/big/cvpr_2024_udf.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Junsheng Zhou#, Weiqi Zhang#, Baorui Ma*, Kanle Shi, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. UDiFF: Generating Conditional Unsigned Distance Fields with Optimal Wavelet Diffusion. <i>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</i>, 2024.
								<br />	
								<a href="https://weiqi-zhang.github.io/UDiFF/">[Project Page]&nbsp&nbsp</a>
								<a href="https://arxiv.org/abs/2404.06851">[ArXiv]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_CVPR2024_UDF.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://github.com/weiqi-zhang/UDiFF">[Github]&nbsp&nbsp</a>
								<br />	
							</td>
						</tr>
						<tr>
							<td><a href="main/big/ECCV2024_VolumeRendering.png"><img src="main/big/ECCV2024_VolumeRendering.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Wenyuan Zhang, Kanle Shi, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. Learning Unsigned Distance Functions from Multi-view Images with Volume Rendering Priors. <i>European Conference on Computer Vision (<strong>ECCV</strong>)</i>, 2024.
								<br />	
								<a href="https://wen-yuan-zhang.github.io/VolumeRenderingPriors/">[Project Page]&nbsp&nbsp</a>
								<a href="https://arxiv.org/abs/2407.16396">[ArXiv]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_ECCV2024_VolumeRendering.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://github.com/wen-yuan-zhang/VolumeRenderingPriors">[Github]&nbsp&nbsp</a>
								<br />	
							</td>
						</tr>
						<tr>
							<td><a href="main/big/ECCV2024_Unseen.png"><img src="main/big/ECCV2024_Unseen.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Chao Chen, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. Learning Local Pattern Modularization for Point Cloud Reconstruction from Unseen Classes. <i>European Conference on Computer Vision (<strong>ECCV</strong>)</i>, 2024.
								<br />	
								<a href="https://www.arxiv.org/abs/2408.14279">[ArXiv]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_ECCV2024_Unseen.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://github.com/chenchao15/Unseen">[Github]&nbsp&nbsp</a>
								<br />	
							</td>
						</tr>
						<tr>
							<td><a href="main/big/ECCV2024_Filtering.png"><img src="main/big/ECCV2024_Filtering.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Shengtao Li, Ge Gao*, Yudong Liu, Ming Gu, <strong>Yu-Shen Liu</strong>. Implicit Filtering for Learning Neural Signed Distance Functions from 3D Point Clouds. <i>European Conference on Computer Vision (<strong>ECCV</strong>)</i>, 2024.
								<br />	
								<a href="https://list17.github.io/ImplicitFilter">[Project Page]&nbsp&nbsp</a>
								<a href="https://arxiv.org/abs/2407.13342">[ArXiv]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_ECCV2024_ImplicitFiltering.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://github.com/list17/ImplicitFiltering">[Github]&nbsp&nbsp</a>
								<br />	
							</td>
						</tr>
						<tr>
							<td><a href="main/big/ACMMM24_Inferring.png"><img src="main/big/ACMMM24_Inferring.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Baorui Ma, <strong>Yu-Shen Liu*</strong>, Matthias Zwicker, Zhizhong Han. Inferring 3D Occupancy Fields through Implicit Reasoning on Silhouette Images. <i>ACM Multimedia (<strong>ACM MM</strong>)</i>, 2024.
								<br />	
								<a href="main/pdf/LiuYS_ACMMM2024_Inferring.pdf">[PDF]&nbsp&nbsp</a>
								<br />	
							</td>
						</tr>
						<tr>
							<td><a href="main/big/Uni3D_junsheng.png"><img src="main/big/Uni3D_junsheng.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Junsheng Zhou#, Jinsheng Wang#, Baorui Ma*#, <strong>Yu-Shen Liu</strong>, Tiejun Huang, Xinlong Wang*. Uni3D: Exploring Unified 3D Representation at Scale. <i>International Conference on Learning Representations (<strong>ICLR</strong>)</i>, 2024. <strong><span style="color:red;">(Spotlight, ~5.0% acceptance rate)</span></strong>
								<br />	
								<a href="https://arxiv.org/abs/2310.06773">[ArXiv]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_junsheng_Uni3d.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://github.com/baaivision/Uni3D">[Github]&nbsp&nbsp</a>
								<br />	
							</td>
						</tr>
						<tr>
							<td><a href="main/big/AAAI2024_shujuan.png"><img src="main/big/AAAI2024_shujuan.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Shujuan Li#, Junsheng Zhou#, Baorui Ma, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. Learning Continuous Implicit Field with Local Distance Indicator for Arbitrary-Scale Point Cloud Upsampling. <i>AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>)</i>, 2024, pp. 3181-3189.
								<br />	
								<a href="https://lisj575.github.io/APU-LDI">[Project Page]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_AAAI2024_pc_upsampling.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://arxiv.org/abs/2312.15133">[ArXiv]&nbsp&nbsp</a>
								<br />	
							</td>
						</tr>
						<tr>
							<td><a href="main/big/AAAI2024_huanghan.png"><img src="main/big/AAAI2024_huanghan.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Han Huang, Yulun Wu, Junsheng Zhou, Ge Gao*, Ming Gu, <strong>Yu-Shen Liu</strong>. NeuSurf: On-Surface Priors for Neural Surface Reconstruction from Sparse Input Views. <i>AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>)</i>, 2024, pp. 2312-2320.
								<br />	
								
								<a href="https://alvin528.github.io/NeuSurf/">[Project Page]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_AAAI2024_huanghan.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://arxiv.org/abs/2312.13977">[ArXiv]&nbsp&nbsp</a>
								<br />	
							</td>
						</tr>
						<tr>
							<td><a href="main/big/AAAI2024_shengtao.png"><img src="main/big/AAAI2024_shengtao.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Shengtao Li, Ge Gao*, Yudong Liu, <strong>Yu-Shen Liu</strong>, Ming Gu. GridFormer: Point-Grid Transformer for Surface Reconstruction. <i>AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>)</i>, 2024, pp. 3163-3171.
								<br />	
								<a href="https://arxiv.org/abs/2401.02292">[ArXiv]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_AAAI2024_shengtao.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://github.com/list17/GridFormer">[Github]&nbsp&nbsp</a>
								<br />	
							</td>
						</tr>
						<tr>
							<td><a href="main/big/ICRA2024.png"><img src="main/big/ICRA2024.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Junsheng Zhou, Xin Wen, Baorui Ma, <strong>Yu-Shen Liu*</strong>, Yue Gao, Yi Fang, Zhizhong Han. 3D-OAE: Occlusion Auto-Encoders for Self-Supervised Learning on Point Clouds. <i>IEEE International Conference on Robotics and Automation (<strong>ICRA</strong>)</i>, 2024. 
								<br />	
								<a href="https://arxiv.org/pdf/2203.14084.pdf">[ArXiv]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_ICRA2024_OAE.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://github.com/junshengzhou/3D-OAE">[Github]&nbsp&nbsp</a>
								<br />	
							</td>
						</tr>
						<tr>
							<td><a href="main/big/TPAMI2024_jishuyi.png"><img src="main/big/TPAMI2024_jishuyi.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Yifan Feng, Shuyi Ji, <strong>Yu-Shen Liu</strong>, Shaoyi Du, Qionghai Dai, Yue Gao*. Hypergraph-Based Multi-Modal Representation for Open-Set 3D Object Retrieval. <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>)</i>, 2024, accepted.
								<br />	
								<br />	
							</td>
						</tr>
					</table>
					
					<b>2023</b>
					<hr />
					<table cellpadding=5>
						<tr>
							<td><a href="main/big/nips2023_zhou.png"><img src="main/big/nips2023_zhou.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Junsheng Zhou#, Baorui Ma#, Wenyuan Zhang, Yi Fang, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. Differentiable Registration of Images and LiDAR Point Clouds with VoxelPoint-to-Pixel Matching. <i>Neural Information Processing Systems (<strong>NeurIPS</strong>)</i>, 2023.<strong><span style="color:red;">(Spotlight)</span></strong>
								<br />	
								<a href="main/pdf/LiuYS_NeurIPS23_VP2P.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://arxiv.org/abs/2312.04060">[ArXiv]&nbsp&nbsp</a>
								<a href="https://github.com/junshengzhou/VP2P-Match">[Github]&nbsp&nbsp</a>
								<br />	
							</td>
						</tr>
						<tr>
							<td><a href="main/big/nips2023_liqing.png"><img src="main/big/nips2023_liqing.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Qing Li, Huifang Feng, Kanle Shi, Yue Gao, Yi Fang, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. NeuralGF: Unsupervised Point Normal Estimation by Learning Neural Gradient Function. <i>Neural Information Processing Systems (<strong>NeurIPS</strong>)</i>, 2023.
								<br />	
								<a href="https://leoqli.github.io/NeuralGF/">[Project Page]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_NeurIPS23_NeuralGF.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://arxiv.org/abs/2311.00389">[ArXiv]&nbsp&nbsp</a>
								<a href="https://github.com/LeoQLi/NeuralGF">[Github]&nbsp&nbsp</a>

								<br />	
							</td>
						</tr>
						<tr>
							<td><a href="main/big/Liqing_siggraph2023.png"><img src="main/big/Liqing_siggraph2023.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Qing Li, Huifang Feng, Kanle Shi, Yi Fang, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. Neural Gradient Learning and Optimization for Oriented Point Normal Estimation. <i><strong>SIGGRAPH Asia 2023</strong></i>.
								<br />	
								<a href="https://leoqli.github.io/NGLO/">[Project Page]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_SigraphAsia_LiQing.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://arxiv.org/abs/2309.09211">[ArXiv]&nbsp&nbsp</a>
								<a href="https://github.com/LeoQLi/NGLO">[Github]&nbsp&nbsp</a>
								<br />	
							</td>
						</tr>
						<tr>
							<td><a href="main/big/GridPull.png"><img src="main/big/GridPull.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Chao Chen, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. GridPull: Towards Scalability in Learning Implicit Representations from 3D Point Clouds. <i>Proceedings of the IEEE/CVF International Conference on Computer Vision <strong>(ICCV)</strong></i>, 2023, pp.18322-18334.(CCF-A).
								<br />	
								<a href="https://arxiv.org/abs/2308.13175">[ArXiv]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_ICCV2023_GridPull.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://openaccess.thecvf.com/content/ICCV2023/html/Chen_GridPull_Towards_Scalability_in_Learning_Implicit_Representations_from_3D_Point_ICCV_2023_paper.html">[Open access]&nbsp&nbsp</a>
								<a href="https://github.com/chenchao15/GridPull">[Github]&nbsp&nbsp</a>
								<br />	
							</td>
						</tr>
						<tr>
							<td><a href="main/big/Retro-FPN.png"><img src="main/big/Retro-FPN.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Peng Xiang, Xin Wen, <strong>Yu-Shen Liu*</strong>, Hui Zhang*, Yi Fang, Zhizhong Han. Retro-FPN: Retrospective Feature Pyramid Network for Point Cloud Semantic Segmentation. <i>Proceedings of the IEEE/CVF International Conference on Computer Vision <strong>(ICCV)</strong></i>, 2023, pp.17826-17838.(CCF-A).
								<br />	
								<a href="https://arxiv.org/abs/2308.09314">[ArXiv]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_ICCV2023_Retro-FPN.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://openaccess.thecvf.com/content/ICCV2023/html/Xiang_Retro-FPN_Retrospective_Feature_Pyramid_Network_for_Point_Cloud_Semantic_Segmentation_ICCV_2023_paper.html">[Open access]&nbsp&nbsp</a>
								<a href="https://github.com/AllenXiangX/Retro-FPN">[Github]&nbsp&nbsp</a>
								<br />	
							</td>
						</tr>
						<tr>
							<td><a href="main/big/LevelSetUDF.png"><img src="main/big/LevelSetUDF.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Junsheng Zhou#, Baorui Ma#, Shujuan Li, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. Learning a More Continuous Zero Level Set in Unsigned Distance Fields through Level Set Projection. <i>Proceedings of the IEEE/CVF International Conference on Computer Vision <strong>(ICCV)</strong></i>, 2023, pp.3181-3192.(CCF-A).
								<br />	
								<a href="https://arxiv.org/abs/2308.11441">[ArXiv]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_ICCV2023_LevelSetUDF.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Learning_a_More_Continuous_Zero_Level_Set_in_Unsigned_Distance_ICCV_2023_paper.html">[Open access]&nbsp&nbsp</a>
								<a href="https://github.com/junshengzhou/LevelSetUDF">[Github]&nbsp&nbsp</a>
								<br />	
							</td>
						</tr>
						<tr>
							<td><a href="main/big/icml2023.png"><img src="main/big/icml2023.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Baorui Ma, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. Learning Signed Distance Functions from Noisy 3D Point Clouds via Noise to Noise Mapping. <i>International Conference on Machine Learning <strong>(ICML)</strong></i>, 2023.(CCF-A).<strong><span style="color:red;">(Oral presentation)</span></strong>.
								<br />
								<a href="https://arxiv.org/abs/2306.01405">[ArXiv]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_ICM2023_learning_signed_distance_funct.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://github.com/mabaorui/Noise2NoiseMapping/">[Github]&nbsp&nbsp</a>
								<br />	
							</td>
						</tr>
						<tr>
							<td><a href="main/big/Snowflake.jpg"><img src="main/big/Snowflake.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Peng Xiang#, Xin Wen#, <strong>Yu-Shen Liu*</strong>, Yan-Pei Cao, Pengfei Wan, Wen Zheng, Zhizhong Han. Snowflake Point Deconvolution for Point Cloud Completion and Generation with Skip-Transformer. <i>IEEE Transactions on Pattern Analysis and Machine Intelligence <strong>(TPAMI)</strong></i>, 2023, 45(5):6320-6338.(CCF-A).
								<br />	
								<a href="https://arxiv.org/abs/2202.09367">[ArXiv]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_TPAMI_SnowFlakeNet.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://ieeexplore.ieee.org/document/9928787/">[IEEE Xplore]&nbsp&nbsp</a>
								<a href="https://mp.weixin.qq.com/s/6Xf22Ht46YFz8qPzLHRoew">[Jittor Media report]</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/PMPNET++.png"><img src="main/big/PMPNET++.png" alt="Neural" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Xin Wen, Peng Xiang, Zhizhong Han, Yan-Pei Cao, Pengfei Wan, Wen Zheng, <strong>Yu-Shen Liu*</strong>. PMP-Net++: Point Cloud Completion by Transformer-Enhanced Multi-step Point Moving Paths. <i>IEEE Transactions on Pattern Analysis and Machine Intelligence <strong>(TPAMI)</strong></i>, 2023, 45(1): 852-867.(CCF-A).
								<br />
								<a href="PMP-Net++/index.html">[Project Page]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_TPAMI_PMP-Net_v2.pdf">[PDF]&nbsp&nbsp</a>
								<a href="http://arxiv.org/abs/2202.09507">[ArXiv]&nbsp&nbsp</a>	
								<a href="https://github.com/diviswen/PMP-Net">[Github]&nbsp&nbsp</a>
								<a href="https://ieeexplore.ieee.org/document/9735342">[IEEE Xplore]&nbsp&nbsp</a>
								<a href="https://mp.weixin.qq.com/s/fSPldmzT_nuCvqupCzlFyg">[Media report]</a>	
								<a href="https://mp.weixin.qq.com/s/UrQC5PbCS27XRvFQfCaQtQ">[Jittor Media report]</a>	
							</td>
						</tr>
						<tr>
							<td><a href="main/big/TIP2022_FLRf.png"><img src="main/big/TIP2022_FLRf.png" alt="Neural" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Wenyuan Zhang, Ruofan Xing, Yunfan Zeng, <strong>Yu-Shen Liu*</strong>, Kan-Le Shi, Zhizhong Han. Fast Learning Radiance Fields by Shooting Much Fewer Rays. <i>IEEE Transactions on Image Processing <strong>(TIP)</strong></i>, 2023, 32: 2703-2718.(CCF-A).
								<br />
								<a href="main/pdf/LiuYS_TIP2023_wenyuan.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://arxiv.org/abs/2208.06821">[ArXiv]&nbsp&nbsp</a>
								<a href="https://zparquet.github.io/Fast-Learning/">[Github]&nbsp&nbsp</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/LiuYS_CVPR2023_towards_better_gradient_consis.png"><img src="main/big/LiuYS_CVPR2023_towards_better_gradient_consis.png" alt="Neural" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Baorui Ma#, Junsheng Zhou#, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. Towards Better Gradient Consistency for Neural Signed Distance Functions via Level Set Alignment. <i>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong></i>, 2023, pp.17724-17734.(CCF-A).
								<br />
								<a href="main/pdf/LiuYS_CVPR2023_towards_better_gradient_consis.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://openaccess.thecvf.com/content/CVPR2023/html/Ma_Towards_Better_Gradient_Consistency_for_Neural_Signed_Distance_Functions_via_CVPR_2023_paper.html">[Open access]&nbsp&nbsp</a>
								<a href="https://github.com/mabaorui/TowardsBetterGradient/">[Github]&nbsp&nbsp</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/LiuYS_CVPR2023_NeuralTPS.png"><img src="main/big/LiuYS_CVPR2023_NeuralTPS.png" alt="Neural" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Chao Chen, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. Unsupervised Inference of Signed Distance Functions from Single Sparse Point Clouds without Learning Priors. <i>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong></i>, 2023, pp.17712-17723.(CCF-A).
								<br />
								<a href="main/pdf/LiuYS_CVPR2023_neuralTPS.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://arxiv.org/pdf/2303.14505.pdf">[ArXiv]&nbsp&nbsp</a>
								<a href="https://openaccess.thecvf.com/content/CVPR2023/html/Chen_Unsupervised_Inference_of_Signed_Distance_Functions_From_Single_Sparse_Point_CVPR_2023_paper.html">[Open access]&nbsp&nbsp</a>
								<a href="https://github.com/chenchao15/NeuralTPS">[Github]&nbsp&nbsp</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/LiuYS_CVPR2023_shs_net_learning_signed_hyper_.png"><img src="main/big/LiuYS_CVPR2023_shs_net_learning_signed_hyper_.png" alt="Neural" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Qing Li, Huifang Feng, Kanle Shi, Yue Gao, Yi Fang, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. SHS-Net: Learning Signed Hyper Surfaces for Oriented Normal Estimation of Point Clouds. <i>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong></i>, 2023, pp. 13591-13600.(CCF-A).
								<br />
								<a href="main/pdf/LiuYS_CVPR2023_shs_net_learning_signed_hyper.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://arxiv.org/pdf/2305.05873.pdf">[ArXiv]&nbsp&nbsp</a>
								<a href="https://openaccess.thecvf.com/content/CVPR2023/html/Li_SHS-Net_Learning_Signed_Hyper_Surfaces_for_Oriented_Normal_Estimation_of_CVPR_2023_paper.html">[Open access]&nbsp&nbsp</a>
								<a href="https://leoqli.github.io/SHS-Net/">[Project Page]&nbsp&nbsp</a>
								<a href="https://github.com/LeoQLi/SHS-Net">[Github]&nbsp&nbsp</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/LiuYS_CVPR2023_lp_dif_learning_local_pattern.png"><img src="main/big/LiuYS_CVPR2023_lp_dif_learning_local_pattern.png" alt="Neural" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Meng Wang, <strong>Yu-Shen Liu*</strong>, Yue Gao, Kanle Shi, Yi Fang, Zhizhong Han. LP-DIF: Learning Local Pattern-specific Deep Implicit Function for 3D Objects and Scenes. <i>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong></i>, 2023, pp.21856-21865.(CCF-A).
								<br />
								<a href="main/pdf/LiuYS_CVPR2023_lp_dif_learning_local_pattern.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://openaccess.thecvf.com/content/CVPR2023/html/Wang_LP-DIF_Learning_Local_Pattern-Specific_Deep_Implicit_Function_for_3D_Objects_CVPR_2023_paper.html">[Open access]&nbsp&nbsp</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/LiuYS_CVPR2023_robust_multiview_point_cloud_r.png"><img src="main/big/LiuYS_CVPR2023_robust_multiview_point_cloud_r.png" alt="Neural" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Haiping Wang, Yuan Liu, Zhen Dong*, Yulan Guo, <strong>Yu-Shen Liu</strong>, Wenping Wang, Bisheng Yang. Robust Multiview Point Cloud Registration with Reliable Pose Graph Initialization and History Reweighting. <i>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong></i>, 2023, pp.9506-9515.(CCF-A).
								<br />
								<a href="main/pdf/LiuYS_CVPR2023_WangRobust.pdf">[PDF]&nbsp&nbsp</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/NEAF.jpg"><img src="main/big/NEAF.jpg" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Shujuan Li#, Junsheng Zhou#, Baorui Ma, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. NeAF: Learning Neural Angle Fields for Point Normal Estimation. <i>AAAI Conference on Artificial Intelligence <strong>(AAAI)</strong></i>, 2023.(CCF-A).<strong><span style="color:red;">(Oral presentation)</span></strong>.
								<br />	
								<a href="https://lisj575.github.io/NeAF/">[Project Page]&nbsp&nbsp</a>
								<a href="https://arxiv.org/abs/2211.16869">[ArXiv]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_AAAI23_NeAF.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://github.com/lisj575/NeAF">[Github]&nbsp&nbsp</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/KT-NET_AAAI2023.jpg"><img src="main/big/KT-NET_AAAI2023.jpg" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Zhen Cao, Wenxiao Zhang, Xin Wen, Zhen Dong*, <strong>Yu-Shen Liu</strong>, Xiongwu Xiao, Bisheng Yang. KT-Net: Knowledge Transfer for Unpaired 3D Shape Completion. <i>AAAI Conference on Artificial Intelligence <strong>(AAAI)</strong></i>, 2023.(CCF-A).
								<br />	
							</td>
						</tr>
						<tr>
							<td><a href="main/big/CAGD2023.png"><img src="main/big/CAGD2023.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Xinhai Liu, Zhizhong Han, Sanghuk Lee, Yan-Pei Cao, <strong>Yu-Shen Liu*</strong>. D-Net: Learning for Distinctive Point Clouds by Self-attentive Point Searching and Learnable Feature Fusion. <i>Computer Aided Geometric Design <strong>(CAGD)</strong></i>, 2023,104:102206.
								<br />
								<a href="main/pdf/CAGD2023_D_Net_CAGD_FT.pdf">[PDF]&nbsp&nbsp</a>
								<br />	
							</td>
						</tr>
						<tr>
							<td><a href="main/big/ICRA2023.png"><img src="main/big/ICRA2023.png" alt="Neural" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Congcong Wen, Hao Huang, <strong>Yu-Shen Liu</strong>, Yi Fang*. Pyramid Learnable Tokens for 3D LiDAR Place Recognition. <i>IEEE International Conference on Robotics and Automation <strong>(ICRA 2023)</strong></i>.
								<br />	
								<a href="main/pdf/LiuYS_ICRA2023.pdf">[PDF]&nbsp&nbsp</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/MM2023.png"><img src="main/big/MM2023.png" alt="Neural" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Congcong Wen, Xiang Li, Hao Huang, <strong>Yu-Shen Liu</strong>, Yi Fang*. 3D Shape Contrastive Representation Learning with Adversarial Examples. <i>IEEE Transactions on Multimedia <strong>(TMM)</strong></i>, 2023 | Journal article DOI: 10.1109/TMM.2023.3265177.(CCF-B).
								<br />
								<a href="main/pdf/TMM2023.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://ieeexplore.ieee.org/document/10094000">[IEEE Xplore]&nbsp&nbsp</a>
								<br />	
							</td>
						</tr>
						<tr>
							<td><a href="main/big/TMM2023_2.png"><img src="main/big/TMM2023_2.png" alt="Neural" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Shuaihang Yuan#, Congcong Wen#, <strong>Yu-Shen Liu</strong>, Yi Fang*. Retrieval-Specific View Learning for Sketch-to-Shape Retrieval. <i>IEEE Transactions on Multimedia <strong>(TMM)</strong></i>, 2023, Accepted.
								<br />	
							</td>
						</tr>
						<tr>
							<td><a href="main/big/liuhan_2023_MVDLite.png"><img src="main/big/liuhan_2023_MVDLite.png" alt="Neural" width="200"/></a></td>
							<td>
								<span class="sequence"></span> Han Liu, Ge Gao*, Hehua Zhang, <strong>Yu-Shen Liu</strong>, Yan Song, Ming Gu. MVDLite: A fast validation algorithm for Model View Definition rules. <i>Advanced Engineering Informatics</i>, 2023, 58 (102132): 1-14. (SCI, 2022 Impact factor: 8.8)
								<br />
								<a href="main/pdf/LiuYS_liuhan_2023_MVDLite.pdf">[PDF]&nbsp&nbsp</a>
								<br />	
							</td>
						</tr>
						<tr>
							<td><a href="main/big/liuhan_2023.png"><img src="main/big/liuhan_2023.png" alt="Neural" width="200"/></a></td>
							<td>
								<span class="sequence"></span> Han Liu, Xiaoyu Song, Ge Gao*, Hehua Zhang, <strong>Yu-Shen Liu</strong>, Ming Gu. Modeling and validating temporal rules with semantic Petri net for digital twins. <i>Advanced Engineering Informatics</i>, 2023, 57 (102099): 1-14.(SCI.2022 Impact factor: 8.8)
								<br />
								<a href="main/pdf/LiuYS_liuhan_2023.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://www.sciencedirect.com/science/article/pii/S1474034623002276?utm_campaign=STMJ_AUTH_SERV_PUBLISHED&utm_medium=email&utm_acid=45570568&SIS_ID=&dgcid=STMJ_AUTH_SERV_PUBLISHED&CMX_ID=&utm_in=DM398833&utm_source=AC_">[ScienceDirect]&nbsp&nbsp</a>
								<br />	
							</td>
						</tr>
					</table>

					<b>2022</b>
					<hr />
					<table cellpadding=5>
						<tr>
							<td><a href="main/big/LiuYS_Arxiv_SPU-Net.png"><img src="main/big/LiuYS_Arxiv_SPU-Net.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Xinhai Liu, Xinchen Liu, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. SPU-Net: Self-supervised Point Cloud Upsampling by Coarse-to-Fine Reconstruction with Self-Projection Optimization. <i>IEEE Transactions on Image Processing <strong>(TIP)</strong></i>, 2022, 31: 4213-4226.(CCF-A).
								<br />	
								<a href="http://arxiv.org/abs/2012.04439">[ArXiv]&nbsp&nbsp</a>	
								<a href="main/pdf/LiuYS_TIP_SPUNet.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://github.com/liuxinhai/SPU-Net">[Github]&nbsp&nbsp</a>
							</td>
						</tr>
						<tr>
						<tr>
							<td><a href="main/big/NIPS2022_zhou.jpg"><img src="main/big/NIPS2022_zhou.jpg" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Junsheng Zhou#, Baorui Ma#, <strong>Yu-Shen Liu*</strong>, Yi Fang, Zhizhong Han. Learning Consistency-Aware Unsigned Distance Functions Progressively from Raw Point Clouds. <i>Neural Information Processing Systems <strong>(NeurIPS)</strong></i>, 2022.(CCF-A).
								<br />	
								<a href="https://junshengzhou.github.io/CAP-UDF">[Project Page]&nbsp&nbsp</a>
								<a href="https://arxiv.org/abs/2210.02757">[ArXiv]&nbsp&nbsp</a>	
								<a href="main/pdf/LiuYS_NeurIPS22_Zhou.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/68d88dcd1e1917c74993902073f08e40-Abstract-Conference.html">[Proceedings]&nbsp&nbsp</a>
								<a href="https://github.com/junshengzhou/CAP-UDF">[Github]&nbsp&nbsp</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/NIPS2022_Li.jpg"><img src="main/big/NIPS2022_Li.jpg" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Qing Li, <strong>Yu-Shen Liu*</strong>, Jin-San Cheng, Cheng Wang, Yi Fang, Zhizhong Han. HSurf-Net: Normal Estimation for 3D Point Clouds by Learning Hyper Surfaces. <i>Neural Information Processing Systems <strong>(NeurIPS)</strong></i>, 2022.(CCF-A).
								<a href="https://arxiv.org/abs/2210.07158">[ArXiv]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_NIPS2022_LIQING.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/1b115b1feab2198dd0881c57b869ddb7-Abstract-Conference.html">[Proceedings]&nbsp&nbsp</a>
								<a href="https://github.com/LeoQLi/HSurf-Net">[Github]&nbsp&nbsp</a>
								<br />
							</td>
						</tr>
						<tr>
							<td><a href="main/big/ECCV2022_LPI.gif"><img src="main/big/ECCV2022_LPI.gif" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Chao Chen, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. Latent Partition Implicit with Surface Codes for 3D Representation. <i>European Conference on Computer Vision <strong>(ECCV)</strong></i>, 2022, LNCS 13663, pp. 322–343.
								<br />	
								<a href="https://chenchao15.github.io/LPI_page/">[Project Page]&nbsp&nbsp</a>
								<a href="https://arxiv.org/abs/2207.08631">[ArXiv]&nbsp&nbsp</a>	
								<a href="main/pdf/LiuYS_ECCV2022_LPI.pdf">[PDF]&nbsp&nbsp</a>
							</td>
						</tr>						
						<tr>
						<td><a href="main/big/CVPR2022_PredictiveContextPriors.png"><img src="main/big/CVPR2022_PredictiveContextPriors.png" alt="Neural" width="200"/></a></td>
						<td>
							<span class="sequence"></span>Baorui Ma, <strong>Yu-Shen Liu*</strong>, Matthias Zwicker, Zhizhong Han. Surface Reconstruction from Point Clouds by Learning Predictive Context Priors. <I>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong></I>, 2022, pp. 6326-6337.(CCF-A)
							<br />
							<a href="https://arxiv.org/abs/2204.11015">[ArXiv]&nbsp&nbsp</a>	
							<a href="https://mabaorui.github.io/PredictableContextPrior_page/">[Project Page]&nbsp&nbsp</a>
							<a href="main/pdf/CVPR2022_PredictiveContextPriors.pdf">[PDF]&nbsp&nbsp</a>
							<a href="main/pdf/LiuYS_CVPR2022_OnSurfacePriors-supp.pdf">[Supp]&nbsp&nbsp</a>
							<a href="https://openaccess.thecvf.com/content/CVPR2022/html/Ma_Surface_Reconstruction_From_Point_Clouds_by_Learning_Predictive_Context_Priors_CVPR_2022_paper.html">[Open access]&nbsp&nbsp</a>
							<a href="https://github.com/mabaorui/PredictableContextPrior">[Github]&nbsp&nbsp</a>
						</td>
						</tr>
						<tr>
						<td><a href="main/big/LiuYS_CVPR2022_OnSurfacePriors.png"><img src="main/big/LiuYS_CVPR2022_OnSurfacePriors.png" alt="Neural" width="200"/></a></td>
						<td>
							<span class="sequence"></span>Baorui Ma, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. Reconstructing Surfaces for Sparse Point Clouds with On-Surface Priors. <I>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong></I>, 2022, pp. 6315-6325.(CCF-A)
							<br />
							<a href="https://arxiv.org/abs/2204.10603">[ArXiv]&nbsp&nbsp</a>	
							<a href="https://mabaorui.github.io/-OnSurfacePrior_project_page/">[Project Page]&nbsp&nbsp</a>
							<a href="main/pdf/LiuYS_CVPR2022_OnSurfacePriors.pdf">[PDF]&nbsp&nbsp</a>
							<a href="main/pdf/LiuYS_CVPR2022_OnSurfacePriors-supp.pdf">[Supp]&nbsp&nbsp</a>
							<a href="https://openaccess.thecvf.com/content/CVPR2022/html/Ma_Reconstructing_Surfaces_for_Sparse_Point_Clouds_With_On-Surface_Priors_CVPR_2022_paper.html">[Open access]&nbsp&nbsp</a>
							<a href="https://github.com/mabaorui/OnSurfacePrior">[Github]&nbsp&nbsp</a>
						</td>
						</tr>
						<tr>
						<td><a href="main/big/LiuYS_CVPR2022_3DAttriFlow.png"><img src="main/big/LiuYS_CVPR2022_3DAttriFlow.png" alt="Neural" width="200"/></a></td>
						<td>
							<span class="sequence"></span>Xin Wen#, Junsheng Zhou#, <strong>Yu-Shen Liu*</strong>, Hua Su, Zhen Dong, Zhizhong Han. 3D Shape Reconstruction from 2D Images with Disentangled Attribute Flow. <I>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong></I>, 2022, pp. 3803-3813.(CCF-A)
							<br />
							<a href="main/pdf/LiuYS_CVPR2022_3DAttriFlow.pdf">[PDF]&nbsp&nbsp</a>
							<a href="https://arxiv.org/abs/2203.15190">[ArXiv]&nbsp&nbsp</a>	
							<a href="https://openaccess.thecvf.com/content/CVPR2022/html/Wen_3D_Shape_Reconstruction_From_2D_Images_With_Disentangled_Attribute_Flow_CVPR_2022_paper.html">[Open access]&nbsp&nbsp</a>
							<a href="https://github.com/junshengzhou/3DAttriFlow">[Github]&nbsp&nbsp</a>
						</td>
						</tr>
						<tr>
						<td><a href="main/big/LiuYS_CVPR2022_DCC-DIF.png"><img src="main/big/LiuYS_CVPR2022_DCC-DIF.png" alt="Neural" width="200"/></a></td>
						<td>
							<span class="sequence"></span>Tianyang Li, Xin Wen, <strong>Yu-Shen Liu*</strong>, Hua Su, Zhizhong Han. Learning Deep Implicit Functions for 3D Shapes with Dynamic Code Clouds. <I>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong></I>, 2022, pp. 12840-12850.(CCF-A)
							<br />
							<a href="https://lity20.github.io/DCCDIF_project_page/">[Project Page]&nbsp&nbsp</a>
							<a href="main/pdf/LiuYS_CVPR2022_DCC-DIF.pdf">[PDF]&nbsp&nbsp</a>
							<a href="https://arxiv.org/abs/2203.14048">[ArXiv]&nbsp&nbsp</a>	
							<a href="main/pdf/LiuYS_CVPR2022_DCC-DIF-supp.pdf">[Supp]&nbsp&nbsp</a>
							<a href="https://openaccess.thecvf.com/content/CVPR2022/html/Li_Learning_Deep_Implicit_Functions_for_3D_Shapes_With_Dynamic_Code_CVPR_2022_paper.html">[Open access]&nbsp&nbsp</a>
							<a href=" https://github.com/lity20/DCCDIF">[Github]&nbsp&nbsp</a>
							<a href="https://mp.weixin.qq.com/s/wpedor7u4wDsOtG3SdO0Dw">[Jittor Media report]</a>
						</td>
						</tr>
					</table>

					<b>2021</b>
					<hr />
					<table cellpadding=5>
						<tr>
						<td><a href="main/big/LiuYS_ICCV2021_SnowflakeNet.jpg"><img src="main/big/LiuYS_ICCV2021_SnowflakeNet.jpg" alt="Neural" width="200"/></a></td>
						<td>
							<span class="sequence"></span>Peng Xiang#, Xin Wen#, <strong>Yu-Shen Liu*</strong>, Yan-Pei Cao, Pengfei Wan, Wen Zheng, Zhizhong Han. SnowflakeNet: Point Cloud Completion by Snowflake Point Deconvolution with Skip-Transformer. <I>Proceedings of the IEEE/CVF International Conference on Computer Vision <strong>(ICCV)</strong></I>, 2021, pp. 5499-5509. (<strong><span style="color:red;">Oral presentation, ~3.4%</span> acceptance rate for Oral, ~25.9% overall acceptance rate</strong>)(CCF-A)
							<br />
							<a href="main/pdf/LiuYS_ICCV2021_SnowflakeNet.pdf">[PDF]&nbsp&nbsp</a>
							<a href="main/pdf/LiuYS_ICCV2021_SnowflakeNet-supp.pdf">[Supp]&nbsp&nbsp</a>
							<a href="https://openaccess.thecvf.com/content/ICCV2021/html/Xiang_SnowflakeNet_Point_Cloud_Completion_by_Snowflake_Point_Deconvolution_With_Skip-Transformer_ICCV_2021_paper.html">[Open access]&nbsp&nbsp</a>
							<a href="https://github.com/AllenXiangX/SnowflakeNet">[Github]&nbsp&nbsp</a>
							<a href="https://arxiv.org/abs/2108.04444">[ArXiv]</a>		
							<a href="https://mp.weixin.qq.com/s/E0Tu6Rr5KnshX6xLVlOXnw">[Media report]</a>	
						</td>
						</tr>
						<tr>
						<td><a href="main/big/LiuYS_ICCV2021_2DProjectionsMatching.jpg"><img src="main/big/LiuYS_ICCV2021_2DProjectionsMatching.jpg" alt="Neural" width="200"/></a></td>
						<td>
							<span class="sequence"></span>Chao Chen#, Zhizhong Han#, <strong>Yu-Shen Liu*</strong>, Matthias Zwicker. Unsupervised Learning of Fine Structure Generation for 3D Point Clouds by 2D Projections Matching. <I>Proceedings of the IEEE/CVF International Conference on Computer Vision <strong>(ICCV)</strong></I>, 2021, pp. 12466-12477. (<strong>~25.9% overall acceptance rate</strong>)(CCF-A)	
							<br />
							<a href="main/pdf/LiuYS_ICCV2021_2DProjectionsMatching.pdf">[PDF]&nbsp&nbsp</a>
							<a href="main/pdf/LiuYS_ICCV2021_2DProjectionsMatching-supp.pdf">[Supp]&nbsp&nbsp</a>
							<a href="https://openaccess.thecvf.com/content/ICCV2021/html/Chen_Unsupervised_Learning_of_Fine_Structure_Generation_for_3D_Point_Clouds_ICCV_2021_paper.html">[Open access]&nbsp&nbsp</a>
							<a href="https://github.com/chenchao15/2D_projection_matching">[Github]&nbsp&nbsp</a>
							<a href="https://arxiv.org/abs/2108.03746">[ArXiv]</a>	
							<a href="https://mp.weixin.qq.com/s/EyjbiPyRhWeXTJb1JsxfcQ">[Media report]</a>			
						</td>
						</tr>
						<tr>
						<td><a href="main/big/LiuYS_ACMMM2021_HVP.png"><img src="main/big/LiuYS_ACMMM2021_HVP.png" alt="Neural" width="200"/></a></td>
						<td>
							<span class="sequence"></span>Zhizhong Han, Xiyang Wang, <strong>Yu-Shen Liu*</strong>, Matthias Zwicker. Hierarchical View Predictor: Unsupervised 3D Global Feature Learning through Hierarchical Prediction among Unordered Views. <I>Proceedings of the 29th ACM International Conference on Multimedia <strong>(ACM MM)</strong></I>, 2021, 3862–3871. (<strong><span style="color: red;">Oral presentation, ~27.9%</span> overall acceptance rate</strong>)(CCF-A)		
							<br />
							<a href="main/pdf/LiuYS_ACMMM21_HVP.pdf">[PDF]&nbsp&nbsp</a>
							<a href="https://arxiv.org/abs/2108.03743">[ArXiv]</a>			
						</td>
						</tr>
						<tr>
						<td><a href="main/big/LiuYS_ICML2021_NeuralPull.jpg"><img src="main/big/LiuYS_ICML2021_NeuralPull.jpg" alt="Neural" width="200"/></a></td>
						<td>
							<span class="sequence"></span>Baorui Ma#, Zhizhong Han#, <strong>Yu-Shen Liu*</strong>, Matthias Zwicker. Neural-Pull: Learning Signed Distance Functions from Point Clouds by Learning to Pull Space onto Surfaces. <I>International Conference on Machine Learning <strong>(ICML)</strong></I>, 2021, PMLR 139: 7246-7257. (<strong>~21.4% overall acceptance rate</strong>)(CCF-A)
							<br />
							<a href="main/pdf/LiuYS_ICML21_NeuralPull.pdf">[PDF]&nbsp&nbsp</a>
							<a href="main/pdf/LiuYS_ICML21_NeuralPull_Supp.pdf">[Supp]&nbsp&nbsp</a>
							<a href="https://proceedings.mlr.press/v139/ma21b.html">[Proceedings]&nbsp&nbsp</a>
							<a href="https://github.com/mabaorui/NeuralPull">[Github]&nbsp&nbsp</a>
							<a href="http://arxiv.org/abs/2011.13495">[ArXiv]</a>						
						</td>
						</tr>
						<tr>
						<td><a href="main/big/LiuYS_CVPR_PMP-Net.png"><img src="main/big/LiuYS_CVPR_PMP-Net.png" alt="PMP" width="200"/></a></td>
						<td>
                            <span class="sequence"></span>Xin Wen, Peng Xiang, Zhizhong Han, Yan-Pei Cao,  Pengfei Wan, Wen Zheng, <strong>Yu-Shen Liu*</strong>. PMP-Net: Point Cloud Completion by Learning Multi-step Point Moving Paths. <I>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong></I>, 2021, pp. 7443-7452. (<strong>~27% overall acceptance rate</strong>)(CCF-A)
                            <p><font color='red'>Ranked <strong>3rd place in Multi-View Partial (MVP) Point Cloud Completion Challenge 2021</strong> at ICCV 2021  -  <a href='https://sense-human.github.io/'>The 3rd Workshop on Sensing, Understanding and Synthesizing Humans.</a></font></p>
							<a href="main/pdf/LiuYS_CVPR21_PMP-Net.pdf">[PDF]&nbsp&nbsp</a>
							<a href="main/pdf/LiuYS_CVPR21_PMP-Net-supp.pdf">[Supp]&nbsp&nbsp</a>
							<a href="https://openaccess.thecvf.com/content/CVPR2021/html/Wen_PMP-Net_Point_Cloud_Completion_by_Learning_Multi-Step_Point_Moving_Paths_CVPR_2021_paper.html">[Open access]&nbsp&nbsp</a>
							<a href="https://github.com/diviswen/PMP-Net">[Github]&nbsp&nbsp</a>
							<a href="https://arxiv.org/abs/2012.03408">[ArXiv]</a>	
							<a href="https://mp.weixin.qq.com/s/Bp68DWQ2_b6mpboVfDGqDg">[Media report]</a>					
						</td>
						</tr>

						<tr>
						<td><a href="main/big/LiuYS_CVPR_Cycle4Completion.png"><img src="main/big/LiuYS_CVPR_Cycle4Completion.png" alt="PMP" width="200"/></a></td>
						<td>
							<span class="sequence"></span>Xin Wen, Zhizhong Han, Yan-Pei Cao,  Pengfei Wan, Wen Zheng, <strong>Yu-Shen Liu*</strong>. Cycle4Completion: Unpaired Point Cloud Completion using Cycle Transformation with Missing Region Coding. <I>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong></I>, 2021, 13080-13089.(<strong>~27% overall acceptance rate</strong>)(CCF-A)
							<br />
							<a href="main/pdf/LiuYS_CVPR21_Cycle4Completion.pdf">[PDF]&nbsp&nbsp</a>
							<a href="https://openaccess.thecvf.com/content/CVPR2021/html/Wen_Cycle4Completion_Unpaired_Point_Cloud_Completion_Using_Cycle_Transformation_With_Missing_CVPR_2021_paper.html">[Open access]&nbsp&nbsp</a>
							<a href="https://github.com/diviswen/Cycle4Completion">[Github]&nbsp&nbsp</a>
							<a href="https://arxiv.org/abs/2103.07838">[ArXiv]</a>
						</td>
						</tr>

						<tr>
							<td><a href="main/big/LiuYS_TIP2021_FG3D-Net.png"><img src="main/big/LiuYS_TIP2021_FG3D-Net.png" alt="FG3D" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Xinhai Liu, Zhizhong Han, <strong>Yu-Shen Liu*</strong>, Matthias Zwicker. Fine-Grained 3D Shape Classification with Hierarchical Part-View Attentions. <I>IEEE Transactions on Image Processing <strong>(TIP)</strong></I>, 2021, 30: 1744-1758. (SCI, 2019 Impact factor: 9.34). (CCF-A)
								<p><font color='red'>Received the <strong>Best Open Graphics Benchmark Award</strong> in the field of the CAD/Graphics area in 2021, which is selected by Technical Committee on Computer Aided Design and Computer Graphics (TCCADCG) affiliated with the China Computer Federation(CCF)</font></p>
								<a href="main/pdf/LiuYS_TIP2021_FG3D-Net.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://github.com/liuxinhai/FG3D-Net">[Data Download]&nbsp&nbsp</a>
								<a href="https://ieeexplore.ieee.org/document/9318534">[IEEE Xplore]&nbsp&nbsp</a>
								<a href="https://arxiv.org/abs/2005.12541">[ArXiv]&nbsp&nbsp</a>
								<a href="https://mp.weixin.qq.com/s/e0YIzM-jcSWqGaD29_0XkA">[Media report]</a>						
							</td>
						</tr>
						<tr>
						<td><a href="main/big/tcvst_cmpd.png"><img src="main/big/tcvst_cmpd.png" alt="tcvst_cmpd" width="200"/></a></td>
						<td>
							<span class="sequence"></span>Xin Wen, Zhizhong Han, <strong>Yu-Shen Liu*</strong>. CMPD: Using Cross Memory Network with Pair Discrimination for Image-Text Retrieval. <I>IEEE Transactions on Circuits and Systems for Video Technology <strong>(TCSVT)</strong></I>, 2021, 31(6): 2427-2437.(SCI Journal Impact factor: <strong>4.685</strong>)(CCF-B)
							<br />
							<a href="main/pdf/LiuYS_TCSVT2021.pdf">[PDF]&nbsp&nbsp</a> 
							<a href="https://ieeexplore.ieee.org/document/9169915">[IEEE Xplore]&nbsp&nbsp</a>						
						</td>
						</tr>
						<tr>
						<td><a href="main/big/LiuYS_HeGeo_AUTCOM2021.png"><img src="main/big/LiuYS_HeGeo_AUTCOM2021.png" alt="autocom" width="200"/></a></td>
						<td>
							<span class="sequence"></span>Xiaoping Zhou, Mengmeng Wang, <strong>Yu-Shen Liu</strong>, Qian Wang, Maozu Guo, Jichao Zhao. Heterogeneous Network Modeling and Segmentation of Building Information Modeling Data for Parallel Triangulation and Visualization. <I>Automation in Construction</I>, 2021, 131: 103897, 1-13. (SCI, 2020 Impact factor: 7.7)
							<br />
							<a href="main/pdf/LiuYS_HeGeo_AUTCOM2021.pdf">[PDF]&nbsp&nbsp</a> 					
						</td>
						</tr>
					</table>

					<b>2020</b>
					<hr />
					<table cellpadding=5>
						<tr>
						<td><a href="main/big/LiuYS_Point2SpatialCapsule.png"><img src="main/big/LiuYS_Point2SpatialCapsule.png" alt="Point2SpatialCapsule" width="200"/></a></td>
						<td>
							<span class="sequence"></span>Xin Wen, Zhizhong Han, Xinhai Liu, <strong>Yu-Shen Liu*</strong>. Point2SpatialCapsule: Aggregating Features and Spatial Relationships of Local Regions on Point Clouds using Spatial-aware Capsules. <I>IEEE Transactions on Image Processing <strong>(TIP)</strong></I>, 2020, 29: 8855-8869. (SCI, 2019 Impact factor: 9.34)(CCF-A)
							<br />	
							<a href="main/pdf/LiuYS_TIP20Capsule.pdf">[PDF]&nbsp&nbsp</a>
							<a href="https://ieeexplore.ieee.org/document/9187572">[IEEE Xplore]&nbsp&nbsp</a>
                            <a href="https://arxiv.org/abs/1908.11026">[ArXiv]</a>
						</td>
						</tr>
						<tr>
						<td><a href="main/big/reconstructing_tip2020.png"><img src="main/big/reconstructing_tip2020.png" alt="reconstructing_tip2020" width="200"/></a></td>
						<td>
							<span class="sequence"></span>Zhizhong Han, Baorui Ma, <strong>Yu-Shen Liu*</strong>, Matthias Zwicker. Reconstructing 3D Shapes from Multiple Sketches using Direct Shape Optimization. <I>IEEE Transactions on Image Processing <strong>(TIP)</strong></I>, 2020, 29: 8721-8734. (SCI, 2019 Impact factor: 9.34)(CCF-A)
							<br />
							<a href="main/pdf/LiuYS_TIP20Sketch3D.pdf">[PDF]&nbsp&nbsp</a>
							<a href="https://ieeexplore.ieee.org/document/9184255">[IEEE Xplore]&nbsp&nbsp</a>
							<!-- <a href="video_page/driftvis-pre1208c01f.autosave_player.html">[Demo]&nbsp&nbsp</a> -->
							<a href="video_page/MS.mp4">[Demo]&nbsp&nbsp</a>			
						</td>
						</tr>
						<tr>
						<td><a href="main/big/acmmm_cfsis.png"><img src="main/big/acmmm_cfsis.png" alt="acmmm_cfsis" width="200"/></a></td>
						<td>
							<span class="sequence"></span>Xin Wen, Zhizhong Han, Geunhyuk Youk, <strong>Yu-Shen Liu*</strong>. CF-SIS: Semantic-Instance Segmentation of 3D Point Clouds by Context Fusion with Self-Attention. <I>Proceedings of the 28th ACM International Conference on Multimedia <strong>(ACM MM'20)</strong></I>, pp. 1661-1669.(<strong>~27.8% overall acceptance rate</strong>)(CCF-A)
							<br />	
							<a href="main/pdf/LiuYS_ACMMM20_CF-SIS.pdf">[PDF]&nbsp&nbsp</a>	
							<a href="https://dl.acm.org/doi/abs/10.1145/3394171.3413829">[DOI]&nbsp&nbsp</a>					
						</td>
						</tr>
						<tr>
						<td><a href="main/big/ShapeCaptioner.png"><img src="main/big/ShapeCaptioner.png" alt="ShapeCaptioner" width="200"/></a></td>
						<td>
							<span class="sequence"></span>Zhizhong Han, Chao Chen, <strong>Yu-Shen Liu*</strong>, Matthias Zwicker. ShapeCaptioner: Generative Caption Network for 3D Shapes by Learning a Mapping from Parts Detected in Multiple Views to Sentences. <I>Proceedings of the 28th ACM International Conference on Multimedia <strong>(ACM MM'20)</strong></I>, pp. 1018-1027.(<strong><span style="color: red;">Oral presentation, ~27.8%</span> overall acceptance rate</strong>)(CCF-A)
							<br />	
							<a href="main/pdf/LiuYS_ACMMM20_ShapeCaptioner.pdf">[PDF]&nbsp&nbsp</a>
							<a href="https://dl.acm.org/doi/10.1145/3394171.3413889">[DOI]&nbsp&nbsp</a>	
							<a href="https://arxiv.org/abs/1908.00120">[ArXiv]</a>						
						</td>	
						</tr>
						<tr>
						<td><a href="main/big/SeqXY2SeqZ.png"><img src="main/big/SeqXY2SeqZ.png" alt="SeqXY2SeqZ" width="200"/></a></td>
						<td>
							<span class="sequence"></span>Zhizhong Han, Guanhui Qiao, <strong>Yu-Shen Liu*</strong>, Matthias Zwicker. SeqXY2SeqZ: Structure Learning for 3D Shapes by Sequentially Predicting 1D Occupancy Segments From 2D Coordinates. <I>European Conference on Computer Vision <strong>(ECCV)</strong></I>, 2020, LNCS 12369, pp. 607–625.(<strong>~27% overall acceptance rate</strong>)(CCF-B)
							<br />
							 <a href="main/pdf/LiuYS_ECCV2020_SeqXY2SeqZ.pdf">[PDF]&nbsp&nbsp</a>
							 <a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123690596.pdf">[Open Access]&nbsp&nbsp</a>
							 <a href="https://arxiv.org/abs/2003.05559">[ArXiv]</a>.
						</td>
						</tr>
						<tr>
							<td><a href="main/big/DRWR_ICML2020.png"><img src="main/big/DRWR_ICML2020.png" alt="DRWR" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Zhizhong Han, Chao Chen, <strong>Yu-Shen Liu*</strong>, Matthias Zwicker. DRWR: A Differentiable Renderer without Rendering for Unsupervised 3D Structure Learning from Silhouette Images. <I>International Conference on Machine Learning <strong>(ICML)</strong></I>, 2020, PMLR 119:3994-4005.(<strong>~21.8% overall acceptance rate</strong>)(CCF-A)
								<br />
								<a href="main/pdf/LiuYS_ICML2020_DRWR.pdf">[PDF]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_ICML2020_DRWR-supp.pdf">[Supplementary]&nbsp&nbsp</a>
								<a href="http://proceedings.mlr.press/v119/han20b.html">[PMLR]&nbsp&nbsp</a>
								<a href="https://arxiv.org/abs/2007.06127">[Arxiv]&nbsp&nbsp</a>	
								<!-- <a href="main/pdf/LiuYS_CVPR20_SANet.pdf">[Paper]&nbsp&nbsp</a>	 <a href="main/pdf/LiuYS_CVPR20_SANet-supp.pdf">[Supplementary]&nbsp&nbsp</a> -->						
							</td>
						</tr>

						<tr>
							<td><a href="main/big/SP_Net_CVPR2020.png"><img src="main/big/SP_Net_CVPR2020.png" alt="SPNet++" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Xin Wen, Tianyang Li, Zhizhong Han, <strong>Yu-Shen Liu*</strong>. Point Cloud Completion by Skip-attention Network with Hierarchical Folding. <I>IEEE Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong></I>, 2020.(<strong>~22% overall acceptance rate</strong>)(CCF-A)
								<br />
								<a href="main/pdf/LiuYS_CVPR20_SANet.pdf">[PDF]&nbsp&nbsp</a>	 
								<a href="main/pdf/LiuYS_CVPR20_SANet-supp.pdf">[Supplementary]&nbsp&nbsp</a>    
								<a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Wen_Point_Cloud_Completion_by_Skip-Attention_Network_With_Hierarchical_Folding_CVPR_2020_paper.pdf">[Open Access]&nbsp&nbsp</a> 
								<a href="https://github.com/diviswen/sanet">[Source code]&nbsp&nbsp</a>
								<!-- <a href="https://arxiv.org/abs/2005.03871">[Arxiv]&nbsp&nbsp</a> -->
								<!-- <a href="main/pdf/LiuYS_CVPR20_SANet.pdf">[CVPR 2020]&nbsp&nbsp</a>	 <a href="main/pdf/LiuYS_CVPR20_SANet-supp.pdf">[Supplementary]&nbsp&nbsp</a> -->						
							</td>
						</tr>
						<tr>
							<td><a href="main/big/LRCNet.png"><img src="main/big/LRCNet.png" alt="LRCNet" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Xinhai Liu, Zhizhong Han, Fangzhou Hong, <strong>Yu-Shen Liu*</strong>, Matthias Zwicker. LRC-Net: Learning Discriminative Features on Point Clouds by Encoding Local Region Contexts. <I>Computer Aided Geometric Design</I>, 2020, 79: 101859. (SCI Journal Impact factor: <strong>1.382</strong>)(CCF-B)
								<br />
								<a href="main/pdf/LiuYS_CAGD20.pdf">[PDF]&nbsp&nbsp</a> 
								<a href="https://www.sciencedirect.com/science/article/pii/S0167839620300467">[ScienceDirect]&nbsp&nbsp</a> 
								<a href="https://www.youtube.com/watch?v=Ln1dOxY5Qwk">[Video]&nbsp&nbsp</a>
								<a href="https://arxiv.org/abs/2003.08240">[Arxiv]&nbsp&nbsp</a>							
							</td>
						</tr>
						<tr>
							<td><a href="main/big/BIMSeek++.png"><img src="main/big/BIMSeek++.png" alt="BIMSeek++" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Nanxing Li, Qian Li, <strong>Yu-Shen Liu*</strong>, Wenlong Lu, Wanqi Wang. BIMSeek++: Retrieving BIM Components using Similarity Measurement of Attributes. <I>Computers in Industry</I>, 2020, 116:103186, 1-12. (SCI Journal Impact factor: <strong>7.635</strong>)
								<br />	
								<a href="main/pdf/LiuYS_COMIND20_BIMSeek.pdf">[PDF]&nbsp&nbsp</a>							
							</td>
						</tr>
						<tr>
							<td><a href="main/big/BIMClustering.png"><img src="main/big/BIMClustering.png" alt="BIMClustering" width="150"/></a></td>
							<td>
								<span class="sequence"></span>Wan-Qi Wang, Bao-Rui Ma, Qian Li, Wen-Long Lu, <strong>Yu-Shen Liu</strong>. Clustering of BIM components based on similarity measurement of attributes. <I>Journal of Graphics</I>, 2020. (in Chinese)
								<br />	
								<a href="main/pdf/LiuYS_BIMClustering.pdf">[PDF]&nbsp&nbsp</a>							
							</td>
						</tr>
					</table>
					
					<b>2019</b>
					<hr />
					<table cellpadding=5>
						<tr>
							<td><a href="main/big/LiuYS_3D2SeqViews.png"><img src="main/big/LiuYS_3D2SeqViews.png" alt="3D2SeqViews" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Zhizhong Han, Honglei Lu, Zhenbao Liu, Chi-Man Vong, <strong>Yu-Shen Liu*</strong>, Matthias Zwicker, Junwei Han, C.L. Philip Chen. 3D2SeqViews: Aggregating Sequential Views for 3D Global Feature Learning by CNN with Hierarchical Attention Aggregation. <I>IEEE Transactions on Image Processing <strong>(TIP)</strong></I>, 2019, 28(8): 3986-3999 . (<b>SCI</b>, 2017 Impact factor: 5.071)(CCF-A)
								
								<br />
								<a href="https://ieeexplore.ieee.org/document/8666059">https://ieeexplore.ieee.org/document/8666059</a>	
								<br/>
								<a href="main/pdf/LiuYS_TIP19_3D2SeqViews.pdf">[Paper]&nbsp&nbsp</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/SeqViews2SeqLabels.png"><img src="main/small/SeqViews2SeqLabels.png" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Zhizhong Han, Mingyang Shang, Zhenbao Liu, Chi-Man Vong, <strong>Yu-Shen Liu*</strong>, Matthias Zwicker, Junwei Han, C.L. Philip Chen.  SeqViews2SeqLabels: Learning 3D Global Features via Aggregating Sequential Views by RNN with Attention. <i>IEEE Transactions on Image Processing <strong>(TIP)</strong></i>, 2019, 28(2): 658-672. (<b>SCI</b>, 2017 Impact factor: 5.071)(CCF-A)
								<br />
								<a href="https://ieeexplore.ieee.org/document/8453813/">https://ieeexplore.ieee.org/document/8453813/</a>	
								<br/>
								<a href="SeqViews2SeqLabels/index.html">[Project Page]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_TIP19RNN.pdf">[Paper]&nbsp&nbsp</a> 
								<a href="https://github.com/mingyangShang/SeqViews2SeqLabels">[Source code]&nbsp&nbsp</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/LiuYS_NeurIPS19_FLRML.png"><img src="main/big/LiuYS_NeurIPS19_FLRML.png" alt="Fast_Low-rank_ML" width="200"/></a></td>
							<td>
								<span class="sequence"></span> Han Liu, Zhizhong Han, <strong>Yu-Shen Liu*</strong>, Ming Gu. Fast Low-rank Metric Learning for Large-scale and High-dimensional Data. In <I>Neural Information Processing Systems <strong>(NeurIPS)</strong></I>, 2019, Vancouver, Canada.(<strong>~21.1% overall acceptance rate</strong>)(CCF-A)
								<!--<img class="new" src="main/img/new.gif"/>-->
								<br />	
								<a href="main/pdf/LiuYS_NeurIPS19_FLRML.pdf">[PDF]&nbsp&nbsp</a>	
								<a href="https://github.com/highan911/FLRML">[Source code]&nbsp&nbsp</a>
								<a href="https://arxiv.org/abs/1909.06297">[ArXiv]</a>
							</td>
						</tr>


						<tr>
							<td><a href="main/big/Point_Cloud_VAE.png"><img src="main/big/Point_Cloud_VAE.png" alt="Point_Cloud_VAE" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Zhizhong Han, Xiyang Wang, <strong>Yu-Shen Liu*</strong>, Matthias Zwicker. Multi-Angle Point Cloud-VAE: Unsupervised Feature Learning for 3D Point Clouds from Multiple Angles by Joint Self-Reconstruction and Half-to-Half Prediction. In <I>IEEE International Conference on Computer Vision <strong>(ICCV)</strong></I>, 2019, pp. 10441-10450.(<strong>~25% overall acceptance rate</strong>)(CCF-A)
								<br />	
								<a href="main/pdf/LiuYS_ICCV19_MAP.pdf">[PDF]&nbsp&nbsp</a>	
								<a href="https://openaccess.thecvf.com/content_ICCV_2019/html/Han_Multi-Angle_Point_Cloud-VAE_Unsupervised_Feature_Learning_for_3D_Point_Clouds_ICCV_2019_paper.html">[Open Access]&nbsp&nbsp</a>						
							</td>
						</tr>
						<tr>
							<td><a href="main/big/LiuYS_L2GAutoencoder.png"><img src="main/big/LiuYS_L2GAutoencoder.png" alt="L2GAutoencoder" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Xinhai Liu, Zhizhong Han, Xin Wen, <strong>Yu-Shen Liu*</strong>, Matthias Zwicker. L2G Auto-encoder: Understanding Point Clouds by Local-to-Global Reconstruction with Hierarchical Self-Attention. In <I>Proceedings of the 27th ACM International Conference on Multimedia <strong>(ACM MM'19)</strong></I>, 2019, pp. 989-997 (<strong><span style="color: red;">Oral presentation, ~26.5%</span> overall acceptance rate</strong>)(CCF-A)
								
								<br/> <a href="https://dl.acm.org/citation.cfm?doid=3343031.3350960">[DOI]</a>	
								<a href="main/pdf/LiuYS_ACMMM19_L2G_AE.pdf">[PDF]&nbsp&nbsp</a>	
								<a href="https://github.com/liuxinhai/L2G-AE">[Source code]&nbsp&nbsp</a>						
							</td>
						</tr>
						<tr>
							<td><a href="main/big/LiuYS_Parts4Feature.png"><img src="main/big/LiuYS_Parts4Feature.png" alt="Parts4Feature" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Zhizhong Han, Xinhai Liu, <strong>Yu-Shen Liu*</strong>, Matthias Zwicker. Parts4Feature: Learning 3D Global Features from Generally Semantic Parts in Multiple Views. In <I>International Joint Conference on Artificial Intelligence <strong>(IJCAI)</strong></I>, 2019, pp. 766-773 (<strong><span style="color: red;">Oral presentation, ~13.6%</span> overall acceptance rate</strong>)(CCF-A)
								
								<br/> <a href="https://doi.org/10.24963/ijcai.2019/108">[DOI]</a>	
 								      <a href="main/pdf/497_ijcai19_Parts4Feature.pdf">[PDF]&nbsp&nbsp</a>								
							</td>
						</tr>
						<tr>
							<td><a href="main/big/LiuYS_3D2ViewGraph.png"><img src="main/big/LiuYS_3D2ViewGraph.png" alt="3D2ViewGraph" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Zhizhong Han, Xiyang Wang, Chi-Man Vong, <strong>Yu-Shen Liu*</strong>, Matthias Zwicker, C.L. Philip Chen. 3DViewGraph: Learning Global Features for 3D Shapes from A Graph of Unordered Views with Attention. In <I>International Joint Conference on Artificial Intelligence <strong>(IJCAI)</strong></I>, 2019, pp. 758-765(<strong><span style="color: red;">Oral presentation, ~13.6%</span> overall acceptance rate</strong>)(CCF-A)
								
								<br/> <a href="https://doi.org/10.24963/ijcai.2019/107">[DOI]</a>
								
								<a href="main/pdf/487_ijcai19_3DViewGraph.pdf">[PDF]&nbsp&nbsp</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/VIPGAN.png"><img src="main/big/VIPGAN.png" alt="VIPGAN" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Zhizhong Han, Mingyang Shang, <strong>Yu-Shen Liu*</strong>, Matthias Zwicker. View Inter-Prediction GAN: Unsupervised Representation Learning for 3D Shapes by Learning Global Shape Memories to Support Local View Predictions. In <I>33rd AAAI Conference on Computing on Artificial Intelligence <strong>(AAAI-19)</strong></I>, 2019, 33(01): 8376-8384.  (<strong><span style="color: red;">Spotlight presentation, ~16.2%</span> overall acceptance rate</strong>)(CCF-A)
								
								<br/> <a href="https://aaai.org/ojs/index.php/AAAI/article/view/4852">https://aaai.org/ojs/index.php/AAAI/article/view/4852</a>
								<br /><a href="VIPGAN/index.html">[Project Page]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_AAAI19_VIPGAN.pdf">[PDF]&nbsp&nbsp</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/Y^2Seq2Seq.png"><img src="main/big/Y^2Seq2Seq.png" alt="Y^2Seq2Seq" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Zhizhong Han, Mingyang Shang, Xiyang Wang, <strong>Yu-Shen Liu*</strong>, Matthias Zwicker. Y^2Seq2Seq: Cross-Modal Representation Learning for 3D Shape and Text by Joint Reconstruction and Prediction of View and Word Sequences. In <I>33rd AAAI Conference on Computing on Artificial Intelligence <strong>(AAAI-19)</strong></I>, 2019, 33(01): 126-133. (<strong><span style="color: red;">Oral presentation, ~16.2%</span> overall acceptance rate</strong>)(CCF-A)
								
								<br/> <a href="https://aaai.org/ojs/index.php/AAAI/article/view/3777">https://aaai.org/ojs/index.php/AAAI/article/view/3777</a>
								<br /><a href="Y2Seq2Seq/index.html">[Project Page]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_AAAI19_Y2Seq2Seq.pdf">[Paper]&nbsp&nbsp</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/Point2Sequence.png"><img src="main/big/Point2Sequence.png" alt="Point2Sequence" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Xinhai Liu, Zhizhong Han, <strong>Yu-Shen Liu*,</strong> Matthias Zwicker. Point2Sequence: Learning the Shape Representation of 3D Point Clouds with an Attention-based Sequence to Sequence Network. In <I>33rd AAAI Conference on Computing on Artificial Intelligence <strong>(AAAI-19)</strong></I>, 2019, 33(01): 8778-8785. (<strong><span style="color: red;">Oral presentation, ~16.2%</span> overall acceptance rate</strong>)(CCF-A)
								
								<br/> <a href="https://aaai.org/ojs/index.php/AAAI/article/view/4903">https://aaai.org/ojs/index.php/AAAI/article/view/4903</a>	
								<br /><a href="Point2Sequence/index.html">[Project Page]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_AAAI19_Point2Sequence.pdf">[Paper]&nbsp&nbsp</a>
								<a href="https://github.com/liuxinhai/Point2Sequence">[Source code]&nbsp&nbsp</a>

							</td>
						</tr>
						<tr>
							<td><a href="main/big/Story.png"><img src="main/big/Story.png" alt="Story" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Nanxing Li, Bei Liu, Zhizhong Han, <strong>Yu-Shen Liu*</strong>, Jianlong Fu. Emotion Reinforced Visual Storytelling. <I> ACM International Conference on Multimedia Retrieval <strong>(ICMR)</strong></I>, 2019, pp.297-305, Ottawa, ON, Canada.(<span style="color: red;">Oral presentation</span>)(CCF-B)
							
								<br />
								<a href="https://dl.acm.org/citation.cfm?id=3325050&preflayout=tabs">https://dl.acm.org/citation.cfm?id=3325050&preflayout=tabs</a>	
								<br/>
								<a href="main/pdf/LiuYS_ICMR19.pdf">[Paper]&nbsp&nbsp</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/CMST.png"><img src="main/big/CMST.png" alt="CMST" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Xin Wen, Zhizhong Han, Xinyu Yin, <strong>Yu-Shen Liu*</strong>. Adversarial Cross-Modal Retrieval via Learning and Transferring Single-Modal Similarities. In <I>IEEE International Conference on Multimedia and Expo <strong>(ICME)</strong></I>, 2019, pp.478-483.(<span style="color: red;">Oral presentation</span>)(CCF-B)
								
								<br /><a href="main/pdf/LiuYS_ICME19_CMST.pdf">[Paper]&nbsp&nbsp</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/VCIBA.png"><img src="main/big/VCIBA.png" alt="VCIBA" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Hong-Lei Lu, Jia-Xing Wu, <strong>Yu-Shen Liu*</strong>, Wan-Qi Wang. Dynamically loading IFC models on a web browser based on spatial semantic partitioning. In <I>Visual Computing for Industry Biomedicine, and Art</I>, 2019, 2:4.
								
								<br /><a href="main/pdf/LiuYS_VCIBA19IFC.pdf">[Paper]&nbsp&nbsp</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/GIS+BIM.png"><img src="main/big/GIS+BIM.png" alt="GIS+BIM" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Pengfei Wu, <strong>Yu-Shen Liu</strong>, Yi Tan, Jianfeng Li. Advances and Trends of Integration between GIS and BIM. In <I>Geomatics & Spatial Information Technology</I>, 2019, 42(1): 1-6. (in Chinese)
								
								<br /><a href="main/pdf/LiuYS_GIS+BIM-19.pdf">[Paper]&nbsp&nbsp</a>
							</td>
						</tr>


					</table>
					<b>2018</b>
					<hr />
					<table cellpadding=5>
						<tr>
							<td><a href="main/big/DeepSpatiality.png"><img src="main/small/DeepSpatiality.png" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Zhizhong Han, Zhenbao Liu, Chi-Man Vong, <strong>Yu-Shen Liu*</strong>,  Shuhui Bu, Junwei Han, C.L. Philip Chen.  Deep Spatiality: Unsupervised Learning of Spatially-Enhanced Global and Local 3D Features by Deep Neural Network with Coupled Softmax. <i>IEEE Transactions on Image Processing <strong>(TIP)</strong></i>, 2018, 27(6): 3049-3063. (<b>SCI</b>, 2017 Impact factor: 5.071)(CCF-A)
								<br />
								<a href="main/pdf/LiuYS_TIP18DS.pdf">[Paper]&nbsp&nbsp</a> 
							</td>
						</tr>
						<tr>
							<td><a href="main/big/ifcdiff.jpg"><img src="main/small/ifcdiff.jpg" alt="IFCdiff" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Xin Shi, <strong>Yu-Shen Liu*</strong>, Ge Gao, Ming Gu, Haijiang Li. IFCdiff: A content-based automatic comparison approach for IFC files. <i>Automation in Construction</i>, 2018, 86: 53-68.  (SCI Journal Impact factor: <strong>7.700</strong>)
								<br/>
								<!-- <a href="main/pdf/LiuYS_VIV15Neucom2.pdf">[Paper]&nbsp&nbsp</a> -->
								<a href="ifcdiff/index.html">[Project Page]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_AIC18IFCdiff.pdf">[Paper]&nbsp&nbsp</a>
								<!--<a href="main/bibtex/Liu15BIMTag.txt">[Bib]&nbsp&nbsp</a>-->
							</td>
						</tr>
					</table>
					<b>2017</b>
					<hr />
					<table cellpadding=5>
						<tr>
							<td><a href="main/big/tip.png"><img src="main/small/tip.png" alt="han_tip" width="200"/></a-></td>
							<td>
								<span class="sequence"></span> Zhizhong Han, Zhenbao Liu, Chi-Man Vong, <strong>Yu-Shen Liu*</strong>, Shuhui Bu, Junwei Han, C.L. Philip Chen. BoSCC: Bag of Spatial Context Correlations for Spatially Enhanced 3D Shape Representation. <i>IEEE Transactions on Image Processing <strong>(TIP)</strong></i>, 2017, 26(8): 3707-3720. (SCI Journal Impact factor: <strong>10.215</strong>)(CCF-A)
								<br/>
								<a href="main/pdf/LiuYS_TIP17BoSCC.pdf">[Paper]&nbsp&nbsp</a>
								<br/>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/Figure_ESA.jpg"><img src="main/small/Figure_ESA.jpg" alt="liu_tii" width="200"/></a-></td>
							<td>
								<span class="sequence"></span>Han Liu, <strong>Yu-Shen Liu*</strong>, Pieter Pauwels, Hongling Guo, Ming Gu. Enhanced explicit semantic analysis for product model retrieval in construction industry. <i>IEEE Transactions on Industrial Informatics</i>, 2017, 13(6): 3361-3369 (<b>SCI</b>, 2016 Impact factor: 6.764)
								<br/>
								<a href="main/pdf/LiuYS_TII17ESA.pdf">[Paper]&nbsp&nbsp</a>
								<a href="https://github.com/highan911/wikiprep-esa">[Source code]&nbsp&nbsp</a>
								<br/>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/bimtag.png"><img src="main/small/bimtag.png" alt="BIMTag" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Ge Gao, <strong>Yu-Shen Liu*</strong>, Pengpeng Lin, Meng Wang, Ming Gu, Jun-Hai Yong. BIMTag: Concept-based automatic semantic annotation of online BIM product resources. <i>Advanced Engineering Informatics</i>, 2017, 31: 48-61. (Special issue of EG-ICE 2014). (SCI Journal Impact factor: <strong>5.603</strong>)(CCF-B)
								<br/>
								<a href="bimtag/index.html">[Project Page]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_AEI17BIMTag.pdf">[Paper]&nbsp&nbsp</a>
								<a href="main/bibtex/Liu17BIMTag.txt">[Bib]&nbsp&nbsp</a>
							</td>
						</tr>
					</table>
					<b>2016</b>
					<hr />
					<table cellpadding=5>
						<tr>
							<td><a href="main/big/LiuYS_VIV15Neucom2.png"><img src="main/small/LiuYS_VIV15Neucom2.png" alt="VIV15Neucom2" width="200"/></a></td>
							<td>
								<span class="sequence"></span><strong>Yu-Shen Liu</strong>, Hongchen Deng, Min Liu, Lianjie Gong. VIV: Using visible internal volume to compute junction-aware shape descriptor of 3D articulated models. <i>Neurocomputing</i>, 2016,215: 32-47. (SCI Impact factor: <strong>5.719</strong>)
								<p>Special Issue on Stereo data sensing, computation and perception
								</p>
								<a href="main/pdf/LiuYS_Neucom16VIV.pdf">[Paper]&nbsp&nbsp</a>
								<!--<a href="main/bibtex/Liu15BIMTag.txt">[Bib]&nbsp&nbsp</a>-->
							</td>
						</tr>
						<tr>
							<td><a href="main/big/icccbe2016_364.jpg"><img src="main/small/icccbe2016_364.jpg" alt="ICCCBE2016" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Ge Gao, <strong>Yu-Shen Liu*,</strong> Jia-Xing Wu, Ming Gu, Xu-Kun Yang, Hua-Liang Li. IFC Railway: A Semantic and Geometric Modeling Approach for Railways based on IFC. In <I>16th International Conference on Computing in Civil and Building Engineering (ICCCBE2016)</I>, 2016, Japan. (<strong><span style="color: red;">Best Student Presentation Award</span></strong>)
								<br/><a href="main/pdf/GaoGe_ICCCBE2016_364.pdf">[Paper]&nbsp&nbsp</a>
							</td>
						</tr>
					</table>
					<b>2015</b>
					<hr />
					<table cellpadding=5>
						<tr>
							<td><a href="main/big/ifcqe.png"><img src="main/small/ifcqe.png" alt="IFCOntoSearch" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Ge Gao, <strong>Yu-Shen Liu*</strong>, Meng Wang, Ming Gu, Jun-Hai Yong. A query expansion method for retrieving online BIM resources based on Industry Foundation Classes. <i>Automation in Construction</i>, 2015, 56: 14–25. (SCI Impact factor: <strong>7.700</strong>)
								
								
								<br/>
								<a href="ifcqe/index.html">[Project Page]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_AIC15IFCQE.pdf">[Paper]&nbsp&nbsp</a>
								<a href="main/bibtex/Liu15IFCQE.txt">[Bib]&nbsp&nbsp</a>

							</td>
						</tr>					
						<tr>
							<td><a href="main/big/compressor.jpg"><img src="main/small/compressor.jpg" alt="IFCCompressor" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Jing Sun, <strong>Yu-Shen Liu*</strong>, Ge Gao, Xiao-Guang Han. IFCCompressor: A content-based compression algorithm for optimizing Industry Foundation Classes files. <i>Automation in Construction</i>, 2015, 50: 1-15. (SCI Impact factor: <strong>7.700</strong>)
								
								
								<br/>
								<a href="IFCCompressor/index.html">[Project Page]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_AIC15IFCCompressor.pdf">[Paper]&nbsp&nbsp</a>
								<a href="main/bibtex/Liu15IFCCompressor.txt">[Bib]&nbsp&nbsp</a>
								<a href="IFCCompressor/IFCCompressor-Code.zip">[Source code]&nbsp&nbsp</a>
							</td>
						</tr>

						<tr>
							<td><a href="main/big/LiuYS_SignalProcessing.png"><img src="main/small/LiuYS_SignalProcessing.png" alt="Junction-aware" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Jinlong Feng, <strong>Yu-Shen Liu*</strong>, Lianjie Gong. Junction-aware shape descriptor for 3D articulated models using local shape-radius variation. <I>Signal Processing,</I> 2015, 112: 4-16. (SCI Impact factor: <strong>4.662</strong>) 
								
								
								<br/>
								<a href="ShapeRadius/index.html">[Project Page]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_SP15Junction.pdf">[Paper]&nbsp&nbsp</a>
								<a href="main/bibtex/Liu15SigPro.txt">[Bib]&nbsp&nbsp</a>

							</td>
						</tr>

						<tr>
							<td><a href="main/big/LiuYS_TSWJ14RBIM.png"><img src="main/small/LiuYS_TSWJ14RBIM.png" alt="TSWJ14RBIM" width="200"/></a></td>
							<td>
								<span class="sequence"></span><strong>Yu-Shen Liu</strong>, Heng Li, Haijiang Li, Pieter Pauwels, Jakob Beetz. Recent Advances on Building Information Modeling. <I>The Scientific World Journal</I>, vol. 2015, Article ID 786598, 2 pages, 2015. doi:10.1155/2015/786598. (<b>Editorial</b>) (<b>SCI</b>, 2013 Impact factor: 1.219)
								
								<br/>
								<a href="main/pdf/LiuYS_TSWJ14RBIM.pdf">[Paper]&nbsp&nbsp</a>
								<a href="main/pdf/Recent_Advances_on_Building_Information_Modeling_2015.pdf">[Special Issue]&nbsp&nbsp</a>
								<!--<a href="main/bibtex/Liu15SigPro.txt">[Bib]&nbsp&nbsp</a>-->

							</td>
						</tr>
					</table>
					<b>2014</b>
					<hr />
					<table cellpadding=5>
						<tr>
							<td><a href="main/big/BIMTagBig.png"><img src="main/small/BIMTag.jpg" alt="" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Ge Gao, <strong>Yu-Shen Liu*, </strong>Meng Wang, Xiao-Guang Han. BIMTag: Semantic Annotation of Web BIM Product Resources Based on IFC Ontology. In: 21st International Workshop of the European Group for Intelligent Computing in Engineering (EG-ICE 2014), July, 2014 Cardiff, United Kingdom. ISBN: 978-0-9930807-0-8 (EI: 20144900283797). (invitation for extended version submission to <I>Advanced Engineering Informatics</I>)
								<br/><a href="main/pdf/EGICE2014_BIMTag_final2.pdf">[Paper]&nbsp&nbsp</a>
							</td>
						</tr>
					</table>
					<b>2013</b>
					<hr />
					<table cellpadding=5>
						<tr>
							<td><a href="main/big/ifcpath.jpg"><img src="main/small/ifcpath.jpg" alt="The IFC-based path planning for 3D indoor spaces" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Ya-Hong Lin, <strong>Yu-Shen Liu*</strong>, Ge Gao, Xiao-Guang Han, Cheng-Yuan Lai, Ming Gu. The IFC-based path planning for 3D indoor spaces. <i>Advanced Engineering Informatics</i>, 2013; 27(2): 189-205. (<b>SCI</b>, 2013 Impact factor: 2.068) (<strong><span style="color:red;">Highly Cited Research Award</span></strong>)(CCF-B)

								<br/>
								<a href="ifcpath/index.html">[Project Page]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_AEI12IFC.pdf">[Paper]&nbsp&nbsp</a>
								<a href="https://github.com/kinmyy/THUIFCer">[Code]&nbsp&nbsp</a>
								<a href="main/bibtex/Liu13ifc.txt">[Bib]&nbsp&nbsp</a>

							</td>
						</tr>
						<tr>
							<td><a href="main/big/ACDT.jpg"><img src="main/small/ACDT.jpg" alt="" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Dongxing Cao, Shengfeng Qin, <strong>Yu-Shen Liu*</strong>. Advances in Conceptual Design Theories, Methodologies, and Applications. <i>Advances in Mechanical Engineering</i>, 2013; Article ID 207492, page 1-3. doi:10.1155/2013/207492. (<b>SCI</b>, 2012 Impact factor:1.062)<br/>
								Special Issue: <br/><a href="http://www.hindawi.com/journals/ame/si/293862/">http://www.hindawi.com/journals/ame/si/293862/</a>						
								<br/><a href="main/pdf/LiuYS_AME13ACDT.pdf">[Paper]&nbsp&nbsp</a>
								<a href="main/bibtex/Liu13AME.txt">[Bib]&nbsp&nbsp</a>
							</td>
						</tr>
					</table>
					<b>2012</b>
					<hr />
					<table cellpadding=5>
						<tr>
							<td><a href="main/big/CAD-S-11-00319.png"><img src="main/small/CAD-S-11-00319.png" alt="Robust shape normalization of 3D articulated volumetric models" width="200"/></a></td>
							<td>
									<span class="sequence"></span>Chao Wang, <strong>Yu-Shen Liu</strong>, Min Liu, Jun-Hai Yong, Jean-Claude Paul. Robust shape normalization of 3D articulated volumetric models. <i>Computer-Aided Design</i>, 2012; 44(12): 1253-1268. (<strong>SCI</strong>, Impact factor: 1.234)(CCF-B).							
								<br/><a href="main/pdf/LiuYS_CAD12Norm.pdf">[Paper]&nbsp&nbsp</a>
								<a href="main/bibtex/Liu12cad.txt">[Bib]</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/3dmolnavi.jpg"><img src="main/small/3dmolnavi.jpg" alt="3DMolNavi: A navigation system for flexible molecular shape retrieval based on histogram and dimensionality reduction" width="200"/></a></td>
							<td>
									<span class="sequence"></span><strong>Yu-Shen Liu</strong>, Meng Wang, Jean-Claude Paul, Karthik Ramani. 3DMolNavi: A web-based retrieval and navigation tool for flexible molecular shape comparison.<i>BMC Bioinformatics</i>, 2012, 13:95. (<strong>SCI</strong>, Impact factor: 3.029).<br/><a href="http://www.biomedcentral.com/1471-2105/13/95">http://www.biomedcentral.com/1471-2105/13/95</a>
								<br/><a href="3dmolnavi/index.html">[Project Page]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_BMC12molnavi.pdf">[Paper]&nbsp&nbsp</a>
								<a href="main/bibtex/Liu12bmcNavi.txt">[Bib]</a>
							</td>
						</tr>
					</table>
					<b>2011</b>
					<hr />
					<table cellpadding=5>
						<tr>
							<td><a href="main/big/LiuYS_PAMI11ID.png"><img src="main/small/LiuYS_PAMI11ID.png" alt="Computing the inner distances of volumetric models for articulated 
								shape description with a visibility graph." width="200"/></a></td>
							<td>
								<span class="sequence"></span><strong>Yu-Shen Liu</strong>, Karthik Ramani, Min Liu. Computing the inner distances of volumetric models for articulated shape description with a visibility graph. <i>IEEE Transactions on Pattern Analysis and Machine Intelligence <strong>(TPAMI)</strong></i>, 2011, 33(12): 2538-2544. (<strong>SCI</strong> , Impact factor: 4.908) (CCF-A)
								<br/>
								<a href="vmid/vmid_index.html">[Project Page]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_PAMI11ID.pdf">[Paper]&nbsp&nbsp</a>
								<a href="main/bibtex/Liu11pami.txt">[Bib]</a>
							</td>
						</tr>
					</table>
					<b>2010</b>
					<hr />
					<table cellpadding=5>
						<tr>
							<td><a href="main/big/LiuYS_BMC10diffusion.png"><img src="main/small/LiuYS_BMC10diffusion.png" alt="Using diffusion distances for flexible molecular shape comparison." width="200"/></a></td>
							<td>
								<span class="sequence"></span><strong>Yu-Shen Liu</strong>, Qi Li, Guo-Qin Zheng, Karthik Ramani, William Benjamin. Using diffusion distances for flexible molecular shape comparison. <i>BMC Bioinformatics</i>, 2010, 11:480 (<strong>SCI</strong>, Impact factor: 3.029)	
								<br/><a href="main/pdf/LiuYS_BMC10diffusion.pdf">[Paper]&nbsp&nbsp</a>
								<a href="main/bibtex/Liu10bmcDiff.txt">[Bib]</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/LiuYS_PR10VolArea.png"><img src="main/small/LiuYS_PR10VolArea.png" alt="Surface area estimation of digitized 3D objects using quasi-Monte Carlo methods."  width="200"/></a></td>
							<td>
								<span class="sequence"></span><strong>Yu-Shen Liu</strong>, Jing Yi, Hu Zhang, Guo-Qin Zheng, Jean-Claude Paul. Surface area estimation of digitized 3D objects using quasi-Monte Carlo methods. <i>Pattern Recognition</i>, 2010, 43(11): 3900-3909 (<strong>SCI</strong>, Impact factor: 2.682)(CCF-B).
								<br/><a href="main/pdf/LiuYS_PR10VolArea.pdf">[Paper]&nbsp&nbsp</a>
								<a href="main/bibtex/Liu10PR.txt">[Bib]</a>
							</td>
						</tr>
					</table>
					<b>2009</b>
					<hr />
					<table cellpadding=5>
						<tr>
							<td>
								<a href="main/big/LiuYS_BMC09IDSS.png"><img src="main/small/LiuYS_BMC09IDSS.png" alt="IDSS: deformation invariant signatures for molecular shape comparison" width="200" /></a> 
							</td>
							<td>
									<span class="sequence"></span><strong>Yu-Shen Liu</strong>, Yi Fang, Karthik Ramani. IDSS: deformation invariant signatures for molecular shape comparison, <i>BMC Bioinformatics</i>, 2009, 10:157 (<strong>SCI</strong>, Impact factor: 3.029). <br/>
									<a href="idss/idss_index.html">[Project Page]&nbsp&nbsp</a>
									<a href="main/pdf/LiuYS_BMC09IDSS.pdf">[Paper]&nbsp&nbsp</a>
									<a href="main/bibtex/Liu09bmcIDSS.txt">[Bib]</a>
							</td>
							
						</tr>
						<tr>
							<td>
								<a href="main/big/LiuYS_CAD09Min.png"><img src="main/small/LiuYS_CAD09Min.png" alt="Computing global visibility maps for regions on the boundaries of polyhedra using Minkowski sums" width="200"/></a>
							</td>
							<td>
								<span class="sequence"></span>Min Liu, <strong>Yu-Shen Liu</strong>, Karthik Ramani. Computing global visibility maps for regions on the boundaries of polyhedra using Minkowski sums. <i>Computer-Aided Design</i>, 2009; 41(9): 668-680 (<strong>SCI</strong>, Impact factor: 1.542)(CCF-B)
								<br/><a href="main/pdf/LiuYS_CAD09Min.pdf">[Paper]&nbsp&nbsp</a>
								<a href="main/bibtex/Liu09Min.txt">[Bib]</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/LiuYS_BMC09Fang.png"><img src="main/small/LiuYS_BMC09Fang.png" alt="Three dimensional shape comparison of flexible protein using the local-diameter descriptor" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Yi Fang, <strong>Yu-Shen Liu</strong>, Karthik Ramani. Three dimensional shape comparison of flexible protein using the local-diameter descriptor, <i>BMC Structural Biology</i>, 2009, 9:29 (<strong>SCI</strong>, Impact factor: 2.258) <br/>
								<a href="https://engineering.purdue.edu/PRECISE/LDD">[Project Page]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_09Fang.pdf">[Paper]&nbsp&nbsp</a>
								<a href="main/bibtex/Liu09Fang.txt">[Bib]</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/LiuYS_BMC09LMSfit.png"><img src="main/small/LiuYS_BMC09LMSfit.png" alt="Using least median of squares for structural superposition of flexible proteins" width="200" /></a></td>
							<td>
								<span class="sequence"></span><strong>Yu-Shen Liu</strong>, Yi Fang, Karthik Ramani. Using least median of squares for structural superposition of flexible proteins. <i>BMC Bioinformatics</i>, 2009, 10:29 (<strong>SCI</strong>, Impact factor: 3.029). <br/>
							<a href="https://engineering.purdue.edu/PRECISE/LMSfit">[Project Page]&nbsp&nbsp</a>
							<a href="main/pdf/LiuYS_BMC09LMSfit.pdf">[Paper]&nbsp&nbsp</a>
							<a href="main/bibtex/Liu09bmcLMS.txt">[Bib]</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/LiuYS_CAD08RPCA.png"><img src="main/small/LiuYS_CAD08RPCA.png" alt="Robust principal axes determination for point-based shapes using least median of squares." width="200"/></a></td>
							<td>
								<span class="sequence"></span><strong>Yu-Shen Liu</strong>, Karthik Ramani. Robust principal axes determination for point-based shapes using least median of squares. <i>Computer-Aided Design</i>, 2009; 41(4): 293-305 (<strong>SCI</strong>, Impact factor: 1.542)(CCF-B)
								<br/><a href="main/pdf/LiuYS_CAD08RPCA.pdf">[Paper]&nbsp&nbsp</a>
								<a href="main/bibtex/Liu09cad.txt">[Bib]</a>
							</td>
						</tr>
					</table>
					<b>2008</b>
					<hr />
					<table cellpadding=5>
						<tr>
							<td><a href="main/big/LiuYS_CAD08projection.png"><img src="main/small/LiuYS_CAD08projection.png" alt="An extension on robust directed projection of points onto point clouds." width="200" /></a></td>
							<td>
								<span class="sequence"></span>Ming-Cui Du, <strong>Yu-Shen Liu</strong>. An extension on robust directed projection of points onto point clouds. <i>Computer-Aided Design</i>, 2008; 40(5):537-553. (<strong>SCI</strong>, Impact factor: 1.542)(CCF-B). 	
								<br/><a href="main/pdf/LiuYS_CAD08projection.pdf">[Paper]&nbsp&nbsp</a>
								<a href="main/bibtex/Liu08CAD.txt">[Bib]</a>
							</td>
						</tr>
					</table>
					<b>2007</b>
					<hr />
					<table cellpadding=5>
						<tr>
							<td></td>
							<td>
								<span class="sequence"></span><strong>Yu-Shen Liu</strong>, Min Liu, Daisuke Kihara, Karthik Ramani. Salient critical points for meshes. <i>In Proceedings of the 2007 ACM symposium on Solid and physical modeling (SPM'07)</i>, 277-282, June 2007, Beijing, China.(CCF-B)
							<br/><a href="main/pdf/LiuYS_SPM07CriticalPoints.pdf">[Paper]&nbsp&nbsp</a>
							<a href="main/bibtex/Liu07spm.txt">[Bib]&nbsp&nbsp</a>
							</td>
						</tr>
						<tr>
							<td></td>
							<td>
								<span class="sequence"></span>Min Liu, <strong>Yu-Shen Liu</strong>, Karthik Ramani. Anisotropic filtering on normal field and curvature tensor field using optimal estimation theory. <I>In Proceedings of the IEEE International Conference on Shape Modeling and Applications 2007 (SMI'07)</I>, 169-178, June 2007, Lyon, France.
							<br/><a href="main/pdf/LiuYS_SMI07Min.pdf">[Paper]&nbsp&nbsp</a>
							</td>
						</tr>
					</table>
					<b>2006</b>
					<hr />
					<table cellpadding=5>
						<tr>
							<td><a href="main/big/LiuYS_CAD06projection.png"><img src="main/small/LiuYS_CAD06projection.png" alt="Automatic least-squares projection of points onto point clouds with applications in reverse engineering"  width="200"/></a></td>
							<td>
								<span class="sequence"></span><strong>Yu-Shen Liu</strong>, Jean-Claude Paul, Jun-Hai Yong, Pi-Qiang Yu, Hui Zhang, Jia-Guang Sun, Karthik Ramani. Automatic least-squares projection of points onto point clouds with applications in reverse engineering. <i>Computer-Aided Design</i>, 2006; 38(12): 1251-1263. (<strong>SCI</strong>, Impact factor: 1.542)(CCF-B)
								<br/><a href="main/pdf/LiuYS_CAD06projection.pdf">[Paper]&nbsp&nbsp</a>
								<a href="main/bibtex/Liu06-LSP.txt">[Bib]</a>
							</td>
							
						</tr>
						<tr>
							<td><a href="main/big/LiuYS_CAD06area.png"><img src="main/small/LiuYS_CAD06area.png" alt="A quasi-Monte Carlo method for computing areas of point-sampled surfaces" width="200"/></a></td>
							<td>
								<span class="sequence"></span><strong>Yu-Shen Liu</strong>, Jun-Hai Yong, Hui Zhang, Dong-Ming Yan, Jia-Guang Sun. A quasi-Monte Carlo method for computing areas of point-sampled surfaces. <i>Computer-Aided Design</i>, 2006; 38(1): 55-68. (<strong>SCI</strong>, Impact factor: 1.542)(CCF-B)	
								<br/><a href="main/pdf/LiuYS_CAD06area.pdf">[Paper]&nbsp&nbsp</a>
								<a href="main/bibtex/Liu06.txt">[Bib]</a>
							</td>
						</tr>
					</table>
					<b>2005</b>
					<hr />
					<table cellpadding=5>
						<tr>
							<td><a href="main/big/LiuYS_TVC05Meshblending.png"><img src="main/small/LiuYS_TVC05Meshblending.png" alt="Mesh blending" width="200"/></a></td>
							<td>
								<span class="sequence"></span><strong>Yu-Shen Liu</strong>, Hui Zhang, Jun-Hai Yong, Pi-Qiang Yu, Jia-Guang Sun. Mesh blending. <i>The Visual Computer</i>, 2005; 21(11): 915-927. (<strong>SCI</strong>, Impact factor: 0.583)	
								<br/><a href="main/pdf/LiuYS_TVC05Meshblending.pdf">[Paper]&nbsp&nbsp</a>
							
							</td>
						</tr>
						<tr>
							<td></td>
							<td>
								<span class="sequence"></span><strong>Yu-Shen Liu</strong>, Jun-Hai Yong, Pi-Qiang Yu, Hui Zhang, Ming-Cui Du, Jia-Guang Sun. Mesh parameterization for an open connected surface without partition. <i>In Proceedings of the Ninth International Conference on Computer Aided Design and Computer Graphics (CAD-CG'05)</i>, 306-312, September, 2005, Hong Kong, China. (<strong><span style="color:red;">Best Student Paper Award</span></strong>)
							<br/><a href="main/pdf/LiuYS_CADCG05MP.pdf">[Paper]&nbsp&nbsp</a>
							</td>
						</tr>
					</table>
					<br/>
					<b>2004</b>
					<hr />
					<table cellpadding=5>
						<tr>
							<td></td>
							<td>
								<span class="sequence"></span><strong>Yu-Shen Liu</strong>, Pi-Qiang Yu, Jun-Hai Yong, Hui Zhang, Jia-Guang Sun. Bilateral filter for meshes using new predictor. <i>International Symposium on Computational and Information Sciences (CIS'04)</i>, LNCS 3314: 1093-1099, 2004. (SCI, Impact factor: 0.531)
								<br/><a href="main/pdf/LiuYS_CIS04BF.pdf">[Paper]&nbsp&nbsp</a>
							
							</td>
						</tr>
					</table>					
					<!-- <div class="subtitle" id="Articles in Review and Preparation">Articles in Review and Preparation:</div> -->
					<!--<hr/>-->
					
					<!-- <table cellpadding=5>
						<tr>
							<td>
								<span class="sequence"></span>Han Liu, <strong>Yu-Shen Liu</strong>, Pieter Pauwels, Hongling Guo, Ming Gu. Enhanced Explicit Semantic Analysis for product model retrieval in construction industry. IEEE Transactions on Industrial Informatics, under review (1st round), 2017.
							</td>
						</tr>
					</table> -->					
				</div>
			</div>
		</div>

	</body>
	<script src="common/js/jquery-3.2.1.min.js" type="text/javascript" ></script>
	<script type="text/javascript" src="common/js/fancybox/jquery.mousewheel-3.0.4.pack.js"></script>
	<!--script type="text/javascript" src="common/js/fancybox/jquery.fancybox-1.3.4.pack.js"></script-->	
	<link rel="stylesheet" type="text/css" href="common/js/fancybox/jquery.fancybox-1.3.4.css" media="screen">
	<script type="text/javascript" >
	<!--
		$(function() {
			$(".sequence").each(function(key,value)
			{
				var sequence=key+1;
				sequence=sequence+". ";
				$(this).text(sequence);
			})

			$(".softseq").each(function(key,value)
			{
				var sequence=key+1;
				sequence=sequence+". ";
				$(this).text(sequence);
			})
		})
	-->
	</script>
</html>