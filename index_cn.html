<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"> 
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
		<meta content="all" name="robots" />
		<meta name="author" content="BradBit" />
		<meta name="Copyright" content="Â© BIM Research Group, School of Software, Tsinghua University" />
		<meta name="description" content="Homepage of Yu-Shen Liu" />
		<meta name="keywords"content="Homepage,Yu-Shen Liu" />
		<link rel="icon" href="main/favicon.ico" type="image/x-icon" />
		<link rel="shortcut icon" href="main/favicon.ico" type="image/x-icon" />
		<link rel="stylesheet" rev="stylesheet" href="main/index.css" type="text/css" media="all" />
		<title>刘玉身 - 清华大学</title>
	</head>
	<body>
		<div class="main shadow">
			<div class="navigate shadow round " >
				<ul>
					<li><a href="#Biography">简介&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></li>
					<li><a href="#Participated Projects">科研项目&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></li>
					<li><a href="#Teaching Course">讲授课程&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></li>
					<li><a href="#Honors and Awards">奖励与荣誉&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></li>
					<li><a href="#Academic Activities">学术服务&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></li>
					<li>
						<a href="#Selected Publication">学术成果&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a>
					</li>
					<li><a href="https://aideadlin.es">人工智能会议日历</a></li>
				</ul>
				<br/>
				<span style="font-size: 14px; font-family: 宋体; float: right;"><a href="index.html">English Version</a></span>
			</div>

			<div class="content">
				<div class="desc s15" id="Biography"> 
					<a href="main/big/liu.jpg"><img class="left" src="main/small/liu.jpg" alt="Yu-Shen Liu" width="200" /></a>
					<div class="picdesc">
					<div class="fullname"> 
						刘玉身 (Yu-Shen Liu)
					</div>
					<hr/>
					副教授<br/>
					<a href="http://www.tsinghua.edu.cn/publish/soft/">清华大学软件学院<br/>
					联系方式：<br/>
					<table>
					<tr>
						<td>E-mail:</td><td><a href="mailto:liuyushen@tsinghua.edu.cn">liuyushen@tsinghua.edu.cn</a></td>
					</tr>
					<tr>
						<td>E-mail:</td><td><a href="mailto:liuyushen00@gmail.com">liuyushen00@gmail.com</a></td>
					</tr>
					<tr>
						<td>电话：</td><td>+86-10-62795455</td>
					</tr>
					</table>
					<br/>
				   个人主页:<br/> 
				   <a href="https://www.thss.tsinghua.edu.cn/faculty/liuyushen.htm" title="Tsinghua homepage">Tsinghua homepage</a>,&nbsp;
				   <a href="https://scholar.google.com/citations?hl=zh-CN&user=Vo4ZHu0AAAAJ&view_op=list_works&sortby=pubdate" title="Google Scholar">Google Scholar</a>,&nbsp;
				   <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Yu=Shen.html" title="DBLP">DBLP</a>
				   </div>
				</div>	
				<div class="block">
					Yu-Shen Liu is an Associate Professor in School of Software at Tsinghua University. He spent three years as a post doctoral researcher in Purdue University from 2006 to 2009. He earned his PhD in the Department of Computer Science and Technology at Tsinghua University, China, in 2006. He received his BS in mathematics from Jilin University, China, in 2000. His current research interests include algorithms in	pattern recognition, machine learning, shape matching and retrieval;	Information retrieval, semantic search;	Smart building, Building Information Modeling (BIM);	Digital Geometry Processing (DGP), shape denoising and smoothing.
				</div>
				<div class="block">
				<!--<strong><font size=4px>社会责任博士生招生</font></strong>
				今年9字班推研(即2022年9月参加推研，2023年入学），清华大学软件学院预计仍会有一个社会责任博士生招生名额，学校要求人选需要满足下述条件之一：<br/> (1)强军计划、<br/> (2)对口支援(新疆大学、青海大学）、<br/> (3)少数名族骨干、<br/> (4)本校应届本科具有专项推免直博资格的军工定向。<br/> 校外考生需满足前三条之一，本校需满足第4条。如有本校9字班同学满足第4条 “本校应届本科具有专项推免直博资格的军工定向”，并有意向博士阶段从事三维计算机视觉、几何智能处理与重建研究，可联系软件学院刘玉身老师，邮箱：liuyushen@tsinghua.edu.cn，主页：<a href="https://yushen-liu.github.io/">https://yushen-liu.github.io/</a>，本科阶段软件工程、计算机等信息科学技术方向优先。欢迎推荐！
				</div>-->
				<div class="title" id="Education"><strong><font size=4px>学习经历</font></strong></div>
				<div class="block">
					<table cellspacing=5>
						<tr valign="Top">
							<td class="period">2000-2006:</td>
							<td>
							<strong>清华大学</strong>, 
							计算机科学与技术系 博士学位<br/>
						</tr>
						<tr align="top">
							<td class="period">1996-2000:</td>
							<td><strong>吉林大学</strong>数学系 学士学位</td>
						</tr>
					</table>
				</div>
				<div class="title" id="Experience"><strong><font size=4px>工作经历</font></strong></div>
				<div class="block">
					<table cellpadding=5>
						<tr>
							<td class="period">2009 至今:  </td>
							<td><strong>清华大学</strong>软件学院</td>
						</tr>
						<tr valign="Top">
							<td class="period">2006-2009:</td>
							<td>美国<strong>普渡(Purdue)大学</strong>机械工程学院 博士后
							</td>
						</tr>
					</table>
				</div>
				<div class="title" id="Research Interests"><strong><font size=4px>研究方向</font></strong></div>
				<div class="block"> 
					<table cellspacing=5>
						<tr><td><strong>三维计算机视觉, 三维深度学习</strong><br/><br/></td></tr>

						<tr><td>三维表征与识别, 三维几何处理与语义理解, 三维重建<br/><br/></td></tr>

						<tr><td>建筑信息模型<br/><br/></td></tr>
					</table>
					<u><a href="mailto:liuyushen@tsinghua.edu.cn">目前，我正在招收<strong>博士生</strong>和<strong>研究助理</strong>参与顶级学术会议、期刊的工作。如有意向请与我取得联系。</a></u><br/><br/>
				</div>
				<div class="title" id="Participated Projects"><strong><font size=4px>科研项目</font></strong></div>
				
				<div class="block">
					
					<table cellspacing=5>
						<tr><td><b>1. </b>国家自然科学基金： 基于特征表示学习的三维点云语义实例分割与形状补全 (62072268), 2021.01-2024.12，负责人;<br/><br/></td></tr>

						<tr><td><b>2. </b>国家重点研发计划课题：面向全生命周期的京张高铁隧道与地下车站智能展示和控制技术 (2020YFF0304100), 2020.10-2022.12, 子课题负责人;<br/><br/></td></tr>

						<tr><td><b>3. </b>国家重点研发计划课题：城镇空间信息协同管理及综合服务平台 (2018YFB0505403)，2018.05-2022.04，课题负责人；<br/><br/></td></tr>

						<tr><td><b>4. </b>国家自然科学基金：基于IFC的建筑信息模型(BIM)语义检索技术研究（61472202），2015.01-2018.12，负责人；<br/><br/></td></tr>

						<tr><td><b>5. </b>国家自然科学基金：基于度量几何的三维关节变形模型的形状匹配研究（61272229），2013.01-2016.12，负责人；<br/><br/></td></tr>

						<tr><td><b>6. </b>国家自然科学基金：非刚性三维模型检索技术研究（61003095），2011.01-2013.12，负责人；<br/><br/></td></tr>

						<tr><td><b>7. </b>科技部“十二五”国家科技支撑计划项目：城镇住宅建设BIM技术研究及其产业化应用示范（2012BAJ03B00），2012.01-2015.09，主要研究人员；<br/><br/></td></tr>

						<tr><td><b>8. </b>国家自然科学基金：中国建筑信息化技术发展战略研究（U0970155），主要研究人员；<br/></td></tr>

					</table>
					<br/>
				</div>
				<div class="title" id="Teaching"><strong><font size=4px>讲授课程</font></strong></div>
				
				<div class="block">
					
					<table cellspacing=5>
						<tr>程序设计基础，本科生课程，2017-至今， <strong>清华大学精品课程</strong> (2021-2024), 2021年评教结果全校前25%<br/><br/></tr>
						
						<tr>数字几何处理，研究生课程， 2016-至今， <strong>清华大学年度教学优秀奖</strong> 2018年评教结果全校前5%<br/><br/></tr>

						<tr>软件工程（1），本科生课程， 2013-2016，<br/><br/></tr>
						
						<tr>业务资产管理，研究生课程，2015-至今<br/><br/></tr>
						
						<tr>数字媒体（2），研究生课程，2019<br/><br/></tr>
						
						<tr><strong>“清华大学优秀班（级）主任”</strong>一等奖，2017</tr>

					</table>
					<br/>
				</div>
				<div class="title" id="Awards"><strong><font size=4px>奖励与荣誉</font></strong></div>
				<div class="block">	
					<table cellpadding=5>	
						<tr>
							<td><a href="main/big/LiuXh_dataset.png"><img src="main/big/LiuXh_dataset.png" alt="Highly_cited" width="200"/></a></td>
							<td>
								<strong><a href="http://tc.ccf.org.cn/tccad/jlry/txkyrjj/hjrxx/2021-09-01/735713.shtml">Best Open Graphics Benchmark Award</a></strong> in the field of the CAD/Graphics area in 2021, which is selected by Technical Committee on Computer Aided Design and Computer Graphics (TCCADCG) affiliated with the China Computer Federation (CCF). 
							</td>
						</tr>
						<tr>
							<td><a href="main/big/MVP.jpg"><img src="main/big/MVP.jpg" alt="Highly_cited" width="200"/></a></td>
							<td>
								In 2021, he led his team to win the ranked 3rd place in MVP Point Cloud Completion Challenge 2021 at ICCV 2021 - The 3rd Workshop on Sensing, Understanding and Synthesizing Humans.
							</td>
						</tr>
						<tr>
							<td><a href="main/big/Highly_cited.jpg"><img src="main/small/Highly_cited.jpg" alt="Highly_cited" width="200"/></a></td>
							<td>
								<strong>Highly Cited Research Award</strong> The paper, “The IFC-based path planning for 3D indoor spaces”, published in Advanced Engineering Informatics (the Elsevier journal) is awarded Highly Cited Research on December, 2016. This paper was published in 2013, which is one of the most highly cited papers during 2014, 2015 and up until June 2016 according to data from Scopus. Dr. Yu-Shen Liu is the corresponding author of this paper.
								<br/><a href="ifcpath/index.html">[Project Page]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_AEI12IFC.pdf">[Paper]&nbsp&nbsp</a>
								<a href="main/bibtex/Liu13ifc.txt">[Bib]&nbsp&nbsp</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/ICCCBE2016_award.jpg"><img src="main/small/ICCCBE2016_award.jpg" alt="ICCCBE2016_award" width="200"/></a></td>
							<td>
								<strong>Best Student Presentation Award</strong>, at the 16th International Conference on Computing in Civil and Building Engineering (ICCCBE2016), held on July 6-8, at 2016, Osaka, Japan. Dr. Yu-Shen Liu is the corresponding author of this paper, and Mr. Ge Gao is the first author.
								<br/><a href="main/pdf/GaoGe_ICCCBE2016_364.pdf">[Paper]&nbsp&nbsp</a>
							</td>
						</tr>
					</table>
					<tr>
						<td>
							<strong>Best Student Paper Award</strong>, at the Proceedings of the Ninth International Conference on Computer Aided Design and Computer Graphics (CAD-CG'05), 306–312, September, 2005, Hong Kong, China.
						</td>
					</tr>
					<br/><br/>
				</div>

				<div class="title" id="Academic Activities"><strong><font size=4px>学术服务</font></strong></div>
				<div class="block">
					<table cellspacing="0">
						<tr><td><strong>Senior Program Committee member</strong> at IJCAI 2021, AAAI 2022</td></tr>
						<tr><td><strong>Program Committee member</strong> at ACM Multimedia 2020, ACM Multimedia 2019</td></tr>
						<tr><td><strong>Program Committee member</strong> at AAAI 2021, AAAI 2020</td></tr>
						<tr><td><strong>Program Committee member</strong> at LCLR 2021</td></tr>
						<tr><td><strong>Program Committee member</strong> at IJCAI 2020, IJCAI 2019</td></tr>
						<tr><td><strong>Program Committee member</strong> at WACV 2020, GDC 2019, CAD&CG 2019, ACM Multimedia Asia 2019</td></tr>
						<tr><td><strong>Program Committee</strong> of EG-ICE 2019(European Group for Intelligent Computing in Engineering)</td></tr>
						<tr><td><strong>The editorial team</strong> of Construction Innovation: Information, Process, Management (CI), 2018 ~ present.
						<a href="http://www.emeraldgrouppublishing.com/products/journals/editorial_team.htm?id=CI">http://www.emeraldgrouppublishing.com/products/journals/editorial_team.htm?id=CI</a><br/><br/></td></tr>
						<tr><td><strong>Co-chairs</strong> of PLM Smart Manufacturing Workshop, <i>2018 Asian Conference on Design and Digital Engineering (ACDDE2018)</i><br/><br/></td></tr>
						<tr><td><strong>The program committee</strong> of <i>AUAPAF2018 (Asian Universities Alliance Postgraduate Academic Forum)</i><br/><br/></td></tr>
						<tr><td><strong>Editorial Board</strong>  on the international journal Energies, Section Board for 'Energy and Buildings', 2021 ~ present. <a href="https://www.mdpi.com/journal/energies/sectioneditors/energy_buildings">https://www.mdpi.com/journal/energies/sectioneditors/energy_buildings</a><br/><br/></td></tr>
						<tr><td><strong>Editorial Board Member</strong> on the international journal <i>Smart Construction Research</i>, 2017 ~ present<br/><br/></td></tr>
						<tr><td><strong>Lead Guest Editor</strong>: Special Issue on Recent Advances on Building Information Modeling (BIM) <i>The Scientific World Journal</i>, 2013. (<b>SCI</b>, 2012 Impact factor: 1.730) <a href="main/bibtex/Liu14TSWJ.txt">&nbsp&nbsp[Bib]</a><br/><a herf="http://www.hindawi.com/journals/tswj/si/465058/cfp/">http://www.hindawi.com/journals/tswj/si/465058/cfp/</a><br/><br/></td></tr>
						<tr><td><strong>Guest Editor</strong>: Special Issue on Advances in Conceptual Design Theories, Methodologies, and Applications. <i>Advances in Mechanical Engineering</i>, 2013. (<b>SCI</b>, 2012 Impact factor: 1.062) <br/>
						<a herf="http://www.hindawi.com/journals/ame/si/293862/">http://www.hindawi.com/journals/ame/si/293862/</a><br/><br/></td></tr>
						<tr><td>The member on IFC Alignment 1.1 Expert Panel in buildingSMART<br/><br/></td></tr>
						<tr><td>The group of buildingSMART IFC Roads and Railway Standard.<br/><br/></td></tr>
						<tr><td>Reviewer for IEEE Transactions on Image Processing (TIP), CVPR, ICCV, IJCAI, AAAI, ACM Multimedia, ICME, Automation in Construction, Computer-Aided Design, ASME Journal of Mechanical Design, The Visual Computer, Computers & Graphics, International Journal of Precision Engineering and Manufacturing, Applied Stochastic Models in Business and Industry.<br/></td></tr>
					</table>
					<br/>
				</div>



				
				<div class="title" id="Selected Publications"><strong><font size=4px>学术成果</font></strong> <strong><font size=4px color=red>(*: corresponding author, #: co-first author)</font></strong></div>
			   	<div class="block">
					<b>Preprint</b>
					<hr />
					<table cellpadding=5>
					<tr>
						<td><a href="main/big/geodream.png"><img src="main/big/geodream.png" alt="SPU" width="200"/></a></td>
						<td>
							1. Baorui Ma*#, Haoge Deng#, Junsheng Zhou, <strong>Yu-Shen Liu</strong>, Tiejun Huang, Xinlong Wang*. GeoDream: Disentangling 2D and Geometric Priors for High-Fidelity and Consistent 3D Generation. arXiv:2311.17971.
							<br />
							<a href="https://mabaorui.github.io/GeoDream_page/">[Project Page]&nbsp&nbsp</a>
							<a href="https://arxiv.org/abs/2311.17971">[ArXiv]&nbsp&nbsp</a>
							<a href="main/pdf/LiuYS_Baorui_GeoDream.pdf">[PDF]&nbsp&nbsp</a>
							<a href="https://github.com/baaivision/GeoDream">[Github]&nbsp&nbsp</a>
						</td>
					</tr>
					</table>
					
					<b>2024</b>
					<hr />
					<table cellpadding=5>
						<tr>
							<td><a href="main/big/TPAMI2024_FastN2N.png"><img src="main/big/TPAMI2024_FastN2N.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Junsheng Zhou#, Baorui Ma#, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. Fast Learning of Signed Distance Functions from Noisy Point Clouds via Noise to Noise Mapping. <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>)</i>, 2024.
								<img class="new" src="main/img/new.gif"/>
								<a href="main/pdf/TPAMI-FastN2N.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://github.com/mabaorui/Noise2NoiseMapping">[Github]&nbsp&nbsp</a>
								<br />
								<br />
							</td>
						</tr>
						<tr>
							<td><a href="main/big/TPAMI_2024_CAPUDF.png"><img src="main/big/TPAMI_2024_CAPUDF.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Junsheng Zhou#, Baorui Ma#, Shujuan Li, <strong>Yu-Shen Liu*</strong>, Yi Fang, Zhizhong Han. CAP-UDF: Learning Unsigned Distance Functions Progressively from Raw Point Clouds with Consistency-Aware Field Optimization. <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>)</i>, 2024.
								<img class="new" src="main/img/new.gif"/>
								<a href="https://junshengzhou.github.io/CAP-UDF/">[Project Page]&nbsp&nbsp</a>
								<a href="main/pdf/TPAMI-CAPUDF.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://github.com/junshengzhou/CAP-UDF">[Github]&nbsp&nbsp</a>
								<br />
								<br />
							</td>
						</tr>
						<tr>
							<td><a href="main/big/cvpr_2024_udf.png"><img src="main/big/cvpr_2024_udf.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Junsheng Zhou#, Weiqi Zhang#, Baorui Ma*, Kanle Shi, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. UDiFF: Generating Conditional Unsigned Distance Fields with Optimal Wavelet Diffusion. <i>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</i>, 2024.
								<img class="new" src="main/img/new.gif"/>
								<br />	
								<a href="https://weiqi-zhang.github.io/UDiFF/">[Project Page]&nbsp&nbsp</a>
								<a href="https://arxiv.org/abs/2404.06851">[ArXiv]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_CVPR2024_UDF.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://github.com/weiqi-zhang/UDiFF">[Github]&nbsp&nbsp</a>
								<br />	
							</td>
						</tr>
						<tr>
							<td><a href="main/big/Uni3D_junsheng.png"><img src="main/big/Uni3D_junsheng.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Junsheng Zhou#, Jinsheng Wang#, Baorui Ma*#, <strong>Yu-Shen Liu</strong>, Tiejun Huang, Xinlong Wang*. Uni3D: Exploring Unified 3D Representation at Scale. <i>International Conference on Learning Representations (<strong>ICLR</strong>)</i>, 2024. <strong><span style="color:red;">(Spotlight, ~5.0% acceptance rate)</span></strong>
								<img class="new" src="main/img/new.gif"/>
								<br />	
								<a href="https://arxiv.org/abs/2310.06773">[ArXiv]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_junsheng_Uni3d.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://github.com/baaivision/Uni3D">[Github]&nbsp&nbsp</a>
								<br />	
							</td>
						</tr>
						<tr>
							<td><a href="main/big/AAAI2024_shujuan.png"><img src="main/big/AAAI2024_shujuan.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Shujuan Li#, Junsheng Zhou#, Baorui Ma, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. Learning Continuous Implicit Field with Local Distance Indicator for Arbitrary-Scale Point Cloud Upsampling. <i>AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>)</i>, 2024, pp. 3181-3189.
								<img class="new" src="main/img/new.gif"/>
								<br />	
								<a href="https://lisj575.github.io/APU-LDI">[Project Page]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_AAAI2024_pc_upsampling.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://arxiv.org/abs/2312.15133">[ArXiv]&nbsp&nbsp</a>
								<br />	
							</td>
						</tr>
						<tr>
							<td><a href="main/big/AAAI2024_huanghan.png"><img src="main/big/AAAI2024_huanghan.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Han Huang, Yulun Wu, Junsheng Zhou, Ge Gao*, Ming Gu, <strong>Yu-Shen Liu</strong>. NeuSurf: On-Surface Priors for Neural Surface Reconstruction from Sparse Input Views. <i>AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>)</i>, 2024, pp. 2312-2320.
								<img class="new" src="main/img/new.gif"/>
								<br />	
								
								<a href="https://alvin528.github.io/NeuSurf/">[Project Page]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_AAAI2024_huanghan.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://arxiv.org/abs/2312.13977">[ArXiv]&nbsp&nbsp</a>
								<br />	
							</td>
						</tr>
						<tr>
							<td><a href="main/big/AAAI2024_shengtao.png"><img src="main/big/AAAI2024_shengtao.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Shengtao Li, Ge Gao*, Yudong Liu, <strong>Yu-Shen Liu</strong>, Ming Gu. GridFormer: Point-Grid Transformer for Surface Reconstruction. <i>AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>)</i>, 2024, pp. 3163-3171.
								<img class="new" src="main/img/new.gif"/>
								<br />	
								<a href="https://arxiv.org/abs/2401.02292">[ArXiv]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_AAAI2024_shengtao.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://github.com/list17/GridFormer">[Github]&nbsp&nbsp</a>
								<br />	
							</td>
						</tr>
						<tr>
							<td><a href="main/big/ICRA2024.png"><img src="main/big/ICRA2024.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Junsheng Zhou, Xin Wen, Baorui Ma, <strong>Yu-Shen Liu*</strong>, Yue Gao, Yi Fang, Zhizhong Han. 3D-OAE: Occlusion Auto-Encoders for Self-Supervised Learning on Point Clouds. <i>IEEE International Conference on Robotics and Automation (<strong>ICRA</strong>)</i>, 2024. 
								<img class="new" src="main/img/new.gif"/>
								<br />	
								<a href="https://arxiv.org/pdf/2203.14084.pdf">[ArXiv]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_ICRA2024_OAE.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://github.com/junshengzhou/3D-OAE">[Github]&nbsp&nbsp</a>
								<br />	
							</td>
						</tr>
						<tr>
							<td><a href="main/big/TPAMI2024_jishuyi.png"><img src="main/big/TPAMI2024_jishuyi.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Yifan Feng, Shuyi Ji, <strong>Yu-Shen Liu</strong>, Shaoyi Du, Qionghai Dai, Yue Gao*. Hypergraph-Based Multi-Modal Representation for Open-Set 3D Object Retrieval. <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>)</i>, 2024, accepted.
								<img class="new" src="main/img/new.gif"/>
								<br />	
								<br />	
							</td>
						</tr>
					</table>
					

					<b>2023</b>
					<hr />
					<table cellpadding=5>
						<tr>
							<td><a href="main/big/nips2023_zhou.png"><img src="main/big/nips2023_zhou.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Junsheng Zhou#, Baorui Ma#, Wenyuan Zhang, Yi Fang, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. Differentiable Registration of Images and LiDAR Point Clouds with VoxelPoint-to-Pixel Matching. <i>Neural Information Processing Systems (<strong>NeurIPS</strong>)</i>, 2023.<strong><span style="color:red;">(Spotlight)</span></strong>
								<br />	
								<br />	
							</td>
						</tr>
						<tr>
							<td><a href="main/big/nips2023_liqing.png"><img src="main/big/nips2023_liqing.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Qing Li, Huifang Feng, Kanle Shi, Yue Gao, Yi Fang, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. NeuralGF: Unsupervised Point Normal Estimation by Learning Neural Gradient Function. <i>Neural Information Processing Systems (<strong>NeurIPS</strong>)</i>, 2023.
								<br />	
								<a href="https://arxiv.org/abs/2311.00389">[ArXiv]&nbsp&nbsp</a>
								<br />	
							</td>
						</tr>
						<tr>
							<td><a href="main/big/Liqing_siggraph2023.png"><img src="main/big/Liqing_siggraph2023.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Qing Li, Huifang Feng, Kanle Shi, Yi Fang, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. Neural Gradient Learning and Optimization for Oriented Point Normal Estimation. <i><strong>SIGGRAPH Asia 2023</strong></i>.
								<br />	
								<a href="https://arxiv.org/abs/2309.09211">[ArXiv]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_SigraphAsia_LiQing.pdf">[PDF]&nbsp&nbsp</a>
								<br />	
							</td>
						</tr>
						<tr>
							<td><a href="main/big/GridPull.png"><img src="main/big/GridPull.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Chao Chen, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. GridPull: Towards Scalability in Learning Implicit Representations from 3D Point Clouds. <i>Proceedings of the IEEE/CVF International Conference on Computer Vision <strong>(ICCV)</strong></i>, 2023, pp.18322-18334.(CCF-A).
								<br />	
								<a href="https://arxiv.org/abs/2308.13175">[ArXiv]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_ICCV2023_GridPull.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://openaccess.thecvf.com/content/ICCV2023/html/Chen_GridPull_Towards_Scalability_in_Learning_Implicit_Representations_from_3D_Point_ICCV_2023_paper.html">[Open access]&nbsp&nbsp</a>
								<a href="https://github.com/chenchao15/GridPull">[Github]&nbsp&nbsp</a>
								<br />	
							</td>
						</tr>
						<tr>
							<td><a href="main/big/Retro-FPN.png"><img src="main/big/Retro-FPN.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Peng Xiang, Xin Wen, <strong>Yu-Shen Liu*</strong>, Hui Zhang*, Yi Fang, Zhizhong Han. Retro-FPN: Retrospective Feature Pyramid Network for Point Cloud Semantic Segmentation. <i>Proceedings of the IEEE/CVF International Conference on Computer Vision <strong>(ICCV)</strong></i>, 2023, pp.17826-17838.(CCF-A).
								<br />	
								<a href="https://arxiv.org/abs/2308.09314">[ArXiv]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_ICCV2023_Retro-FPN.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://openaccess.thecvf.com/content/ICCV2023/html/Xiang_Retro-FPN_Retrospective_Feature_Pyramid_Network_for_Point_Cloud_Semantic_Segmentation_ICCV_2023_paper.html">[Open access]&nbsp&nbsp</a>
								<a href="https://github.com/AllenXiangX/Retro-FPN">[Github]&nbsp&nbsp</a>
								<br />	
							</td>
						</tr>
						<tr>
							<td><a href="main/big/LevelSetUDF.png"><img src="main/big/LevelSetUDF.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Junsheng Zhou#, Baorui Ma#, Shujuan Li, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. Learning a More Continuous Zero Level Set in Unsigned Distance Fields through Level Set Projection. <i>Proceedings of the IEEE/CVF International Conference on Computer Vision <strong>(ICCV)</strong></i>, 2023, pp.3181-3192.(CCF-A).
								<br />	
								<a href="https://arxiv.org/abs/2308.11441">[ArXiv]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_ICCV2023_LevelSetUDF.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Learning_a_More_Continuous_Zero_Level_Set_in_Unsigned_Distance_ICCV_2023_paper.html">[Open access]&nbsp&nbsp</a>
								<a href="https://github.com/junshengzhou/LevelSetUDF">[Github]&nbsp&nbsp</a>
								<br />	
							</td>
						</tr>
						<tr>
							<td><a href="main/big/icml2023.png"><img src="main/big/icml2023.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Baorui Ma, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. Learning Signed Distance Functions from Noisy 3D Point Clouds via Noise to Noise Mapping. <i>International Conference on Machine Learning <strong>(ICML)</strong></i>, 2023.(CCF-A).<strong><span style="color:red;">(Oral presentation)</span></strong>.
								<br />
								<a href="https://arxiv.org/abs/2306.01405">[ArXiv]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_ICM2023_learning_signed_distance_funct.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://github.com/mabaorui/Noise2NoiseMapping/">[Github]&nbsp&nbsp</a>
								<br />	
							</td>
						</tr>
						<tr>
							<td><a href="main/big/Snowflake.jpg"><img src="main/big/Snowflake.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Peng Xiang#, Xin Wen#, <strong>Yu-Shen Liu*</strong>, Yan-Pei Cao, Pengfei Wan, Wen Zheng, Zhizhong Han. Snowflake Point Deconvolution for Point Cloud Completion and Generation with Skip-Transformer. <i>IEEE Transactions on Pattern Analysis and Machine Intelligence <strong>(TPAMI)</strong></i>, 2023, 45(5):6320-6338.(CCF-A).
								<br />	
								<a href="https://arxiv.org/abs/2202.09367">[ArXiv]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_TPAMI_SnowFlakeNet.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://ieeexplore.ieee.org/document/9928787/">[IEEE Xplore]&nbsp&nbsp</a>
								<a href="https://mp.weixin.qq.com/s/6Xf22Ht46YFz8qPzLHRoew">[Jittor Media report]</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/PMPNET++.png"><img src="main/big/PMPNET++.png" alt="Neural" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Xin Wen, Peng Xiang, Zhizhong Han, Yan-Pei Cao, Pengfei Wan, Wen Zheng, <strong>Yu-Shen Liu*</strong>. PMP-Net++: Point Cloud Completion by Transformer-Enhanced Multi-step Point Moving Paths. <i>IEEE Transactions on Pattern Analysis and Machine Intelligence <strong>(TPAMI)</strong></i>, 2023, 45(1): 852-867.(CCF-A).
								<br />
								<a href="PMP-Net++/index.html">[Project Page]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_TPAMI_PMP-Net_v2.pdf">[PDF]&nbsp&nbsp</a>
								<a href="http://arxiv.org/abs/2202.09507">[ArXiv]&nbsp&nbsp</a>	
								<a href="https://github.com/diviswen/PMP-Net">[Github]&nbsp&nbsp</a>
								<a href="https://ieeexplore.ieee.org/document/9735342">[IEEE Xplore]&nbsp&nbsp</a>
								<a href="https://mp.weixin.qq.com/s/fSPldmzT_nuCvqupCzlFyg">[Media report]</a>	
								<a href="https://mp.weixin.qq.com/s/UrQC5PbCS27XRvFQfCaQtQ">[Jittor Media report]</a>	
							</td>
						</tr>
						<tr>
							<td><a href="main/big/TIP2022_FLRf.png"><img src="main/big/TIP2022_FLRf.png" alt="Neural" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Wenyuan Zhang, Ruofan Xing, Yunfan Zeng, <strong>Yu-Shen Liu*</strong>, Kan-Le Shi, Zhizhong Han. Fast Learning Radiance Fields by Shooting Much Fewer Rays. <i>IEEE Transactions on Image Processing <strong>(TIP)</strong></i>, 2023, 32: 2703-2718.(CCF-A).
								<br />
								<a href="main/pdf/LiuYS_TIP2023_wenyuan.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://arxiv.org/abs/2208.06821">[ArXiv]&nbsp&nbsp</a>
								<a href="https://zparquet.github.io/Fast-Learning/">[Github]&nbsp&nbsp</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/LiuYS_CVPR2023_towards_better_gradient_consis.png"><img src="main/big/LiuYS_CVPR2023_towards_better_gradient_consis.png" alt="Neural" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Baorui Ma#, Junsheng Zhou#, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. Towards Better Gradient Consistency for Neural Signed Distance Functions via Level Set Alignment. <i>Proceedings of the IEEE/CVF Conference on Computer Vsion and Pattern Recognition <strong>(CVPR)</strong></i>, 2023, pp.17724-17734.(CCF-A).
								<br />
								<a href="main/pdf/LiuYS_CVPR2023_towards_better_gradient_consis.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://openaccess.thecvf.com/content/CVPR2023/html/Ma_Towards_Better_Gradient_Consistency_for_Neural_Signed_Distance_Functions_via_CVPR_2023_paper.html">[Open access]&nbsp&nbsp</a>
								<a href="https://github.com/mabaorui/TowardsBetterGradient/">[Github]&nbsp&nbsp</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/LiuYS_CVPR2023_NeuralTPS.png"><img src="main/big/LiuYS_CVPR2023_NeuralTPS.png" alt="Neural" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Chao Chen, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. Unsupervised Inference of Signed Distance Functions from Single Sparse Point Clouds without Learning Priors. <i>Proceedings of the IEEE/CVF Conference on Computer Vsion and Pattern Recognition <strong>(CVPR)</strong></i>, 2023, pp.17712-17723.(CCF-A).
								<br />
								<a href="main/pdf/LiuYS_CVPR2023_neuralTPS.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://arxiv.org/pdf/2303.14505.pdf">[ArXiv]&nbsp&nbsp</a>
								<a href="https://openaccess.thecvf.com/content/CVPR2023/html/Chen_Unsupervised_Inference_of_Signed_Distance_Functions_From_Single_Sparse_Point_CVPR_2023_paper.html">[Open access]&nbsp&nbsp</a>
								<a href="https://github.com/chenchao15/NeuralTPS">[Github]&nbsp&nbsp</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/LiuYS_CVPR2023_shs_net_learning_signed_hyper_.png"><img src="main/big/LiuYS_CVPR2023_shs_net_learning_signed_hyper_.png" alt="Neural" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Qing Li, Huifang Feng, Kanle Shi, Yue Gao, Yi Fang, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. SHS-Net: Learning Signed Hyper Surfaces for Oriented Normal Estimation of Point Clouds. <i>Proceedings of the IEEE/CVF Conference on Computer Vsion and Pattern Recognition <strong>(CVPR)</strong></i>, 2023, pp. 13591-13600.(CCF-A).
								<br />
								<a href="main/pdf/LiuYS_CVPR2023_shs_net_learning_signed_hyper.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://arxiv.org/pdf/2305.05873.pdf">[ArXiv]&nbsp&nbsp</a>
								<a href="https://openaccess.thecvf.com/content/CVPR2023/html/Li_SHS-Net_Learning_Signed_Hyper_Surfaces_for_Oriented_Normal_Estimation_of_CVPR_2023_paper.html">[Open access]&nbsp&nbsp</a>
								<a href="https://leoqli.github.io/SHS-Net/">[Project Page]&nbsp&nbsp</a>
								<a href="https://github.com/LeoQLi/SHS-Net">[Github]&nbsp&nbsp</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/LiuYS_CVPR2023_lp_dif_learning_local_pattern.png"><img src="main/big/LiuYS_CVPR2023_lp_dif_learning_local_pattern.png" alt="Neural" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Meng Wang, <strong>Yu-Shen Liu*</strong>, Yue Gao, Kanle Shi, Yi Fang, Zhizhong Han. LP-DIF: Learning Local Pattern-specific Deep Implicit Function for 3D Objects and Scenes. <i>Proceedings of the IEEE/CVF Conference on Computer Vsion and Pattern Recognition <strong>(CVPR)</strong></i>, 2023, pp.21856-21865.(CCF-A).
								<br />
								<a href="main/pdf/LiuYS_CVPR2023_lp_dif_learning_local_pattern.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://openaccess.thecvf.com/content/CVPR2023/html/Wang_LP-DIF_Learning_Local_Pattern-Specific_Deep_Implicit_Function_for_3D_Objects_CVPR_2023_paper.html">[Open access]&nbsp&nbsp</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/LiuYS_CVPR2023_robust_multiview_point_cloud_r.png"><img src="main/big/LiuYS_CVPR2023_robust_multiview_point_cloud_r.png" alt="Neural" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Haiping Wang, Yuan Liu, Zhen Dong*, Yulan Guo, <strong>Yu-Shen Liu</strong>, Wenping Wang, Bisheng Yang. Robust Multiview Point Cloud Registration with Reliable Pose Graph Initialization and History Reweighting. <i>Proceedings of the IEEE/CVF Conference on Computer Vsion and Pattern Recognition <strong>(CVPR)</strong></i>, 2023, pp.9506-9515.(CCF-A).
								<br />
								<a href="main/pdf/LiuYS_CVPR2023_WangRobust.pdf">[PDF]&nbsp&nbsp</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/NEAF.jpg"><img src="main/big/NEAF.jpg" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Shujuan Li#, Junsheng Zhou#, Baorui Ma, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. NeAF: Learning Neural Angle Fields for Point Normal Estimation. <i>AAAI Conference on Artificial Intelligence <strong>(AAAI)</strong></i>, 2023.(CCF-A).<strong><span style="color:red;">(Oral presentation)</span></strong>
								<br />	
							</td>
						</tr>
						<tr>
							<td><a href="main/big/KT-NET_AAAI2023.jpg"><img src="main/big/KT-NET_AAAI2023.jpg" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Zhen Cao, Wenxiao Zhang, Xin Wen, Zhen Dong*, <strong>Yu-Shen Liu</strong>, Xiongwu Xiao, Bisheng Yang. KT-Net: Knowledge Transfer for Unpaired 3D Shape Completion. <i>AAAI Conference on Artificial Intelligence <strong>(AAAI)</strong></i>, 2023.(CCF-A).
								<br />
								<a href="https://lisj575.github.io/NeAF/">[Project Page]&nbsp&nbsp</a>
								<a href="https://arxiv.org/abs/2211.16869">[ArXiv]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_AAAI23_NeAF.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://github.com/lisj575/NeAF">[Github]&nbsp&nbsp</a>								
							</td>
						</tr>
						<tr>
							<td><a href="main/big/CAGD2023.png"><img src="main/big/CAGD2023.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Xinhai Liu, Zhizhong Han, Sanghuk Lee, Yan-Pei Cao, <strong>Yu-Shen Liu*</strong>. D-Net: Learning for Distinctive Point Clouds by Self-attentive Point Searching and Learnable Feature Fusion. <i>Computer Aided Geometric Design <strong>(CAGD)</strong></i>, 2023,104:102206.
								<br />
								<a href="main/pdf/CAGD2023_D_Net_CAGD_FT.pdf">[PDF]&nbsp&nbsp</a>
								<br />	
							</td>
						</tr>
						<tr>
							<td><a href="main/big/ICRA2023.png"><img src="main/big/ICRA2023.png" alt="Neural" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Congcong Wen, Hao Huang, <strong>Yu-Shen Liu</strong>, Yi Fang*. Pyramid Learnable Tokens for 3D LiDAR Place Recognition. <i>IEEE International Conference on Robotics and Automation <strong>(ICRA 2023)</strong></i>.
								<br />	
								<a href="main/pdf/LiuYS_ICRA2023.pdf">[PDF]&nbsp&nbsp</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/MM2023.png"><img src="main/big/MM2023.png" alt="Neural" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Congcong Wen, Xiang Li, Hao Huang, <strong>Yu-Shen Liu</strong>, Yi Fang*. 3D Shape Contrastive Representation Learning with Adversarial Examples. <i>IEEE Transactions on Multimedia <strong>(TMM)</strong></i>, 2023 | Journal article DOI: 10.1109/TMM.2023.3265177.(CCF-B).
								<br />
								<a href="main/pdf/TMM2023.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://ieeexplore.ieee.org/document/10094000">[IEEE Xplore]&nbsp&nbsp</a>
								<br />	
							</td>
						</tr>
						<tr>
							<td><a href="main/big/TMM2023_2.png"><img src="main/big/TMM2023_2.png" alt="Neural" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Shuaihang Yuan#, Congcong Wen#, <strong>Yu-Shen Liu</strong>, Yi Fang*. Retrieval-Specific View Learning for Sketch-to-Shape Retrieval. <i>IEEE Transactions on Multimedia <strong>(TMM)</strong></i>, 2023, Accepted.
								<br />	
							</td>
						</tr>
						<tr>
							<td><a href="main/big/liuhan_2023_MVDLite.png"><img src="main/big/liuhan_2023_MVDLite.png" alt="Neural" width="200"/></a></td>
							<td>
								<span class="sequence"></span> Han Liu, Ge Gao*, Hehua Zhang, <strong>Yu-Shen Liu</strong>, Yan Song, Ming Gu. MVDLite: A fast validation algorithm for Model View Definition rules. <i>Advanced Engineering Informatics</i>, 2023, 58 (102132): 1-14. (SCI, 2022 Impact factor: 8.8)
								<br />
								<a href="main/pdf/LiuYS_liuhan_2023_MVDLite.pdf">[PDF]&nbsp&nbsp</a>
								<br />	
							</td>
						</tr>
						<tr>
							<td><a href="main/big/liuhan_2023.png"><img src="main/big/liuhan_2023.png" alt="Neural" width="200"/></a></td>
							<td>
								<span class="sequence"></span> Han Liu*. Xiaoyu Song, Ge Gao*, Hehua Zhang, <strong>Yu-Shen Liu</strong>, Ming Gu. Modeling and validating temporal rules with semantic Petri net for digital twins. <i>Advanced Engineering Informatics</i>, 2023, 57 (102099): 1-14.(SCI.2022 Impact factor: 8.8)
								<br />
								<a href="main/pdf/LiuYS_liuhan_2023.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://www.sciencedirect.com/science/article/pii/S1474034623002276?utm_campaign=STMJ_AUTH_SERV_PUBLISHED&utm_medium=email&utm_acid=45570568&SIS_ID=&dgcid=STMJ_AUTH_SERV_PUBLISHED&CMX_ID=&utm_in=DM398833&utm_source=AC_">[ScienceDirect]&nbsp&nbsp</a>
								<br />	
							</td>
						</tr>
					</table>

					<b>2022</b>
					<hr />
					<table cellpadding=5>
						<tr>
							<td><a href="main/big/LiuYS_Arxiv_SPU-Net.png"><img src="main/big/LiuYS_Arxiv_SPU-Net.png" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Xinhai Liu, Xinchen Liu, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. SPU-Net: Self-supervised Point Cloud Upsampling by Coarse-to-Fine Reconstruction with Self-Projection Optimization. <i>IEEE Transactions on Image Processing <strong>(TIP)</strong></i>, 2022, 31: 4213-4226.(CCF-A).
								<br />	
								<a href="http://arxiv.org/abs/2012.04439">[ArXiv]&nbsp&nbsp</a>	
								<a href="main/pdf/LiuYS_TIP_SPUNet.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://github.com/liuxinhai/SPU-Net">[Github]&nbsp&nbsp</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/NIPS2022_zhou.jpg"><img src="main/big/NIPS2022_zhou.jpg" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Junsheng Zhou#, Baorui Ma#, <strong>Yu-Shen Liu*</strong>, Yi Fang, Zhizhong Han. Learning Consistency-Aware Unsigned Distance Functions Progressively from Raw Point Clouds. <i>Neural Information Processing Systems <strong>(NeurIPS)</strong></i>, 2022.
								<br />	
								<a href="https://junshengzhou.github.io/CAP-UDF">[Project Page]&nbsp&nbsp</a>
								<a href="https://arxiv.org/abs/2210.02757">[ArXiv]&nbsp&nbsp</a>	
								<a href="main/pdf/LiuYS_NeurIPS22_Zhou.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://github.com/junshengzhou/CAP-UDF">[Github]&nbsp&nbsp</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/NIPS2022_Li.jpg"><img src="main/big/NIPS2022_Li.jpg" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Qing Li, <strong>Yu-Shen Liu*</strong>, Jin-San Cheng, Cheng Wang, Yi Fang, Zhizhong Han. HSurf-Net: Normal Estimation for 3D Point Clouds by Learning Hyper Surfaces. <i>Neural Information Processing Systems <strong>(NeurIPS)</strong></i>, 2022.
								<a href="https://arxiv.org/abs/2210.07158">[ArXiv]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_NIPS2022_LIQING.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://github.com/LeoQLi/HSurf-Net">[Github]&nbsp&nbsp</a>
								<br />
							</td>
						</tr>
						<tr>
							<td><a href="main/big/ECCV2022_LPI.gif"><img src="main/big/ECCV2022_LPI.gif" alt="SPU" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Chao Chen, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. Latent Partition Implicit with Surface Codes for 3D Representation. <i>European Conference on Computer Vision <strong>(ECCV)</strong></i>, 2022, LNCS 13663, pp. 322–343.
								<br />	
								<a href="https://chenchao15.github.io/LPI_page/">[Project Page]&nbsp&nbsp</a>
								<a href="https://arxiv.org/abs/2207.08631">[ArXiv]&nbsp&nbsp</a>	
								<a href="main/pdf/LiuYS_ECCV2022_LPI.pdf">[PDF]&nbsp&nbsp</a>
							</td>
						</tr>	
						<tr>
						<td><a href="main/big/CVPR2022_PredictiveContextPriors.png"><img src="main/big/CVPR2022_PredictiveContextPriors.png" alt="Neural" width="200"/></a></td>
						<td>
							<span class="sequence"></span>Baorui Ma, <strong>Yu-Shen Liu*</strong>, Matthias Zwicker, Zhizhong Han. Surface Reconstruction from Point Clouds by Learning Predictive Context Priors. <I>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong></I>, 2022, pp. 6326-6337.(CCF-A)
							<br />
							<a href="https://arxiv.org/abs/2204.11015">[ArXiv]&nbsp&nbsp</a>	
							<a href="https://mabaorui.github.io/PredictableContextPrior_page/">[Project Page]&nbsp&nbsp</a>
							<a href="main/pdf/CVPR2022_PredictiveContextPriors.pdf">[PDF]&nbsp&nbsp</a>
							<a href="main/pdf/LiuYS_CVPR2022_OnSurfacePriors-supp.pdf">[Supp]&nbsp&nbsp</a>
							<a href="https://openaccess.thecvf.com/content/CVPR2022/html/Ma_Surface_Reconstruction_From_Point_Clouds_by_Learning_Predictive_Context_Priors_CVPR_2022_paper.html">[Open access]&nbsp&nbsp</a>
							<a href="https://github.com/mabaorui/PredictableContextPrior">[Github]&nbsp&nbsp</a>
						</td>
						</tr>
						<tr>
						<td><a href="main/big/LiuYS_CVPR2022_OnSurfacePriors.png"><img src="main/big/LiuYS_CVPR2022_OnSurfacePriors.png" alt="Neural" width="200"/></a></td>
						<td>
							<span class="sequence"></span>Baorui Ma, <strong>Yu-Shen Liu*</strong>, Zhizhong Han. Reconstructing Surfaces for Sparse Point Clouds with On-Surface Priors. <I>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong></I>, 2022, pp. 6315-6325.(CCF-A)
							<br />
							<a href="https://arxiv.org/abs/2204.10603">[ArXiv]&nbsp&nbsp</a>	
							<a href="https://mabaorui.github.io/-OnSurfacePrior_project_page/">[Project Page]&nbsp&nbsp</a>
							<a href="main/pdf/LiuYS_CVPR2022_OnSurfacePriors.pdf">[PDF]&nbsp&nbsp</a>
							<a href="main/pdf/LiuYS_CVPR2022_OnSurfacePriors-supp.pdf">[Supp]&nbsp&nbsp</a>
							<a href="https://openaccess.thecvf.com/content/CVPR2022/html/Ma_Reconstructing_Surfaces_for_Sparse_Point_Clouds_With_On-Surface_Priors_CVPR_2022_paper.html">[Open access]&nbsp&nbsp</a>
							<a href="https://github.com/mabaorui/OnSurfacePrior">[Github]&nbsp&nbsp</a>
						</td>
						</tr>
						<tr>
						<td><a href="main/big/LiuYS_CVPR2022_3DAttriFlow.png"><img src="main/big/LiuYS_CVPR2022_3DAttriFlow.png" alt="Neural" width="200"/></a></td>
						<td>
							<span class="sequence"></span>Xin Wen#, Junsheng Zhou#, <strong>Yu-Shen Liu*</strong>, Hua Su, Zhen Dong, Zhizhong Han. 3D Shape Reconstruction from 2D Images with Disentangled Attribute Flow. <I>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong></I>, 2022, pp. 3803-3813.(CCF-A)
							<br />
							<a href="main/pdf/LiuYS_CVPR2022_3DAttriFlow.pdf">[PDF]&nbsp&nbsp</a>
							<a href="https://arxiv.org/abs/2203.15190">[ArXiv]&nbsp&nbsp</a>	
							<a href="https://openaccess.thecvf.com/content/CVPR2022/html/Wen_3D_Shape_Reconstruction_From_2D_Images_With_Disentangled_Attribute_Flow_CVPR_2022_paper.html">[Open access]&nbsp&nbsp</a>
							<a href="https://github.com/junshengzhou/3DAttriFlow">[Github]&nbsp&nbsp</a>
						</td>
						</tr>
						<tr>
						<td><a href="main/big/LiuYS_CVPR2022_DCC-DIF.png"><img src="main/big/LiuYS_CVPR2022_DCC-DIF.png" alt="Neural" width="200"/></a></td>
						<td>
							<span class="sequence"></span>Tianyang Li, Xin Wen, <strong>Yu-Shen Liu*</strong>, Hua Su, Zhizhong Han. Learning Deep Implicit Functions for 3D Shapes with Dynamic Code Clouds. <I>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong></I>, 2022, pp. 12840-12850.(CCF-A)
							<br />
							<a href="https://lity20.github.io/DCCDIF_project_page/">[Project Page]&nbsp&nbsp</a>
							<a href="main/pdf/LiuYS_CVPR2022_DCC-DIF.pdf">[PDF]&nbsp&nbsp</a>
							<a href="https://arxiv.org/abs/2203.14048">[ArXiv]&nbsp&nbsp</a>	
							<a href="main/pdf/LiuYS_CVPR2022_DCC-DIF-supp.pdf">[Supp]&nbsp&nbsp</a>
							<a href="https://openaccess.thecvf.com/content/CVPR2022/html/Li_Learning_Deep_Implicit_Functions_for_3D_Shapes_With_Dynamic_Code_CVPR_2022_paper.html">[Open access]&nbsp&nbsp</a>
							<a href=" https://github.com/lity20/DCCDIF">[Github]&nbsp&nbsp</a>
							<a href="https://mp.weixin.qq.com/s/wpedor7u4wDsOtG3SdO0Dw">[Jittor Media report]</a>
						</td>
						</tr>
					</table>

					<b>2021</b>
					<hr />
					<table cellpadding=5>
						<tr>
						<td><a href="main/big/LiuYS_ICCV2021_SnowflakeNet.jpg"><img src="main/big/LiuYS_ICCV2021_SnowflakeNet.jpg" alt="Neural" width="200"/></a></td>
						<td>
							<span class="sequence"></span>Peng Xiang#, Xin Wen#, <strong>Yu-Shen Liu*</strong>, Yan-Pei Cao, Pengfei Wan, Wen Zheng, Zhizhong Han. SnowflakeNet: Point Cloud Completion by Snowflake Point Deconvolution with Skip-Transformer. <I>Proceedings of the IEEE/CVF International Conference on Computer Vision <strong>(ICCV)</strong></I>, 2021, pp. 5499-5509. (<strong><span style="color:red;">Oral presentation, ~3.4%</span> acceptance rate for Oral, ~25.9% overall acceptance rate</strong>)(CCF-A)
							<br />
							<a href="main/pdf/LiuYS_ICCV2021_SnowflakeNet.pdf">[PDF]&nbsp&nbsp</a>
							<a href="main/pdf/LiuYS_ICCV2021_SnowflakeNet-supp.pdf">[Supp]&nbsp&nbsp</a>
							<a href="https://openaccess.thecvf.com/content/ICCV2021/html/Xiang_SnowflakeNet_Point_Cloud_Completion_by_Snowflake_Point_Deconvolution_With_Skip-Transformer_ICCV_2021_paper.html">[Open access]&nbsp&nbsp</a>
							<a href="https://github.com/AllenXiangX/SnowflakeNet">[Github]&nbsp&nbsp</a>
							<a href="https://arxiv.org/abs/2108.04444">[ArXiv]</a>		
							<a href="https://mp.weixin.qq.com/s/E0Tu6Rr5KnshX6xLVlOXnw">[Media report]</a>	
						</td>
						</tr>
						<tr>
						<td><a href="main/big/LiuYS_ICCV2021_2DProjectionsMatching.jpg"><img src="main/big/LiuYS_ICCV2021_2DProjectionsMatching.jpg" alt="Neural" width="200"/></a></td>
						<td>
							<span class="sequence"></span>Chao Chen#, Zhizhong Han#, <strong>Yu-Shen Liu*</strong>, Matthias Zwicker. Unsupervised Learning of Fine Structure Generation for 3D Point Clouds by 2D Projections Matching. <I>Proceedings of the IEEE/CVF International Conference on Computer Vision <strong>(ICCV)</strong></I>, 2021, pp. 12466-12477. (<strong>~25.9% overall acceptance rate</strong>)(CCF-A)	
							<br />
							<a href="main/pdf/LiuYS_ICCV2021_2DProjectionsMatching.pdf">[PDF]&nbsp&nbsp</a>
							<a href="main/pdf/LiuYS_ICCV2021_2DProjectionsMatching-supp.pdf">[Supp]&nbsp&nbsp</a>
							<a href="https://openaccess.thecvf.com/content/ICCV2021/html/Chen_Unsupervised_Learning_of_Fine_Structure_Generation_for_3D_Point_Clouds_ICCV_2021_paper.html">[Open access]&nbsp&nbsp</a>
							<a href="https://github.com/chenchao15/2D_projection_matching">[Github]&nbsp&nbsp</a>
							<a href="https://arxiv.org/abs/2108.03746">[ArXiv]</a>	
							<a href="https://mp.weixin.qq.com/s/EyjbiPyRhWeXTJb1JsxfcQ">[Media report]</a>			
						</td>
						</tr>
						<tr>
						<td><a href="main/big/LiuYS_ACMMM2021_HVP.png"><img src="main/big/LiuYS_ACMMM2021_HVP.png" alt="Neural" width="200"/></a></td>
						<td>
							<span class="sequence"></span>Zhizhong Han, Xiyang Wang, <strong>Yu-Shen Liu*</strong>, Matthias Zwicker. Hierarchical View Predictor: Unsupervised 3D Global Feature Learning through Hierarchical Prediction among Unordered Views. <I>Proceedings of the 29th ACM International Conference on Multimedia <strong>(ACM MM)</strong></I>, 2021, 3862–3871. (<strong><span style="color: red;">Oral presentation, ~27.9%</span> overall acceptance rate</strong>)(CCF-A)	
							<br />
							<a href="main/pdf/LiuYS_ACMMM21_HVP.pdf">[PDF]&nbsp&nbsp</a>
							<a href="https://arxiv.org/abs/2108.03743">[ArXiv]</a>			
						</td>
						</tr>
						<tr>
						<td><a href="main/big/LiuYS_ICML2021_NeuralPull.jpg"><img src="main/big/LiuYS_ICML2021_NeuralPull.jpg" alt="Neural" width="200"/></a></td>
						<td>
							<span class="sequence"></span>Baorui Ma#, Zhizhong Han#, <strong>Yu-Shen Liu*</strong>, Matthias Zwicker. Neural-Pull: Learning Signed Distance Functions from Point Clouds by Learning to Pull Space onto Surfaces. <I>International Conference on Machine Learning <strong>(ICML)</strong></I>, 2021, PMLR 139: 7246-7257. (<strong>~21.4% overall acceptance rate</strong>)(CCF-A)
							<br />
							<a href="main/pdf/LiuYS_ICML21_NeuralPull.pdf">[PDF]&nbsp&nbsp</a>
							<a href="main/pdf/LiuYS_ICML21_NeuralPull_Supp.pdf">[Supp]&nbsp&nbsp</a>
							<a href="https://proceedings.mlr.press/v139/ma21b.html">[Proceedings]&nbsp&nbsp</a>
							<a href="https://github.com/mabaorui/NeuralPull">[Github]&nbsp&nbsp</a>
							<a href="http://arxiv.org/abs/2011.13495">[ArXiv]</a>						
						</td>
						</tr>
						<tr>
						<td><a href="main/big/LiuYS_CVPR_PMP-Net.png"><img src="main/big/LiuYS_CVPR_PMP-Net.png" alt="PMP" width="200"/></a></td>
						<td>
                            <span class="sequence"></span>Xin Wen, Peng Xiang, Zhizhong Han, Yan-Pei Cao,  Pengfei Wan, Wen Zheng, <strong>Yu-Shen Liu*</strong>. PMP-Net: Point Cloud Completion by Learning Multi-step Point Moving Paths. <I>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong></I>, 2021, pp. 7443-7452. (<strong>~27% overall acceptance rate</strong>)(CCF-A)
                            <p><font color='red'>Ranked <strong>3rd place in Multi-View Partial (MVP) Point Cloud Completion Challenge 2021</strong> at ICCV 2021  -  <a href='https://sense-human.github.io/'>The 3rd Workshop on Sensing, Understanding and Synthesizing Humans.</a></font></p>
							<a href="main/pdf/LiuYS_CVPR21_PMP-Net.pdf">[PDF]&nbsp&nbsp</a>
							<a href="main/pdf/LiuYS_CVPR21_PMP-Net-supp.pdf">[Supp]&nbsp&nbsp</a>
							<a href="https://openaccess.thecvf.com/content/CVPR2021/html/Wen_PMP-Net_Point_Cloud_Completion_by_Learning_Multi-Step_Point_Moving_Paths_CVPR_2021_paper.html">[Open access]&nbsp&nbsp</a>
							<a href="https://github.com/diviswen/PMP-Net">[Github]&nbsp&nbsp</a>
							<a href="https://arxiv.org/abs/2012.03408">[ArXiv]</a>	
							<a href="https://mp.weixin.qq.com/s/Bp68DWQ2_b6mpboVfDGqDg">[Media report]</a>					
						</td>
						</tr>

						<tr>
						<td><a href="main/big/LiuYS_CVPR_Cycle4Completion.png"><img src="main/big/LiuYS_CVPR_Cycle4Completion.png" alt="PMP" width="200"/></a></td>
						<td>
							<span class="sequence"></span>Xin Wen, Zhizhong Han, Yan-Pei Cao,  Pengfei Wan, Wen Zheng, <strong>Yu-Shen Liu*</strong>. Cycle4Completion: Unpaired Point Cloud Completion using Cycle Transformation with Missing Region Coding. <I>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong></I>, 2021, 13080-13089.(<strong>~27% overall acceptance rate</strong>)(CCF-A)
							<br />
							<a href="main/pdf/LiuYS_CVPR21_Cycle4Completion.pdf">[PDF]&nbsp&nbsp</a>
							<a href="https://openaccess.thecvf.com/content/CVPR2021/html/Wen_Cycle4Completion_Unpaired_Point_Cloud_Completion_Using_Cycle_Transformation_With_Missing_CVPR_2021_paper.html">[Open access]&nbsp&nbsp</a>
							<a href="https://github.com/diviswen/Cycle4Completion">[Github]&nbsp&nbsp</a>
							<a href="https://arxiv.org/abs/2103.07838">[ArXiv]</a>
						</td>
						</tr>

						<tr>
							<td><a href="main/big/LiuYS_TIP2021_FG3D-Net.png"><img src="main/big/LiuYS_TIP2021_FG3D-Net.png" alt="FG3D" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Xinhai Liu, Zhizhong Han, <strong>Yu-Shen Liu*</strong>, Matthias Zwicker. Fine-Grained 3D Shape Classification with Hierarchical Part-View Attentions. <I>IEEE Transactions on Image Processing <strong>(TIP)</strong></I>, 2021, 30: 1744-1758. (SCI, 2019 Impact factor: 9.34). (CCF-A)
								<p><font color='red'>Received the <strong>Best Open Graphics Benchmark Award</strong> in the field of the CAD/Graphics area in 2021, which is selected by Technical Committee on Computer Aided Design and Computer Graphics (TCCADCG) affiliated with the China Computer Federation(CCF)</font></p>
								<a href="main/pdf/LiuYS_TIP2021_FG3D-Net.pdf">[PDF]&nbsp&nbsp</a>
								<a href="https://github.com/liuxinhai/FG3D-Net">[Data Download]&nbsp&nbsp</a>
								<a href="https://ieeexplore.ieee.org/document/9318534">[IEEE Xplore]&nbsp&nbsp</a>
								<a href="https://arxiv.org/abs/2005.12541">[ArXiv]&nbsp&nbsp</a>
								<a href="https://mp.weixin.qq.com/s/e0YIzM-jcSWqGaD29_0XkA">[Media report]</a>						
							</td>
						</tr>
						<tr>
						<td><a href="main/big/tcvst_cmpd.png"><img src="main/big/tcvst_cmpd.png" alt="tcvst_cmpd" width="200"/></a></td>
						<td>
							<span class="sequence"></span>Xin Wen, Zhizhong Han, <strong>Yu-Shen Liu*</strong>. CMPD: Using Cross Memory Network with Pair Discrimination for Image-Text Retrieval. <I>IEEE Transactions on Circuits and Systems for Video Technology <strong>(TCSVT)</strong></I>, 2021, 31(6): 2427-2437.(SCI Journal Impact factor: <strong>4.685</strong>)(CCF-B)
							<br />
							<a href="main/pdf/LiuYS_TCSVT2021.pdf">[PDF]&nbsp&nbsp</a> 
							<a href="https://ieeexplore.ieee.org/document/9169915">[IEEE Xplore]&nbsp&nbsp</a>						
						</td>
						</tr>
						<tr>
						<td><a href="main/big/LiuYS_HeGeo_AUTCOM2021.png"><img src="main/big/LiuYS_HeGeo_AUTCOM2021.png" alt="autocom" width="200"/></a></td>
						<td>
							<span class="sequence"></span>Xiaoping Zhou, Mengmeng Wang, <strong>Yu-Shen Liu</strong>, Qian Wang, Maozu Guo, Jichao Zhao. Heterogeneous Network Modeling and Segmentation of Building Information Modeling Data for Parallel Triangulation and Visualization. <I>Automation in Construction</I>, 2021, 131: 103897, 1-13. (SCI, 2020 Impact factor: 7.7)
							<br />
							<a href="main/pdf/LiuYS_HeGeo_AUTCOM2021.pdf">[PDF]&nbsp&nbsp</a> 					
						</td>
						</tr>
					</table>

					<b>2020</b>
					<hr />
					<table cellpadding=5>
						<tr>
						<td><a href="main/big/LiuYS_Point2SpatialCapsule.png"><img src="main/big/LiuYS_Point2SpatialCapsule.png" alt="Point2SpatialCapsule" width="200"/></a></td>
						<td>
							<span class="sequence"></span>Xin Wen, Zhizhong Han, Xinhai Liu, <strong>Yu-Shen Liu*</strong>. Point2SpatialCapsule: Aggregating Features and Spatial Relationships of Local Regions on Point Clouds using Spatial-aware Capsules. <I>IEEE Transactions on Image Processing <strong>(TIP)</strong></I>, 2020, 29: 8855-8869. (SCI, 2019 Impact factor: 9.34)(CCF-A)
							<br />	
							<a href="main/pdf/LiuYS_TIP20Capsule.pdf">[PDF]&nbsp&nbsp</a>
							<a href="https://ieeexplore.ieee.org/document/9187572">[IEEE Xplore]&nbsp&nbsp</a>
                            <a href="https://arxiv.org/abs/1908.11026">[ArXiv]</a>
						</td>
						</tr>
						<tr>
						<td><a href="main/big/reconstructing_tip2020.png"><img src="main/big/reconstructing_tip2020.png" alt="reconstructing_tip2020" width="200"/></a></td>
						<td>
							<span class="sequence"></span>Zhizhong Han, Baorui Ma, <strong>Yu-Shen Liu*</strong>, Matthias Zwicker. Reconstructing 3D Shapes from Multiple Sketches using Direct Shape Optimization. <I>IEEE Transactions on Image Processing <strong>(TIP)</strong></I>, 2020, 29: 8721-8734. (SCI, 2019 Impact factor: 9.34)(CCF-A)
							<br />
							<a href="main/pdf/LiuYS_TIP20Sketch3D.pdf">[PDF]&nbsp&nbsp</a>
							<a href="https://ieeexplore.ieee.org/document/9184255">[IEEE Xplore]&nbsp&nbsp</a>
							<!-- <a href="video_page/driftvis-pre1208c01f.autosave_player.html">[Demo]&nbsp&nbsp</a> -->
							<a href="video_page/MS.mp4">[Demo]&nbsp&nbsp</a>			
						</td>
						</tr>
						<tr>
						<td><a href="main/big/acmmm_cfsis.png"><img src="main/big/acmmm_cfsis.png" alt="acmmm_cfsis" width="200"/></a></td>
						<td>
							<span class="sequence"></span>Xin Wen, Zhizhong Han, Geunhyuk Youk, <strong>Yu-Shen Liu*</strong>. CF-SIS: Semantic-Instance Segmentation of 3D Point Clouds by Context Fusion with Self-Attention. <I>Proceedings of the 28th ACM International Conference on Multimedia <strong>(ACM MM'20)</strong></I>, pp. 1661-1669.(<strong>~27.8% overall acceptance rate</strong>)(CCF-A)
							<br />	
							<a href="main/pdf/LiuYS_ACMMM20_CF-SIS.pdf">[PDF]&nbsp&nbsp</a>	
							<a href="https://dl.acm.org/doi/abs/10.1145/3394171.3413829">[DOI]&nbsp&nbsp</a>					
						</td>
						</tr>
						<tr>
						<td><a href="main/big/ShapeCaptioner.png"><img src="main/big/ShapeCaptioner.png" alt="ShapeCaptioner" width="200"/></a></td>
						<td>
							<span class="sequence"></span>Zhizhong Han, Chao Chen, <strong>Yu-Shen Liu*</strong>, Matthias Zwicker. ShapeCaptioner: Generative Caption Network for 3D Shapes by Learning a Mapping from Parts Detected in Multiple Views to Sentences. <I>Proceedings of the 28th ACM International Conference on Multimedia <strong>(ACM MM'20)</strong></I>, pp. 1018-1027.(<strong><span style="color: red;">Oral presentation, ~27.8%</span> overall acceptance rate</strong>)(CCF-A)
							<br />	
							<a href="main/pdf/LiuYS_ACMMM20_ShapeCaptioner.pdf">[PDF]&nbsp&nbsp</a>
							<a href="https://dl.acm.org/doi/10.1145/3394171.3413889">[DOI]&nbsp&nbsp</a>	
							<a href="https://arxiv.org/abs/1908.00120">[ArXiv]</a>						
						</td>	
						</tr>
						<tr>
						<td><a href="main/big/SeqXY2SeqZ.png"><img src="main/big/SeqXY2SeqZ.png" alt="SeqXY2SeqZ" width="200"/></a></td>
						<td>
							<span class="sequence"></span>Zhizhong Han, Guanhui Qiao, <strong>Yu-Shen Liu*</strong>, Matthias Zwicker. SeqXY2SeqZ: Structure Learning for 3D Shapes by Sequentially Predicting 1D Occupancy Segments From 2D Coordinates. <I>European Conference on Computer Vision <strong>(ECCV)</strong></I>, 2020, LNCS 12369, pp. 607–625.(<strong>~27% overall acceptance rate</strong>)(CCF-B)
							<br />
							 <a href="main/pdf/LiuYS_ECCV2020_SeqXY2SeqZ.pdf">[PDF]&nbsp&nbsp</a>
							 <a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123690596.pdf">[Open Access]&nbsp&nbsp</a>
							 <a href="https://arxiv.org/abs/2003.05559">[ArXiv]</a>.
						</td>
						</tr>
						<tr>
							<td><a href="main/big/DRWR_ICML2020.png"><img src="main/big/DRWR_ICML2020.png" alt="DRWR" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Zhizhong Han, Chao Chen, <strong>Yu-Shen Liu*</strong>, Matthias Zwicker. DRWR: A Differentiable Renderer without Rendering for Unsupervised 3D Structure Learning from Silhouette Images. <I>International Conference on Machine Learning <strong>(ICML)</strong></I>, 2020, PMLR 119:3994-4005.(<strong>~21.8% overall acceptance rate</strong>)(CCF-A)
								<br />
								<a href="main/pdf/LiuYS_ICML2020_DRWR.pdf">[PDF]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_ICML2020_DRWR-supp.pdf">[Supplementary]&nbsp&nbsp</a>
								<a href="http://proceedings.mlr.press/v119/han20b.html">[PMLR]&nbsp&nbsp</a>
								<a href="https://arxiv.org/abs/2007.06127">[Arxiv]&nbsp&nbsp</a>	
								<!-- <a href="main/pdf/LiuYS_CVPR20_SANet.pdf">[Paper]&nbsp&nbsp</a>	 <a href="main/pdf/LiuYS_CVPR20_SANet-supp.pdf">[Supplementary]&nbsp&nbsp</a> -->						
							</td>
						</tr>

						<tr>
							<td><a href="main/big/SP_Net_CVPR2020.png"><img src="main/big/SP_Net_CVPR2020.png" alt="SPNet++" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Xin Wen, Tianyang Li, Zhizhong Han, <strong>Yu-Shen Liu*</strong>. Point Cloud Completion by Skip-attention Network with Hierarchical Folding. <I>IEEE Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong></I>, 2020.(<strong>~22% overall acceptance rate</strong>)(CCF-A)
								<br />
								<a href="main/pdf/LiuYS_CVPR20_SANet.pdf">[PDF]&nbsp&nbsp</a>	 
								<a href="main/pdf/LiuYS_CVPR20_SANet-supp.pdf">[Supplementary]&nbsp&nbsp</a>    
								<a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Wen_Point_Cloud_Completion_by_Skip-Attention_Network_With_Hierarchical_Folding_CVPR_2020_paper.pdf">[Open Access]&nbsp&nbsp</a> 
								<a href="https://github.com/diviswen/sanet">[Source code]&nbsp&nbsp</a>
								<!-- <a href="https://arxiv.org/abs/2005.03871">[Arxiv]&nbsp&nbsp</a> -->
								<!-- <a href="main/pdf/LiuYS_CVPR20_SANet.pdf">[CVPR 2020]&nbsp&nbsp</a>	 <a href="main/pdf/LiuYS_CVPR20_SANet-supp.pdf">[Supplementary]&nbsp&nbsp</a> -->						
							</td>
						</tr>
						<tr>
							<td><a href="main/big/LRCNet.png"><img src="main/big/LRCNet.png" alt="LRCNet" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Xinhai Liu, Zhizhong Han, Fangzhou Hong, <strong>Yu-Shen Liu*</strong>, Matthias Zwicker. LRC-Net: Learning Discriminative Features on Point Clouds by Encoding Local Region Contexts. <I>Computer Aided Geometric Design</I>, 2020, 79: 101859. (SCI Journal Impact factor: <strong>1.382</strong>)(CCF-B)
								<br />
								<a href="main/pdf/LiuYS_CAGD20.pdf">[PDF]&nbsp&nbsp</a> 
								<a href="https://www.sciencedirect.com/science/article/pii/S0167839620300467">[ScienceDirect]&nbsp&nbsp</a> 
								<a href="https://www.youtube.com/watch?v=Ln1dOxY5Qwk">[Video]&nbsp&nbsp</a>
								<a href="https://arxiv.org/abs/2003.08240">[Arxiv]&nbsp&nbsp</a>							
							</td>
						</tr>
						<tr>
							<td><a href="main/big/BIMSeek++.png"><img src="main/big/BIMSeek++.png" alt="BIMSeek++" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Nanxing Li, Qian Li, <strong>Yu-Shen Liu*</strong>, Wenlong Lu, Wanqi Wang. BIMSeek++: Retrieving BIM Components using Similarity Measurement of Attributes. <I>Computers in Industry</I>, 2020, 116:103186, 1-12. (SCI Journal Impact factor: <strong>7.635</strong>)
								<br />	
								<a href="main/pdf/LiuYS_COMIND20_BIMSeek.pdf">[PDF]&nbsp&nbsp</a>							
							</td>
						</tr>
						<tr>
							<td><a href="main/big/BIMClustering.png"><img src="main/big/BIMClustering.png" alt="BIMClustering" width="150"/></a></td>
							<td>
								<span class="sequence"></span>Wan-Qi Wang, Bao-Rui Ma, Qian Li, Wen-Long Lu, <strong>Yu-Shen Liu</strong>. Clustering of BIM components based on similarity measurement of attributes. <I>Journal of Graphics</I>, 2020. (in Chinese)
								<br />	
								<a href="main/pdf/LiuYS_BIMClustering.pdf">[PDF]&nbsp&nbsp</a>							
							</td>
						</tr>
					</table>
					
					<b>2019</b>
					<hr />
					<table cellpadding=5>
						<tr>
							<td><a href="main/big/LiuYS_3D2SeqViews.png"><img src="main/big/LiuYS_3D2SeqViews.png" alt="3D2SeqViews" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Zhizhong Han, Honglei Lu, Zhenbao Liu, Chi-Man Vong, <strong>Yu-Shen Liu*</strong>, Matthias Zwicker, Junwei Han, C.L. Philip Chen. 3D2SeqViews: Aggregating Sequential Views for 3D Global Feature Learning by CNN with Hierarchical Attention Aggregation. <I>IEEE Transactions on Image Processing <strong>(TIP)</strong></I>, 2019, 28(8): 3986-3999 . (<b>SCI</b>, 2017 Impact factor: 5.071)(CCF-A)
								
								<br />
								<a href="https://ieeexplore.ieee.org/document/8666059">https://ieeexplore.ieee.org/document/8666059</a>	
								<br/>
								<a href="main/pdf/LiuYS_TIP19_3D2SeqViews.pdf">[Paper]&nbsp&nbsp</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/SeqViews2SeqLabels.png"><img src="main/small/SeqViews2SeqLabels.png" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Zhizhong Han, Mingyang Shang, Zhenbao Liu, Chi-Man Vong, <strong>Yu-Shen Liu*</strong>, Matthias Zwicker, Junwei Han, C.L. Philip Chen.  SeqViews2SeqLabels: Learning 3D Global Features via Aggregating Sequential Views by RNN with Attention. <i>IEEE Transactions on Image Processing <strong>(TIP)</strong></i>, 2019, 28(2): 658-672. (<b>SCI</b>, 2017 Impact factor: 5.071)(CCF-A)
								<br />
								<a href="https://ieeexplore.ieee.org/document/8453813/">https://ieeexplore.ieee.org/document/8453813/</a>	
								<br/>
								<a href="SeqViews2SeqLabels/index.html">[Project Page]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_TIP19RNN.pdf">[Paper]&nbsp&nbsp</a> 
								<a href="https://github.com/mingyangShang/SeqViews2SeqLabels">[Source code]&nbsp&nbsp</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/LiuYS_NeurIPS19_FLRML.png"><img src="main/big/LiuYS_NeurIPS19_FLRML.png" alt="Fast_Low-rank_ML" width="200"/></a></td>
							<td>
								<span class="sequence"></span> Han Liu, Zhizhong Han, <strong>Yu-Shen Liu*</strong>, Ming Gu. Fast Low-rank Metric Learning for Large-scale and High-dimensional Data. In <I>Neural Information Processing Systems <strong>(NeurIPS)</strong></I>, 2019, Vancouver, Canada.(<strong>~21.1% overall acceptance rate</strong>)(CCF-A)
								<!--<img class="new" src="main/img/new.gif"/>-->
								<br />	
								<a href="main/pdf/LiuYS_NeurIPS19_FLRML.pdf">[PDF]&nbsp&nbsp</a>	
								<a href="https://github.com/highan911/FLRML">[Source code]&nbsp&nbsp</a>
								<a href="https://arxiv.org/abs/1909.06297">[ArXiv]</a>
							</td>
						</tr>


						<tr>
							<td><a href="main/big/Point_Cloud_VAE.png"><img src="main/big/Point_Cloud_VAE.png" alt="Point_Cloud_VAE" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Zhizhong Han, Xiyang Wang, <strong>Yu-Shen Liu*</strong>, Matthias Zwicker. Multi-Angle Point Cloud-VAE: Unsupervised Feature Learning for 3D Point Clouds from Multiple Angles by Joint Self-Reconstruction and Half-to-Half Prediction. In <I>IEEE International Conference on Computer Vision <strong>(ICCV)</strong></I>, 2019, pp. 10441-10450.(<strong>~25% overall acceptance rate</strong>)(CCF-A)
								<br />	
								<a href="main/pdf/LiuYS_ICCV19_MAP.pdf">[PDF]&nbsp&nbsp</a>	
								<a href="https://openaccess.thecvf.com/content_ICCV_2019/html/Han_Multi-Angle_Point_Cloud-VAE_Unsupervised_Feature_Learning_for_3D_Point_Clouds_ICCV_2019_paper.html">[Open Access]&nbsp&nbsp</a>						
							</td>
						</tr>
						<tr>
							<td><a href="main/big/LiuYS_L2GAutoencoder.png"><img src="main/big/LiuYS_L2GAutoencoder.png" alt="L2GAutoencoder" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Xinhai Liu, Zhizhong Han, Xin Wen, <strong>Yu-Shen Liu*</strong>, Matthias Zwicker. L2G Auto-encoder: Understanding Point Clouds by Local-to-Global Reconstruction with Hierarchical Self-Attention. In <I>Proceedings of the 27th ACM International Conference on Multimedia <strong>(ACM MM'19)</strong></I>, 2019, pp. 989-997 (<strong><span style="color: red;">Oral presentation, ~26.5%</span> overall acceptance rate</strong>)(CCF-A)
								
								<br/> <a href="https://dl.acm.org/citation.cfm?doid=3343031.3350960">[DOI]</a>	
								<a href="main/pdf/LiuYS_ACMMM19_L2G_AE.pdf">[PDF]&nbsp&nbsp</a>	
								<a href="https://github.com/liuxinhai/L2G-AE">[Source code]&nbsp&nbsp</a>						
							</td>
						</tr>
						<tr>
							<td><a href="main/big/LiuYS_Parts4Feature.png"><img src="main/big/LiuYS_Parts4Feature.png" alt="Parts4Feature" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Zhizhong Han, Xinhai Liu, <strong>Yu-Shen Liu*</strong>, Matthias Zwicker. Parts4Feature: Learning 3D Global Features from Generally Semantic Parts in Multiple Views. In <I>International Joint Conference on Artificial Intelligence <strong>(IJCAI)</strong></I>, 2019, pp. 766-773 (<strong><span style="color: red;">Oral presentation, ~13.6%</span> overall acceptance rate</strong>)(CCF-A)
								
								<br/> <a href="https://doi.org/10.24963/ijcai.2019/108">[DOI]</a>	
 								      <a href="main/pdf/497_ijcai19_Parts4Feature.pdf">[PDF]&nbsp&nbsp</a>								
							</td>
						</tr>
						<tr>
							<td><a href="main/big/LiuYS_3D2ViewGraph.png"><img src="main/big/LiuYS_3D2ViewGraph.png" alt="3D2ViewGraph" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Zhizhong Han, Xiyang Wang, Chi-Man Vong, <strong>Yu-Shen Liu*</strong>, Matthias Zwicker, C.L. Philip Chen. 3DViewGraph: Learning Global Features for 3D Shapes from A Graph of Unordered Views with Attention. In <I>International Joint Conference on Artificial Intelligence <strong>(IJCAI)</strong></I>, 2019, pp. 758-765(<strong><span style="color: red;">Oral presentation, ~13.6%</span> overall acceptance rate</strong>)(CCF-A)
								
								<br/> <a href="https://doi.org/10.24963/ijcai.2019/107">[DOI]</a>
								
								<a href="main/pdf/487_ijcai19_3DViewGraph.pdf">[PDF]&nbsp&nbsp</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/VIPGAN.png"><img src="main/big/VIPGAN.png" alt="VIPGAN" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Zhizhong Han, Mingyang Shang, <strong>Yu-Shen Liu*</strong>, Matthias Zwicker. View Inter-Prediction GAN: Unsupervised Representation Learning for 3D Shapes by Learning Global Shape Memories to Support Local View Predictions. In <I>33rd AAAI Conference on Computing on Artificial Intelligence <strong>(AAAI-19)</strong></I>, 2019, 33(01): 8376-8384.  (<strong><span style="color: red;">Spotlight presentation, ~16.2%</span> overall acceptance rate</strong>)(CCF-A)
								
								<br/> <a href="https://aaai.org/ojs/index.php/AAAI/article/view/4852">https://aaai.org/ojs/index.php/AAAI/article/view/4852</a>
								<br /><a href="VIPGAN/index.html">[Project Page]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_AAAI19_VIPGAN.pdf">[PDF]&nbsp&nbsp</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/Y^2Seq2Seq.png"><img src="main/big/Y^2Seq2Seq.png" alt="Y^2Seq2Seq" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Zhizhong Han, Mingyang Shang, Xiyang Wang, <strong>Yu-Shen Liu*</strong>, Matthias Zwicker. Y^2Seq2Seq: Cross-Modal Representation Learning for 3D Shape and Text by Joint Reconstruction and Prediction of View and Word Sequences. In <I>33rd AAAI Conference on Computing on Artificial Intelligence <strong>(AAAI-19)</strong></I>, 2019, 33(01): 126-133. (<strong><span style="color: red;">Oral presentation, ~16.2%</span> overall acceptance rate</strong>)(CCF-A)
								
								<br/> <a href="https://aaai.org/ojs/index.php/AAAI/article/view/3777">https://aaai.org/ojs/index.php/AAAI/article/view/3777</a>
								<br /><a href="Y2Seq2Seq/index.html">[Project Page]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_AAAI19_Y2Seq2Seq.pdf">[Paper]&nbsp&nbsp</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/Point2Sequence.png"><img src="main/big/Point2Sequence.png" alt="Point2Sequence" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Xinhai Liu, Zhizhong Han, <strong>Yu-Shen Liu*,</strong> Matthias Zwicker. Point2Sequence: Learning the Shape Representation of 3D Point Clouds with an Attention-based Sequence to Sequence Network. In <I>33rd AAAI Conference on Computing on Artificial Intelligence <strong>(AAAI-19)</strong></I>, 2019, 33(01): 8778-8785. (<strong><span style="color: red;">Oral presentation, ~16.2%</span> overall acceptance rate</strong>)(CCF-A)
								
								<br/> <a href="https://aaai.org/ojs/index.php/AAAI/article/view/4903">https://aaai.org/ojs/index.php/AAAI/article/view/4903</a>	
								<br /><a href="Point2Sequence/index.html">[Project Page]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_AAAI19_Point2Sequence.pdf">[Paper]&nbsp&nbsp</a>
								<a href="https://github.com/liuxinhai/Point2Sequence">[Source code]&nbsp&nbsp</a>

							</td>
						</tr>
						<tr>
							<td><a href="main/big/Story.png"><img src="main/big/Story.png" alt="Story" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Nanxing Li, Bei Liu, Zhizhong Han, <strong>Yu-Shen Liu*</strong>, Jianlong Fu. Emotion Reinforced Visual Storytelling. <I> ACM International Conference on Multimedia Retrieval <strong>(ICMR)</strong></I>, 2019, pp.297-305, Ottawa, ON, Canada.(<span style="color: red;">Oral presentation</span>)(CCF-B)
							
								<br />
								<a href="https://dl.acm.org/citation.cfm?id=3325050&preflayout=tabs">https://dl.acm.org/citation.cfm?id=3325050&preflayout=tabs</a>	
								<br/>
								<a href="main/pdf/LiuYS_ICMR19.pdf">[Paper]&nbsp&nbsp</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/CMST.png"><img src="main/big/CMST.png" alt="CMST" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Xin Wen, Zhizhong Han, Xinyu Yin, <strong>Yu-Shen Liu*</strong>. Adversarial Cross-Modal Retrieval via Learning and Transferring Single-Modal Similarities. In <I>IEEE International Conference on Multimedia and Expo <strong>(ICME)</strong></I>, 2019, pp.478-483.(<span style="color: red;">Oral presentation</span>)(CCF-B)
								
								<br /><a href="main/pdf/LiuYS_ICME19_CMST.pdf">[Paper]&nbsp&nbsp</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/VCIBA.png"><img src="main/big/VCIBA.png" alt="VCIBA" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Hong-Lei Lu, Jia-Xing Wu, <strong>Yu-Shen Liu*</strong>, Wan-Qi Wang. Dynamically loading IFC models on a web browser based on spatial semantic partitioning. In <I>Visual Computing for Industry Biomedicine, and Art</I>, 2019, 2:4.
								
								<br /><a href="main/pdf/LiuYS_VCIBA19IFC.pdf">[Paper]&nbsp&nbsp</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/GIS+BIM.png"><img src="main/big/GIS+BIM.png" alt="GIS+BIM" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Pengfei Wu, <strong>Yu-Shen Liu</strong>, Yi Tan, Jianfeng Li. Advances and Trends of Integration between GIS and BIM. In <I>Geomatics & Spatial Information Technology</I>, 2019, 42(1): 1-6. (in Chinese)
								
								<br /><a href="main/pdf/LiuYS_GIS+BIM-19.pdf">[Paper]&nbsp&nbsp</a>
							</td>
						</tr>


					</table>
					<b>2018</b>
					<hr />
					<table cellpadding=5>
						<tr>
							<td><a href="main/big/DeepSpatiality.png"><img src="main/small/DeepSpatiality.png" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Zhizhong Han, Zhenbao Liu, Chi-Man Vong, <strong>Yu-Shen Liu*</strong>,  Shuhui Bu, Junwei Han, C.L. Philip Chen.  Deep Spatiality: Unsupervised Learning of Spatially-Enhanced Global and Local 3D Features by Deep Neural Network with Coupled Softmax. <i>IEEE Transactions on Image Processing <strong>(TIP)</strong></i>, 2018, 27(6): 3049-3063. (<b>SCI</b>, 2017 Impact factor: 5.071)(CCF-A)
								<br />
								<a href="main/pdf/LiuYS_TIP18DS.pdf">[Paper]&nbsp&nbsp</a> 
							</td>
						</tr>
						<tr>
							<td><a href="main/big/ifcdiff.jpg"><img src="main/small/ifcdiff.jpg" alt="IFCdiff" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Xin Shi, <strong>Yu-Shen Liu*</strong>, Ge Gao, Ming Gu, Haijiang Li. IFCdiff: A content-based automatic comparison approach for IFC files. <i>Automation in Construction</i>, 2018, 86: 53-68.  (SCI Journal Impact factor: <strong>7.700</strong>)
								<br/>
								<!-- <a href="main/pdf/LiuYS_VIV15Neucom2.pdf">[Paper]&nbsp&nbsp</a> -->
								<a href="ifcdiff/index.html">[Project Page]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_AIC18IFCdiff.pdf">[Paper]&nbsp&nbsp</a>
								<!--<a href="main/bibtex/Liu15BIMTag.txt">[Bib]&nbsp&nbsp</a>-->
							</td>
						</tr>
					</table>
					<b>2017</b>
					<hr />
					<table cellpadding=5>
						<tr>
							<td><a href="main/big/tip.png"><img src="main/small/tip.png" alt="han_tip" width="200"/></a-></td>
							<td>
								<span class="sequence"></span> Zhizhong Han, Zhenbao Liu, Chi-Man Vong, <strong>Yu-Shen Liu*</strong>, Shuhui Bu, Junwei Han, C.L. Philip Chen. BoSCC: Bag of Spatial Context Correlations for Spatially Enhanced 3D Shape Representation. <i>IEEE Transactions on Image Processing <strong>(TIP)</strong></i>, 2017, 26(8): 3707-3720. (SCI Journal Impact factor: <strong>10.215</strong>)(CCF-A)
								<br/>
								<a href="main/pdf/LiuYS_TIP17BoSCC.pdf">[Paper]&nbsp&nbsp</a>
								<br/>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/Figure_ESA.jpg"><img src="main/small/Figure_ESA.jpg" alt="liu_tii" width="200"/></a-></td>
							<td>
								<span class="sequence"></span>Han Liu, <strong>Yu-Shen Liu*</strong>, Pieter Pauwels, Hongling Guo, Ming Gu. Enhanced explicit semantic analysis for product model retrieval in construction industry. <i>IEEE Transactions on Industrial Informatics</i>, 2017, 13(6): 3361-3369 (<b>SCI</b>, 2016 Impact factor: 6.764)
								<br/>
								<a href="main/pdf/LiuYS_TII17ESA.pdf">[Paper]&nbsp&nbsp</a>
								<a href="https://github.com/highan911/wikiprep-esa">[Source code]&nbsp&nbsp</a>
								<br/>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/bimtag.png"><img src="main/small/bimtag.png" alt="BIMTag" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Ge Gao, <strong>Yu-Shen Liu*</strong>, Pengpeng Lin, Meng Wang, Ming Gu, Jun-Hai Yong. BIMTag: Concept-based automatic semantic annotation of online BIM product resources. <i>Advanced Engineering Informatics</i>, 2017, 31: 48-61. (Special issue of EG-ICE 2014). (SCI Journal Impact factor: <strong>5.603</strong>)(CCF-B)
								<br/>
								<a href="bimtag/index.html">[Project Page]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_AEI17BIMTag.pdf">[Paper]&nbsp&nbsp</a>
								<a href="main/bibtex/Liu17BIMTag.txt">[Bib]&nbsp&nbsp</a>
							</td>
						</tr>
					</table>
					<b>2016</b>
					<hr />
					<table cellpadding=5>
						<tr>
							<td><a href="main/big/LiuYS_VIV15Neucom2.png"><img src="main/small/LiuYS_VIV15Neucom2.png" alt="VIV15Neucom2" width="200"/></a></td>
							<td>
								<span class="sequence"></span><strong>Yu-Shen Liu</strong>, Hongchen Deng, Min Liu, Lianjie Gong. VIV: Using visible internal volume to compute junction-aware shape descriptor of 3D articulated models. <i>Neurocomputing</i>, 2016,215: 32-47. (SCI Impact factor: <strong>5.719</strong>)
								<p>Special Issue on Stereo data sensing, computation and perception
								</p>
								<a href="main/pdf/LiuYS_Neucom16VIV.pdf">[Paper]&nbsp&nbsp</a>
								<!--<a href="main/bibtex/Liu15BIMTag.txt">[Bib]&nbsp&nbsp</a>-->
							</td>
						</tr>
						<tr>
							<td><a href="main/big/icccbe2016_364.jpg"><img src="main/small/icccbe2016_364.jpg" alt="ICCCBE2016" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Ge Gao, <strong>Yu-Shen Liu*,</strong> Jia-Xing Wu, Ming Gu, Xu-Kun Yang, Hua-Liang Li. IFC Railway: A Semantic and Geometric Modeling Approach for Railways based on IFC. In <I>16th International Conference on Computing in Civil and Building Engineering (ICCCBE2016)</I>, 2016, Japan. (<strong><span style="color: red;">Best Student Presentation Award</span></strong>)
								<br/><a href="main/pdf/GaoGe_ICCCBE2016_364.pdf">[Paper]&nbsp&nbsp</a>
							</td>
						</tr>
					</table>
					<b>2015</b>
					<hr />
					<table cellpadding=5>
						<tr>
							<td><a href="main/big/ifcqe.png"><img src="main/small/ifcqe.png" alt="IFCOntoSearch" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Ge Gao, <strong>Yu-Shen Liu*</strong>, Meng Wang, Ming Gu, Jun-Hai Yong. A query expansion method for retrieving online BIM resources based on Industry Foundation Classes. <i>Automation in Construction</i>, 2015, 56: 14–25. (SCI Impact factor: <strong>7.700</strong>)
								
								
								<br/>
								<a href="ifcqe/index.html">[Project Page]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_AIC15IFCQE.pdf">[Paper]&nbsp&nbsp</a>
								<a href="main/bibtex/Liu15IFCQE.txt">[Bib]&nbsp&nbsp</a>

							</td>
						</tr>					
						<tr>
							<td><a href="main/big/compressor.jpg"><img src="main/small/compressor.jpg" alt="IFCCompressor" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Jing Sun, <strong>Yu-Shen Liu*</strong>, Ge Gao, Xiao-Guang Han. IFCCompressor: A content-based compression algorithm for optimizing Industry Foundation Classes files. <i>Automation in Construction</i>, 2015, 50: 1-15. (SCI Impact factor: <strong>7.700</strong>)
								
								
								<br/>
								<a href="IFCCompressor/index.html">[Project Page]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_AIC15IFCCompressor.pdf">[Paper]&nbsp&nbsp</a>
								<a href="main/bibtex/Liu15IFCCompressor.txt">[Bib]&nbsp&nbsp</a>
								<a href="IFCCompressor/IFCCompressor-Code.zip">[Source code]&nbsp&nbsp</a>
							</td>
						</tr>

						<tr>
							<td><a href="main/big/LiuYS_SignalProcessing.png"><img src="main/small/LiuYS_SignalProcessing.png" alt="Junction-aware" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Jinlong Feng, <strong>Yu-Shen Liu*</strong>, Lianjie Gong. Junction-aware shape descriptor for 3D articulated models using local shape-radius variation. <I>Signal Processing,</I> 2015, 112: 4-16. (SCI Impact factor: <strong>4.662</strong>) 
								
								
								<br/>
								<a href="ShapeRadius/index.html">[Project Page]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_SP15Junction.pdf">[Paper]&nbsp&nbsp</a>
								<a href="main/bibtex/Liu15SigPro.txt">[Bib]&nbsp&nbsp</a>

							</td>
						</tr>

						<tr>
							<td><a href="main/big/LiuYS_TSWJ14RBIM.png"><img src="main/small/LiuYS_TSWJ14RBIM.png" alt="TSWJ14RBIM" width="200"/></a></td>
							<td>
								<span class="sequence"></span><strong>Yu-Shen Liu</strong>, Heng Li, Haijiang Li, Pieter Pauwels, Jakob Beetz. Recent Advances on Building Information Modeling. <I>The Scientific World Journal</I>, vol. 2015, Article ID 786598, 2 pages, 2015. doi:10.1155/2015/786598. (<b>Editorial</b>) (<b>SCI</b>, 2013 Impact factor: 1.219)
								
								<br/>
								<a href="main/pdf/LiuYS_TSWJ14RBIM.pdf">[Paper]&nbsp&nbsp</a>
								<a href="main/pdf/Recent_Advances_on_Building_Information_Modeling_2015.pdf">[Special Issue]&nbsp&nbsp</a>
								<!--<a href="main/bibtex/Liu15SigPro.txt">[Bib]&nbsp&nbsp</a>-->

							</td>
						</tr>
					</table>
					<b>2014</b>
					<hr />
					<table cellpadding=5>
						<tr>
							<td><a href="main/big/BIMTagBig.png"><img src="main/small/BIMTag.jpg" alt="" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Ge Gao, <strong>Yu-Shen Liu*, </strong>Meng Wang, Xiao-Guang Han. BIMTag: Semantic Annotation of Web BIM Product Resources Based on IFC Ontology. In: 21st International Workshop of the European Group for Intelligent Computing in Engineering (EG-ICE 2014), July, 2014 Cardiff, United Kingdom. ISBN: 978-0-9930807-0-8 (EI: 20144900283797). (invitation for extended version submission to <I>Advanced Engineering Informatics</I>)
								<br/><a href="main/pdf/EGICE2014_BIMTag_final2.pdf">[Paper]&nbsp&nbsp</a>
							</td>
						</tr>
					</table>
					<b>2013</b>
					<hr />
					<table cellpadding=5>
						<tr>
							<td><a href="main/big/ifcpath.jpg"><img src="main/small/ifcpath.jpg" alt="The IFC-based path planning for 3D indoor spaces" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Ya-Hong Lin, <strong>Yu-Shen Liu*</strong>, Ge Gao, Xiao-Guang Han, Cheng-Yuan Lai, Ming Gu. The IFC-based path planning for 3D indoor spaces. <i>Advanced Engineering Informatics</i>, 2013; 27(2): 189-205. (<b>SCI</b>, 2013 Impact factor: 2.068) (<strong><span style="color:red;">Highly Cited Research Award</span></strong>)(CCF-B)

								<br/>
								<a href="ifcpath/index.html">[Project Page]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_AEI12IFC.pdf">[Paper]&nbsp&nbsp</a>
								<a href="https://github.com/kinmyy/THUIFCer">[Code]&nbsp&nbsp</a>
								<a href="main/bibtex/Liu13ifc.txt">[Bib]&nbsp&nbsp</a>

							</td>
						</tr>
						<tr>
							<td><a href="main/big/ACDT.jpg"><img src="main/small/ACDT.jpg" alt="" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Dongxing Cao, Shengfeng Qin, <strong>Yu-Shen Liu*</strong>. Advances in Conceptual Design Theories, Methodologies, and Applications. <i>Advances in Mechanical Engineering</i>, 2013; Article ID 207492, page 1-3. doi:10.1155/2013/207492. (<b>SCI</b>, 2012 Impact factor:1.062)<br/>
								Special Issue: <br/><a href="http://www.hindawi.com/journals/ame/si/293862/">http://www.hindawi.com/journals/ame/si/293862/</a>						
								<br/><a href="main/pdf/LiuYS_AME13ACDT.pdf">[Paper]&nbsp&nbsp</a>
								<a href="main/bibtex/Liu13AME.txt">[Bib]&nbsp&nbsp</a>
							</td>
						</tr>
					</table>
					<b>2012</b>
					<hr />
					<table cellpadding=5>
						<tr>
							<td><a href="main/big/CAD-S-11-00319.png"><img src="main/small/CAD-S-11-00319.png" alt="Robust shape normalization of 3D articulated volumetric models" width="200"/></a></td>
							<td>
									<span class="sequence"></span>Chao Wang, <strong>Yu-Shen Liu</strong>, Min Liu, Jun-Hai Yong, Jean-Claude Paul. Robust shape normalization of 3D articulated volumetric models. <i>Computer-Aided Design</i>, 2012; 44(12): 1253-1268. (<strong>SCI</strong>, Impact factor: 1.234)(CCF-B).							
								<br/><a href="main/pdf/LiuYS_CAD12Norm.pdf">[Paper]&nbsp&nbsp</a>
								<a href="main/bibtex/Liu12cad.txt">[Bib]</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/3dmolnavi.jpg"><img src="main/small/3dmolnavi.jpg" alt="3DMolNavi: A navigation system for flexible molecular shape retrieval based on histogram and dimensionality reduction" width="200"/></a></td>
							<td>
									<span class="sequence"></span><strong>Yu-Shen Liu</strong>, Meng Wang, Jean-Claude Paul, Karthik Ramani. 3DMolNavi: A web-based retrieval and navigation tool for flexible molecular shape comparison.<i>BMC Bioinformatics</i>, 2012, 13:95. (<strong>SCI</strong>, Impact factor: 3.029).<br/><a href="http://www.biomedcentral.com/1471-2105/13/95">http://www.biomedcentral.com/1471-2105/13/95</a>
								<br/><a href="3dmolnavi/index.html">[Project Page]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_BMC12molnavi.pdf">[Paper]&nbsp&nbsp</a>
								<a href="main/bibtex/Liu12bmcNavi.txt">[Bib]</a>
							</td>
						</tr>
					</table>
					<b>2011</b>
					<hr />
					<table cellpadding=5>
						<tr>
							<td><a href="main/big/LiuYS_PAMI11ID.png"><img src="main/small/LiuYS_PAMI11ID.png" alt="Computing the inner distances of volumetric models for articulated 
								shape description with a visibility graph." width="200"/></a></td>
							<td>
								<span class="sequence"></span><strong>Yu-Shen Liu</strong>, Karthik Ramani, Min Liu. Computing the inner distances of volumetric models for articulated shape description with a visibility graph. <i>IEEE Transactions on Pattern Analysis and Machine Intelligence <strong>(TPAMI)</strong></i>, 2011, 33(12): 2538-2544. (<strong>SCI</strong> , Impact factor: 4.908) (CCF-A)
								<br/>
								<a href="vmid/vmid_index.html">[Project Page]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_PAMI11ID.pdf">[Paper]&nbsp&nbsp</a>
								<a href="main/bibtex/Liu11pami.txt">[Bib]</a>
							</td>
						</tr>
					</table>
					<b>2010</b>
					<hr />
					<table cellpadding=5>
						<tr>
							<td><a href="main/big/LiuYS_BMC10diffusion.png"><img src="main/small/LiuYS_BMC10diffusion.png" alt="Using diffusion distances for flexible molecular shape comparison." width="200"/></a></td>
							<td>
								<span class="sequence"></span><strong>Yu-Shen Liu</strong>, Qi Li, Guo-Qin Zheng, Karthik Ramani, William Benjamin. Using diffusion distances for flexible molecular shape comparison. <i>BMC Bioinformatics</i>, 2010, 11:480 (<strong>SCI</strong>, Impact factor: 3.029)	
								<br/><a href="main/pdf/LiuYS_BMC10diffusion.pdf">[Paper]&nbsp&nbsp</a>
								<a href="main/bibtex/Liu10bmcDiff.txt">[Bib]</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/LiuYS_PR10VolArea.png"><img src="main/small/LiuYS_PR10VolArea.png" alt="Surface area estimation of digitized 3D objects using quasi-Monte Carlo methods."  width="200"/></a></td>
							<td>
								<span class="sequence"></span><strong>Yu-Shen Liu</strong>, Jing Yi, Hu Zhang, Guo-Qin Zheng, Jean-Claude Paul. Surface area estimation of digitized 3D objects using quasi-Monte Carlo methods. <i>Pattern Recognition</i>, 2010, 43(11): 3900-3909 (<strong>SCI</strong>, Impact factor: 2.682)(CCF-B).
								<br/><a href="main/pdf/LiuYS_PR10VolArea.pdf">[Paper]&nbsp&nbsp</a>
								<a href="main/bibtex/Liu10PR.txt">[Bib]</a>
							</td>
						</tr>
					</table>
					<b>2009</b>
					<hr />
					<table cellpadding=5>
						<tr>
							<td>
								<a href="main/big/LiuYS_BMC09IDSS.png"><img src="main/small/LiuYS_BMC09IDSS.png" alt="IDSS: deformation invariant signatures for molecular shape comparison" width="200" /></a> 
							</td>
							<td>
									<span class="sequence"></span><strong>Yu-Shen Liu</strong>, Yi Fang, Karthik Ramani. IDSS: deformation invariant signatures for molecular shape comparison, <i>BMC Bioinformatics</i>, 2009, 10:157 (<strong>SCI</strong>, Impact factor: 3.029). <br/>
									<a href="idss/idss_index.html">[Project Page]&nbsp&nbsp</a>
									<a href="main/pdf/LiuYS_BMC09IDSS.pdf">[Paper]&nbsp&nbsp</a>
									<a href="main/bibtex/Liu09bmcIDSS.txt">[Bib]</a>
							</td>
							
						</tr>
						<tr>
							<td>
								<a href="main/big/LiuYS_CAD09Min.png"><img src="main/small/LiuYS_CAD09Min.png" alt="Computing global visibility maps for regions on the boundaries of polyhedra using Minkowski sums" width="200"/></a>
							</td>
							<td>
								<span class="sequence"></span>Min Liu, <strong>Yu-Shen Liu</strong>, Karthik Ramani. Computing global visibility maps for regions on the boundaries of polyhedra using Minkowski sums. <i>Computer-Aided Design</i>, 2009; 41(9): 668-680 (<strong>SCI</strong>, Impact factor: 1.542)(CCF-B)
								<br/><a href="main/pdf/LiuYS_CAD09Min.pdf">[Paper]&nbsp&nbsp</a>
								<a href="main/bibtex/Liu09Min.txt">[Bib]</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/LiuYS_BMC09Fang.png"><img src="main/small/LiuYS_BMC09Fang.png" alt="Three dimensional shape comparison of flexible protein using the local-diameter descriptor" width="200"/></a></td>
							<td>
								<span class="sequence"></span>Yi Fang, <strong>Yu-Shen Liu</strong>, Karthik Ramani. Three dimensional shape comparison of flexible protein using the local-diameter descriptor, <i>BMC Structural Biology</i>, 2009, 9:29 (<strong>SCI</strong>, Impact factor: 2.258) <br/>
								<a href="https://engineering.purdue.edu/PRECISE/LDD">[Project Page]&nbsp&nbsp</a>
								<a href="main/pdf/LiuYS_09Fang.pdf">[Paper]&nbsp&nbsp</a>
								<a href="main/bibtex/Liu09Fang.txt">[Bib]</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/LiuYS_BMC09LMSfit.png"><img src="main/small/LiuYS_BMC09LMSfit.png" alt="Using least median of squares for structural superposition of flexible proteins" width="200" /></a></td>
							<td>
								<span class="sequence"></span><strong>Yu-Shen Liu</strong>, Yi Fang, Karthik Ramani. Using least median of squares for structural superposition of flexible proteins. <i>BMC Bioinformatics</i>, 2009, 10:29 (<strong>SCI</strong>, Impact factor: 3.029). <br/>
							<a href="https://engineering.purdue.edu/PRECISE/LMSfit">[Project Page]&nbsp&nbsp</a>
							<a href="main/pdf/LiuYS_BMC09LMSfit.pdf">[Paper]&nbsp&nbsp</a>
							<a href="main/bibtex/Liu09bmcLMS.txt">[Bib]</a>
							</td>
						</tr>
						<tr>
							<td><a href="main/big/LiuYS_CAD08RPCA.png"><img src="main/small/LiuYS_CAD08RPCA.png" alt="Robust principal axes determination for point-based shapes using least median of squares." width="200"/></a></td>
							<td>
								<span class="sequence"></span><strong>Yu-Shen Liu</strong>, Karthik Ramani. Robust principal axes determination for point-based shapes using least median of squares. <i>Computer-Aided Design</i>, 2009; 41(4): 293-305 (<strong>SCI</strong>, Impact factor: 1.542)(CCF-B)
								<br/><a href="main/pdf/LiuYS_CAD08RPCA.pdf">[Paper]&nbsp&nbsp</a>
								<a href="main/bibtex/Liu09cad.txt">[Bib]</a>
							</td>
						</tr>
					</table>
					<b>2008</b>
					<hr />
					<table cellpadding=5>
						<tr>
							<td><a href="main/big/LiuYS_CAD08projection.png"><img src="main/small/LiuYS_CAD08projection.png" alt="An extension on robust directed projection of points onto point clouds." width="200" /></a></td>
							<td>
								<span class="sequence"></span>Ming-Cui Du, <strong>Yu-Shen Liu</strong>. An extension on robust directed projection of points onto point clouds. <i>Computer-Aided Design</i>, 2008; 40(5):537-553. (<strong>SCI</strong>, Impact factor: 1.542)(CCF-B). 	
								<br/><a href="main/pdf/LiuYS_CAD08projection.pdf">[Paper]&nbsp&nbsp</a>
								<a href="main/bibtex/Liu08CAD.txt">[Bib]</a>
							</td>
						</tr>
					</table>
					<b>2007</b>
					<hr />
					<table cellpadding=5>
						<tr>
							<td></td>
							<td>
								<span class="sequence"></span><strong>Yu-Shen Liu</strong>, Min Liu, Daisuke Kihara, Karthik Ramani. Salient critical points for meshes. <i>In Proceedings of the 2007 ACM symposium on Solid and physical modeling (SPM'07)</i>, 277-282, June 2007, Beijing, China.(CCF-B)
							<br/><a href="main/pdf/LiuYS_SPM07CriticalPoints.pdf">[Paper]&nbsp&nbsp</a>
							<a href="main/bibtex/Liu07spm.txt">[Bib]&nbsp&nbsp</a>
							</td>
						</tr>
						<tr>
							<td></td>
							<td>
								<span class="sequence"></span>Min Liu, <strong>Yu-Shen Liu</strong>, Karthik Ramani. Anisotropic filtering on normal field and curvature tensor field using optimal estimation theory. <I>In Proceedings of the IEEE International Conference on Shape Modeling and Applications 2007 (SMI'07)</I>, 169-178, June 2007, Lyon, France.
							<br/><a href="main/pdf/LiuYS_SMI07Min.pdf">[Paper]&nbsp&nbsp</a>
							</td>
						</tr>
					</table>
					<b>2006</b>
					<hr />
					<table cellpadding=5>
						<tr>
							<td><a href="main/big/LiuYS_CAD06projection.png"><img src="main/small/LiuYS_CAD06projection.png" alt="Automatic least-squares projection of points onto point clouds with applications in reverse engineering"  width="200"/></a></td>
							<td>
								<span class="sequence"></span><strong>Yu-Shen Liu</strong>, Jean-Claude Paul, Jun-Hai Yong, Pi-Qiang Yu, Hui Zhang, Jia-Guang Sun, Karthik Ramani. Automatic least-squares projection of points onto point clouds with applications in reverse engineering. <i>Computer-Aided Design</i>, 2006; 38(12): 1251-1263. (<strong>SCI</strong>, Impact factor: 1.542)(CCF-B)
								<br/><a href="main/pdf/LiuYS_CAD06projection.pdf">[Paper]&nbsp&nbsp</a>
								<a href="main/bibtex/Liu06-LSP.txt">[Bib]</a>
							</td>
							
						</tr>
						<tr>
							<td><a href="main/big/LiuYS_CAD06area.png"><img src="main/small/LiuYS_CAD06area.png" alt="A quasi-Monte Carlo method for computing areas of point-sampled surfaces" width="200"/></a></td>
							<td>
								<span class="sequence"></span><strong>Yu-Shen Liu</strong>, Jun-Hai Yong, Hui Zhang, Dong-Ming Yan, Jia-Guang Sun. A quasi-Monte Carlo method for computing areas of point-sampled surfaces. <i>Computer-Aided Design</i>, 2006; 38(1): 55-68. (<strong>SCI</strong>, Impact factor: 1.542)(CCF-B)	
								<br/><a href="main/pdf/LiuYS_CAD06area.pdf">[Paper]&nbsp&nbsp</a>
								<a href="main/bibtex/Liu06.txt">[Bib]</a>
							</td>
						</tr>
					</table>
					<b>2005</b>
					<hr />
					<table cellpadding=5>
						<tr>
							<td><a href="main/big/LiuYS_TVC05Meshblending.png"><img src="main/small/LiuYS_TVC05Meshblending.png" alt="Mesh blending" width="200"/></a></td>
							<td>
								<span class="sequence"></span><strong>Yu-Shen Liu</strong>, Hui Zhang, Jun-Hai Yong, Pi-Qiang Yu, Jia-Guang Sun. Mesh blending. <i>The Visual Computer</i>, 2005; 21(11): 915-927. (<strong>SCI</strong>, Impact factor: 0.583)	
								<br/><a href="main/pdf/LiuYS_TVC05Meshblending.pdf">[Paper]&nbsp&nbsp</a>
							
							</td>
						</tr>
						<tr>
							<td></td>
							<td>
								<span class="sequence"></span><strong>Yu-Shen Liu</strong>, Jun-Hai Yong, Pi-Qiang Yu, Hui Zhang, Ming-Cui Du, Jia-Guang Sun. Mesh parameterization for an open connected surface without partition. <i>In Proceedings of the Ninth International Conference on Computer Aided Design and Computer Graphics (CAD-CG'05)</i>, 306-312, September, 2005, Hong Kong, China. (<strong><span style="color:red;">Best Student Paper Award</span></strong>)
							<br/><a href="main/pdf/LiuYS_CADCG05MP.pdf">[Paper]&nbsp&nbsp</a>
							</td>
						</tr>
					</table>
					<br/>
					<b>2004</b>
					<hr />
					<table cellpadding=5>
						<tr>
							<td></td>
							<td>
								<span class="sequence"></span><strong>Yu-Shen Liu</strong>, Pi-Qiang Yu, Jun-Hai Yong, Hui Zhang, Jia-Guang Sun. Bilateral filter for meshes using new predictor. <i>International Symposium on Computational and Information Sciences (CIS'04)</i>, LNCS 3314: 1093-1099, 2004. (SCI, Impact factor: 0.531)
								<br/><a href="main/pdf/LiuYS_CIS04BF.pdf">[Paper]&nbsp&nbsp</a>
							
							</td>
						</tr>
					</table>					
					<!-- <div class="subtitle" id="Articles in Review and Preparation">Articles in Review and Preparation:</div> -->
					<!--<hr/>-->
					
					<!-- <table cellpadding=5>
						<tr>
							<td>
								<span class="sequence"></span>Han Liu, <strong>Yu-Shen Liu</strong>, Pieter Pauwels, Hongling Guo, Ming Gu. Enhanced Explicit Semantic Analysis for product model retrieval in construction industry. IEEE Transactions on Industrial Informatics, under review (1st round), 2017.
							</td>
						</tr>
					</table> -->					
				</div>
			</div>
		</div>

	</body>
	<script src="common/js/jquery-3.2.1.min.js" type="text/javascript" ></script>
	<script type="text/javascript" src="common/js/fancybox/jquery.mousewheel-3.0.4.pack.js"></script>
	<!--script type="text/javascript" src="common/js/fancybox/jquery.fancybox-1.3.4.pack.js"></script-->	
	<link rel="stylesheet" type="text/css" href="common/js/fancybox/jquery.fancybox-1.3.4.css" media="screen">
	<script type="text/javascript" >
	<!--
		$(function() {
			$(".sequence").each(function(key,value)
			{
				var sequence=key+1;
				sequence=sequence+". ";
				$(this).text(sequence);
			})

			$(".softseq").each(function(key,value)
			{
				var sequence=key+1;
				sequence=sequence+". ";
				$(this).text(sequence);
			})
		})
	-->
	</script>
</html>
